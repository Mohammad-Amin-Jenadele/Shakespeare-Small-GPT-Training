{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "import torch\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the Shakespeare.txt file\n",
    "with open('Shakespeare.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the text : 1115394\n",
      "\n",
      "First 1000 characters of the text : \n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of the text : {len(text)}\\n')\n",
    "print(f'First 1000 characters of the text : \\n{text[:1000]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text: [0, 3, 4, 5, 6, 37, 38, 39, 40, 12, 41, 42, 43, 44, 45, 46, 47, 1, 16, 6, 48, 49, 1, 27, 2]\n",
      "Original Text: First Citizen : \n",
      " Let us kill him , and we'll have corn at our own <UNK> . \n",
      " Is't a <UNK> ?\n",
      "The length the tokenizer : 1979\n"
     ]
    }
   ],
   "source": [
    "# Making a dictionary for the text\n",
    "nltk.download('punkt')\n",
    "repetition_threshold = 10  # Set your desired repetition threshold\n",
    "tokenizer = utils.TextTokenizer(repetition_threshold)\n",
    "tokenizer.process_text(text)\n",
    "vocab_size = len(tokenizer.get_token_dict())\n",
    "# Example text and tokenized text\n",
    "example_text = \"First Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\"\n",
    "tokenized_text = tokenizer.text_to_tokens(example_text)\n",
    "print(\"Tokenized Text:\", tokenized_text)\n",
    "\n",
    "# Convert tokenized text back to original text\n",
    "original_text = tokenizer.tokens_to_text(tokenized_text)\n",
    "print(\"Original Text:\", original_text)\n",
    "print(f'The length the tokenizer : {vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([290403])\n",
      "tensor([  0,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
      "         16,   6,   6,  17,   5,   6,  18,  12,  15,  16,   6,   6,   3,   4,\n",
      "          5,   6,  19,  20,  21,  22,  23,  24,  25,  26,  24,   1,  27,   6,\n",
      "          6,  17,   5,   6,   1,  16,  22,  16,   6,   6,   3,   4,   5,   6,\n",
      "          3,  12,  28,  29,  30,  31,  32,   1,  33,  24,  34,  35,  16,   6,\n",
      "          6,  17,   5,   6,  36,   1,  12,   8,   1,  16,   6,   6,   3,   4,\n",
      "          5,   6,  37,  38,  39,  40,  12,  41,  42,  43,  44,  45,  46,  47,\n",
      "          1,  16,   6,  48,  49,   1,  27,   6,   6,  17,   5,   6,  50,  51,\n",
      "          1,  52,  53,  54,  55,  56,  57,   5,  58,  12,  58,  59,   6,   6,\n",
      "         60,   4,   5,   6,  61,  62,  12,  63,  64,  16,   6,   6,   3,   4,\n",
      "          5,   6,  36,  20,   1,  65,  64,  12,  34,   1,  63,  16,   6,  66,\n",
      "         67,   1,  68,  69,   1,  38,   5,  70,  71,   6,  69,  72,  38,  73,\n",
      "         34,   1,  12,  74,  55,  75,   6,   1,  12,   8,  76,  77,  71,   1,\n",
      "         38,   1,  53,   6,  73,  71,  78,   8,  20,  79,  80,   5,  34,   1,\n",
      "         81,   6,   1,  38,  12,  34,   1,  82,  46,  83,  12,  32,  84,  85,\n",
      "          6,   1,  24,   1,  86,   1,  53,  46,   6,   1,  32,  49,  87,  24,\n",
      "         88,  37,  38,  89,  90,  91,   6,  46,   1,  12,  92,   8,  93,   1,\n",
      "          5,  94,  34,  95,  29,  96,   6,  15,  90,  97,   1,  94,   1,  12,\n",
      "         98,  97,   1,  94,  89,  16,   6,   6,  60,   4,   5,   6,  99,  28,\n",
      "          9,   1, 100,  30,  31,  27,   6,   6,  17,   5,   6, 101,  40, 102,\n",
      "          5, 103,  49, 104, 105,  24,  34,   1,  16,   6,   6,  60,   4,   5,\n",
      "          6,   1,  28, 106, 107, 108, 109,  57,  94, 110, 111,  27,   6,   6,\n",
      "          3,   4,   5,   6, 112, 113,  53,  41, 114,  56, 115,  24, 116,  40,\n",
      "         63,   6, 117,   1,  12,  73,  81, 108,   1, 118,  91, 119, 120,  16,\n",
      "          6,   6,  60,   4,   5,   6, 121,  12,  73,  15,  98,   1,  16,   6,\n",
      "          6,   3,   4,   5,   6,  96, 122, 123,  28,  12, 106, 108, 124,  57,\n",
      "          1,  12, 108, 125,   6,  55,  24,  81, 126,   5, 127, 128,   1, 129,\n",
      "        130,  56,   6, 115,  24, 122,  55, 131,  94, 110, 111, 108, 125,  55,\n",
      "         24,   6, 132, 110, 133,  41,  24,  56,   1, 120,  53, 134, 108,   6,\n",
      "         32,  12, 135, 136,  34,   1,  82, 110, 137,  16,   6,   6,  60,   4,\n",
      "          5,   6,  66, 108, 138, 139,  97, 110, 140,  12,  28, 141,  49,   6,\n",
      "        142,  97,  40,  16,  19, 143,  97, 144, 145, 122, 108,  32,   1,  16,\n",
      "          6,   6,   3,   4,   5,   6, 146,  96, 143,  98,  12,  96, 147,  98,\n",
      "         56,   1,  82,   1,  53,   6, 108, 124, 148,  12,  91,   1,  12,  24,\n",
      "          1,  97,   1,  16,   6,  66,   1,  20, 149,  27, 150, 151, 152, 153,\n",
      "         34, 154,   6,  32,   1,   5, 155, 156,   8,   1, 157,  27,  24,  34,\n",
      "        158,  59,   6,   6,  17,   5,   6, 159,  12, 160,  16,   6,   6,   3,\n",
      "          4,   5,   6,   1,  59, 161, 162, 157,  27,   6,   6,  60,   4,   5,\n",
      "          6, 163, 164,   1,  53, 165,  81, 124, 166, 167,   6,  34,  35,  16,\n",
      "          6,   6,   3,   4,   5,   6, 168, 165, 169, 170,   5,  69,  21,  34,\n",
      "        171,  75, 172,  59,   6,   6, 173,   5,   6,  66,   1,  12, 174,   1,\n",
      "         12,  97, 175,  27, 176, 177,  28,   6, 178,   1,  41,   1,  27, 150,\n",
      "        179,  27,  15,  12,  96, 180,  28,  16,   6,   6,   3,   4,   5,   6,\n",
      "        181, 182,  32,  98, 183,  24,  34, 184,  53,  71,  43,   6, 185,   1,\n",
      "         90,   1, 106,   8, 186,  24, 187,  12,   6, 134, 188,  42, 189, 190,\n",
      "         97, 191,  16, 192, 122,  65,   6,   1,  43, 193,   1,   5,  71, 194,\n",
      "         29,   8,   6,  43, 193, 195,  79,  16,   6,   6, 173,   5,   6, 196,\n",
      "         12, 197,  12, 174,  63, 198,  12, 199, 169,   1,  12,   6, 200,  28,\n",
      "          1, 201,  27,   6,   6,   3,   4,   5,   6,  36, 138,  12, 202,  12,\n",
      "          8,  20, 203, 204,  16,   6,   6, 173,   5,   6,  96, 205,  28,  12,\n",
      "        198,  12, 206,   1, 207,   6, 208,  34,   1,  82,  28,  16, 209, 210,\n",
      "        211,  12,   6, 212,   1,  97,  90,   1,  12,  28, 213,  84, 113,   6,\n",
      "          1,  45,  34, 214,  91, 210,   1,  84,   1,  88,   6, 101,  34, 215,\n",
      "        216,  12, 217, 218, 219,  68,   6, 150, 145,  55,   1,  12,   1, 220,\n",
      "        221,   1,   6, 222,  51, 193,   1,   1,  26, 130, 223,   6,   1,  97,\n",
      "        210,   1,  16, 209,  34,   1,  12,   6, 150,  95,  12,  98,  34,   1,\n",
      "         12, 224,  55,  12,  41,   6, 212, 225,  24,  88,  12,  98, 195,  12,\n",
      "        143, 139,  16, 226,  12,   6,  19,  20,   1, 227,   1,   6,   1, 176,\n",
      "         51,   1,  28,  12,  41,  28, 228,   6, 150,   1, 153,  34, 216,  12,\n",
      "        161, 207,  94,  28, 229,   1,  12,   6, 230,  28, 231,  88,  84, 232,\n",
      "         16,   6,   6,   3,   4,   5,   6,   1,  94,  38,  59, 233,  12, 234,\n",
      "         59, 192, 235,   1,  94,  38,   6, 236,   5, 237,  38,  24,   1,  12,\n",
      "         41,  86,   1, 238,   6,   1,  91,   1,  53, 224,   1,  94,   1,  12,\n",
      "         24,   6,   1,   1,  53,   1,   1,  10,   1, 239,   6,   1, 100,  34,\n",
      "        240,  12,  41,   1,  51,   6,   1,   1,   1,  12,  24,   1, 241,  41,\n",
      "          1,   6,  34,  65,  16, 146,  34, 242, 243,  38,  98, 241,  12,  71,\n",
      "        219,  53,  41,   6, 244,  21,  34, 245,  71, 246,  38,  16,   6,   6,\n",
      "        173,   5,   6, 247,  28, 143,   6,   1, 201,   1,   1,  12,   6, 248,\n",
      "         56,   1,  82, 249,  16,  96, 194, 205,  28,   6, 250, 251, 252,   5,\n",
      "         55, 213,  56,  28,  43, 253,  55,  53,   6, 254,  12, 255,  55, 256,\n",
      "        174, 257,  12,  96, 219,   1,   6, 258,   1, 259,  49, 260,  51,  16,\n",
      "          6,   6,   3,   4,   5,   6])\n"
     ]
    }
   ],
   "source": [
    "# tokenizing the entire Shakespeare text\n",
    "data = torch.tensor(tokenizer.text_to_tokens(text))\n",
    "print(data.shape)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the validation and training data\n",
    "n = int(0.9 * len(data))\n",
    "training_set = data[:n]\n",
    "validation_set = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below , we are determining the `block_size` which is the size of each training data . But each example , has `block_size` examples within iy self . In the cell below , it is shown by an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an example of a data : tensor([0, 3, 4, 5, 6, 7, 8, 9])\n",
      "input : tensor([0]) , target : 3\n",
      "input : tensor([0, 3]) , target : 4\n",
      "input : tensor([0, 3, 4]) , target : 5\n",
      "input : tensor([0, 3, 4, 5]) , target : 6\n",
      "input : tensor([0, 3, 4, 5, 6]) , target : 7\n",
      "input : tensor([0, 3, 4, 5, 6, 7]) , target : 8\n",
      "input : tensor([0, 3, 4, 5, 6, 7, 8]) , target : 9\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "x = training_set[:block_size]\n",
    "print(f'an example of a data : {x}')\n",
    "for t in range(1,block_size):\n",
    "    context = x[:t]\n",
    "    target = x[t]\n",
    "    print(f'input : {context} , target : {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs =\n",
      "tensor([[  34,    1,   16,    6,    6,    3, 1893,    5],\n",
      "        [   6,    6,  462,    5,    6,  150, 1625,   82],\n",
      "        [   6,  317,  434,   98,  137,   12,  144,   12],\n",
      "        [   6, 1937,    5,    6, 1928,  124,  777,   88]])\n",
      "outputs =\n",
      "tensor([[   1,   16,    6,    6,    3, 1893,    5,    6],\n",
      "        [   6,  462,    5,    6,  150, 1625,   82, 1697],\n",
      "        [ 317,  434,   98,  137,   12,  144,   12,  391],\n",
      "        [1937,    5,    6, 1928,  124,  777,   88,  673]])\n",
      "------------------------ EXAMPLE ------------------------\n",
      "input : [34] , target : 1\n",
      "input : [34, 1] , target : 16\n",
      "input : [34, 1, 16] , target : 6\n",
      "input : [34, 1, 16, 6] , target : 6\n",
      "input : [34, 1, 16, 6, 6] , target : 3\n",
      "input : [34, 1, 16, 6, 6, 3] , target : 1893\n",
      "input : [34, 1, 16, 6, 6, 3, 1893] , target : 5\n",
      "input : [34, 1, 16, 6, 6, 3, 1893, 5] , target : 6\n",
      "input : [6] , target : 6\n",
      "input : [6, 6] , target : 462\n",
      "input : [6, 6, 462] , target : 5\n",
      "input : [6, 6, 462, 5] , target : 6\n",
      "input : [6, 6, 462, 5, 6] , target : 150\n",
      "input : [6, 6, 462, 5, 6, 150] , target : 1625\n",
      "input : [6, 6, 462, 5, 6, 150, 1625] , target : 82\n",
      "input : [6, 6, 462, 5, 6, 150, 1625, 82] , target : 1697\n",
      "input : [6] , target : 317\n",
      "input : [6, 317] , target : 434\n",
      "input : [6, 317, 434] , target : 98\n",
      "input : [6, 317, 434, 98] , target : 137\n",
      "input : [6, 317, 434, 98, 137] , target : 12\n",
      "input : [6, 317, 434, 98, 137, 12] , target : 144\n",
      "input : [6, 317, 434, 98, 137, 12, 144] , target : 12\n",
      "input : [6, 317, 434, 98, 137, 12, 144, 12] , target : 391\n",
      "input : [6] , target : 1937\n",
      "input : [6, 1937] , target : 5\n",
      "input : [6, 1937, 5] , target : 6\n",
      "input : [6, 1937, 5, 6] , target : 1928\n",
      "input : [6, 1937, 5, 6, 1928] , target : 124\n",
      "input : [6, 1937, 5, 6, 1928, 124] , target : 777\n",
      "input : [6, 1937, 5, 6, 1928, 124, 777] , target : 88\n",
      "input : [6, 1937, 5, 6, 1928, 124, 777, 88] , target : 673\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4 \n",
    "block_size = 8  # Number of maximum context length\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "def get_batch(dataset , batch_size):\n",
    "    data = training_set if dataset == 'train' else  validation_set\n",
    "    ix = torch.randint(len(data) - block_size , size = (batch_size,))\n",
    "    x = torch.stack([data[i : i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1 : i + block_size + 1] for i in ix])\n",
    "    x , y = x.to(device) , y.to(device)\n",
    "    return x , y\n",
    "\n",
    "\n",
    "x_b , y_b = get_batch('train' , batch_size = batch_size)\n",
    "print(f'inputs =\\n{x_b}')\n",
    "print(f'outputs =\\n{y_b}')\n",
    "\n",
    "# An Example\n",
    "print('------------------------ EXAMPLE ------------------------')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = x_b[b , : t+1]\n",
    "        target = y_b[b  , t]\n",
    "        print(f'input : {context.tolist()} , target : {target}')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Language Model Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bigram language model is the simplest type of language model, predicting the next token based solely on the previous one. In this section, we implement such a model, and you can see the results at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.1455, grad_fn=<NllLossBackward0>)\n",
      "duty ye See touch O nine Faith home Lest ways glass ladies pray towards minister Art seal go needful foes lady's BUSHY died something was Page rest from Pray woman's and could knave evil hath rage act shame field Tell\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self , vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(num_embeddings = vocab_size , embedding_dim = vocab_size)\n",
    "\n",
    "    def forward(self , idx , targets = None):\n",
    "        logits = self.token_embedding_table(idx)    # (Batch_size, Time or block_size , Channels = Embedding size)\n",
    "\n",
    "        if targets is None :\n",
    "            loss = None\n",
    "        else :     \n",
    "            B , T , C = logits.shape\n",
    "            logits = logits.reshape(B * T , C)\n",
    "            targets = targets.reshape(B * T)\n",
    "            loss = F.cross_entropy(logits , targets)\n",
    "        return logits , loss\n",
    "    \n",
    "    def generate(self , idx , max_new_tokens):\n",
    "        # This function will predict the next word base on the previous word\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits , loss = self(idx)\n",
    "            logits = logits[: , -1 , :]  # we put -1 because we only need the last word\n",
    "            probs = F.softmax(logits , dim = 1)\n",
    "            idx_next = torch.multinomial(probs , num_samples = 1)\n",
    "            idx = torch.cat([idx , idx_next] , dim = 1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "m =  BigramLanguageModel(vocab_size = vocab_size).to(device)\n",
    "logits , loss = m(x_b , y_b)\n",
    "print(loss)\n",
    "print(tokenizer.tokens_to_text(m.generate(torch.zeros((1 , 1) , dtype = torch.long) , max_new_tokens = 40)[0].tolist()))  # showing the results of untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 0 , loss : 7.999255180358887\n",
      "iteration : 1 , loss : 8.000387191772461\n",
      "iteration : 2 , loss : 8.10175609588623\n",
      "iteration : 3 , loss : 8.054214477539062\n",
      "iteration : 4 , loss : 8.084694862365723\n",
      "iteration : 5 , loss : 8.066719055175781\n",
      "iteration : 6 , loss : 8.02578067779541\n",
      "iteration : 7 , loss : 8.013591766357422\n",
      "iteration : 8 , loss : 7.935837268829346\n",
      "iteration : 9 , loss : 7.968321800231934\n",
      "iteration : 10 , loss : 7.990190505981445\n",
      "iteration : 11 , loss : 8.023605346679688\n",
      "iteration : 12 , loss : 8.142383575439453\n",
      "iteration : 13 , loss : 8.10863971710205\n",
      "iteration : 14 , loss : 8.037957191467285\n",
      "iteration : 15 , loss : 8.018180847167969\n",
      "iteration : 16 , loss : 8.065342903137207\n",
      "iteration : 17 , loss : 7.953418731689453\n",
      "iteration : 18 , loss : 7.97348690032959\n",
      "iteration : 19 , loss : 7.878756523132324\n",
      "iteration : 20 , loss : 7.963230133056641\n",
      "iteration : 21 , loss : 7.919926166534424\n",
      "iteration : 22 , loss : 7.884855270385742\n",
      "iteration : 23 , loss : 7.787797927856445\n",
      "iteration : 24 , loss : 7.9021148681640625\n",
      "iteration : 25 , loss : 7.935387134552002\n",
      "iteration : 26 , loss : 7.8657965660095215\n",
      "iteration : 27 , loss : 7.9295196533203125\n",
      "iteration : 28 , loss : 7.874075412750244\n",
      "iteration : 29 , loss : 7.753864288330078\n",
      "iteration : 30 , loss : 7.987642765045166\n",
      "iteration : 31 , loss : 7.899656295776367\n",
      "iteration : 32 , loss : 7.908427715301514\n",
      "iteration : 33 , loss : 7.915867328643799\n",
      "iteration : 34 , loss : 7.798992156982422\n",
      "iteration : 35 , loss : 7.800290107727051\n",
      "iteration : 36 , loss : 7.838414669036865\n",
      "iteration : 37 , loss : 7.78106164932251\n",
      "iteration : 38 , loss : 7.785120487213135\n",
      "iteration : 39 , loss : 7.84316349029541\n",
      "iteration : 40 , loss : 7.715953826904297\n",
      "iteration : 41 , loss : 7.852653503417969\n",
      "iteration : 42 , loss : 7.921637058258057\n",
      "iteration : 43 , loss : 7.761166095733643\n",
      "iteration : 44 , loss : 7.733033180236816\n",
      "iteration : 45 , loss : 7.841603755950928\n",
      "iteration : 46 , loss : 7.786383628845215\n",
      "iteration : 47 , loss : 7.855177879333496\n",
      "iteration : 48 , loss : 7.816448211669922\n",
      "iteration : 49 , loss : 7.787570953369141\n",
      "iteration : 50 , loss : 7.755755424499512\n",
      "iteration : 51 , loss : 7.722527027130127\n",
      "iteration : 52 , loss : 7.639910697937012\n",
      "iteration : 53 , loss : 7.679637432098389\n",
      "iteration : 54 , loss : 7.595274448394775\n",
      "iteration : 55 , loss : 7.666780948638916\n",
      "iteration : 56 , loss : 7.8039679527282715\n",
      "iteration : 57 , loss : 7.695677280426025\n",
      "iteration : 58 , loss : 7.724567413330078\n",
      "iteration : 59 , loss : 7.6988205909729\n",
      "iteration : 60 , loss : 7.764384746551514\n",
      "iteration : 61 , loss : 7.743918418884277\n",
      "iteration : 62 , loss : 7.564975261688232\n",
      "iteration : 63 , loss : 7.627100944519043\n",
      "iteration : 64 , loss : 7.560061454772949\n",
      "iteration : 65 , loss : 7.588670253753662\n",
      "iteration : 66 , loss : 7.649606704711914\n",
      "iteration : 67 , loss : 7.600375652313232\n",
      "iteration : 68 , loss : 7.687963008880615\n",
      "iteration : 69 , loss : 7.587196350097656\n",
      "iteration : 70 , loss : 7.633499622344971\n",
      "iteration : 71 , loss : 7.628917217254639\n",
      "iteration : 72 , loss : 7.577887058258057\n",
      "iteration : 73 , loss : 7.559202194213867\n",
      "iteration : 74 , loss : 7.41676139831543\n",
      "iteration : 75 , loss : 7.595911502838135\n",
      "iteration : 76 , loss : 7.45474910736084\n",
      "iteration : 77 , loss : 7.484342098236084\n",
      "iteration : 78 , loss : 7.5314106941223145\n",
      "iteration : 79 , loss : 7.666451930999756\n",
      "iteration : 80 , loss : 7.367990493774414\n",
      "iteration : 81 , loss : 7.542226791381836\n",
      "iteration : 82 , loss : 7.58997917175293\n",
      "iteration : 83 , loss : 7.45611572265625\n",
      "iteration : 84 , loss : 7.333827972412109\n",
      "iteration : 85 , loss : 7.509795665740967\n",
      "iteration : 86 , loss : 7.447027683258057\n",
      "iteration : 87 , loss : 7.426325798034668\n",
      "iteration : 88 , loss : 7.433661460876465\n",
      "iteration : 89 , loss : 7.401768207550049\n",
      "iteration : 90 , loss : 7.531220436096191\n",
      "iteration : 91 , loss : 7.553877353668213\n",
      "iteration : 92 , loss : 7.409421920776367\n",
      "iteration : 93 , loss : 7.4680585861206055\n",
      "iteration : 94 , loss : 7.468171119689941\n",
      "iteration : 95 , loss : 7.492249011993408\n",
      "iteration : 96 , loss : 7.241348743438721\n",
      "iteration : 97 , loss : 7.360759258270264\n",
      "iteration : 98 , loss : 7.353362560272217\n",
      "iteration : 99 , loss : 7.337210178375244\n",
      "iteration : 100 , loss : 7.482277870178223\n",
      "iteration : 101 , loss : 7.360795497894287\n",
      "iteration : 102 , loss : 7.442664623260498\n",
      "iteration : 103 , loss : 7.201963424682617\n",
      "iteration : 104 , loss : 7.357263565063477\n",
      "iteration : 105 , loss : 7.370162010192871\n",
      "iteration : 106 , loss : 7.4967360496521\n",
      "iteration : 107 , loss : 7.38586950302124\n",
      "iteration : 108 , loss : 7.142126083374023\n",
      "iteration : 109 , loss : 7.311069965362549\n",
      "iteration : 110 , loss : 7.356229782104492\n",
      "iteration : 111 , loss : 7.294344425201416\n",
      "iteration : 112 , loss : 7.259151935577393\n",
      "iteration : 113 , loss : 7.401702880859375\n",
      "iteration : 114 , loss : 7.223082542419434\n",
      "iteration : 115 , loss : 7.380771160125732\n",
      "iteration : 116 , loss : 7.162837028503418\n",
      "iteration : 117 , loss : 7.3213300704956055\n",
      "iteration : 118 , loss : 7.265883922576904\n",
      "iteration : 119 , loss : 7.132410526275635\n",
      "iteration : 120 , loss : 7.202459335327148\n",
      "iteration : 121 , loss : 7.364403247833252\n",
      "iteration : 122 , loss : 7.101759910583496\n",
      "iteration : 123 , loss : 7.1745991706848145\n",
      "iteration : 124 , loss : 7.2219743728637695\n",
      "iteration : 125 , loss : 7.216100215911865\n",
      "iteration : 126 , loss : 7.171134948730469\n",
      "iteration : 127 , loss : 7.364673614501953\n",
      "iteration : 128 , loss : 7.235788345336914\n",
      "iteration : 129 , loss : 7.069562911987305\n",
      "iteration : 130 , loss : 7.092513084411621\n",
      "iteration : 131 , loss : 6.990941047668457\n",
      "iteration : 132 , loss : 7.036655902862549\n",
      "iteration : 133 , loss : 7.249363422393799\n",
      "iteration : 134 , loss : 7.249423027038574\n",
      "iteration : 135 , loss : 7.073473930358887\n",
      "iteration : 136 , loss : 7.260887145996094\n",
      "iteration : 137 , loss : 7.0102763175964355\n",
      "iteration : 138 , loss : 7.184347152709961\n",
      "iteration : 139 , loss : 7.193124294281006\n",
      "iteration : 140 , loss : 7.0222954750061035\n",
      "iteration : 141 , loss : 6.956981182098389\n",
      "iteration : 142 , loss : 7.081676483154297\n",
      "iteration : 143 , loss : 7.130711078643799\n",
      "iteration : 144 , loss : 7.0421319007873535\n",
      "iteration : 145 , loss : 6.922875881195068\n",
      "iteration : 146 , loss : 7.08664083480835\n",
      "iteration : 147 , loss : 6.916060447692871\n",
      "iteration : 148 , loss : 6.875065803527832\n",
      "iteration : 149 , loss : 7.128538131713867\n",
      "iteration : 150 , loss : 7.096225261688232\n",
      "iteration : 151 , loss : 7.025193214416504\n",
      "iteration : 152 , loss : 7.047565460205078\n",
      "iteration : 153 , loss : 7.019622802734375\n",
      "iteration : 154 , loss : 6.999174118041992\n",
      "iteration : 155 , loss : 7.070245742797852\n",
      "iteration : 156 , loss : 7.055094242095947\n",
      "iteration : 157 , loss : 7.047992706298828\n",
      "iteration : 158 , loss : 7.024339199066162\n",
      "iteration : 159 , loss : 6.934540748596191\n",
      "iteration : 160 , loss : 6.964328765869141\n",
      "iteration : 161 , loss : 6.959292888641357\n",
      "iteration : 162 , loss : 6.995090007781982\n",
      "iteration : 163 , loss : 7.012381076812744\n",
      "iteration : 164 , loss : 6.979513645172119\n",
      "iteration : 165 , loss : 6.830020904541016\n",
      "iteration : 166 , loss : 7.028848648071289\n",
      "iteration : 167 , loss : 6.898959636688232\n",
      "iteration : 168 , loss : 6.602540016174316\n",
      "iteration : 169 , loss : 6.7255473136901855\n",
      "iteration : 170 , loss : 6.804656028747559\n",
      "iteration : 171 , loss : 6.819108009338379\n",
      "iteration : 172 , loss : 6.8557586669921875\n",
      "iteration : 173 , loss : 7.004805564880371\n",
      "iteration : 174 , loss : 6.625221252441406\n",
      "iteration : 175 , loss : 6.9518351554870605\n",
      "iteration : 176 , loss : 6.866561412811279\n",
      "iteration : 177 , loss : 6.702986240386963\n",
      "iteration : 178 , loss : 6.8133544921875\n",
      "iteration : 179 , loss : 6.949211120605469\n",
      "iteration : 180 , loss : 7.067959308624268\n",
      "iteration : 181 , loss : 6.868814945220947\n",
      "iteration : 182 , loss : 6.96909761428833\n",
      "iteration : 183 , loss : 6.732810020446777\n",
      "iteration : 184 , loss : 6.572860240936279\n",
      "iteration : 185 , loss : 6.712955474853516\n",
      "iteration : 186 , loss : 6.86795711517334\n",
      "iteration : 187 , loss : 6.921563625335693\n",
      "iteration : 188 , loss : 6.728801727294922\n",
      "iteration : 189 , loss : 6.801579475402832\n",
      "iteration : 190 , loss : 6.668130874633789\n",
      "iteration : 191 , loss : 6.8325419425964355\n",
      "iteration : 192 , loss : 6.935441017150879\n",
      "iteration : 193 , loss : 6.624192714691162\n",
      "iteration : 194 , loss : 6.657224178314209\n",
      "iteration : 195 , loss : 6.566450595855713\n",
      "iteration : 196 , loss : 6.541702747344971\n",
      "iteration : 197 , loss : 6.514719009399414\n",
      "iteration : 198 , loss : 6.634617805480957\n",
      "iteration : 199 , loss : 6.656484603881836\n",
      "iteration : 200 , loss : 6.655729293823242\n",
      "iteration : 201 , loss : 6.543543338775635\n",
      "iteration : 202 , loss : 6.677812099456787\n",
      "iteration : 203 , loss : 6.704550743103027\n",
      "iteration : 204 , loss : 6.68161153793335\n",
      "iteration : 205 , loss : 6.59950065612793\n",
      "iteration : 206 , loss : 6.44018030166626\n",
      "iteration : 207 , loss : 6.440955638885498\n",
      "iteration : 208 , loss : 6.505262851715088\n",
      "iteration : 209 , loss : 6.5777997970581055\n",
      "iteration : 210 , loss : 6.819590091705322\n",
      "iteration : 211 , loss : 6.500345706939697\n",
      "iteration : 212 , loss : 6.63323450088501\n",
      "iteration : 213 , loss : 6.662027359008789\n",
      "iteration : 214 , loss : 6.660158157348633\n",
      "iteration : 215 , loss : 6.660062313079834\n",
      "iteration : 216 , loss : 6.583262920379639\n",
      "iteration : 217 , loss : 6.571277618408203\n",
      "iteration : 218 , loss : 6.4785356521606445\n",
      "iteration : 219 , loss : 6.616118907928467\n",
      "iteration : 220 , loss : 6.5261335372924805\n",
      "iteration : 221 , loss : 6.5413594245910645\n",
      "iteration : 222 , loss : 6.793883323669434\n",
      "iteration : 223 , loss : 6.7445831298828125\n",
      "iteration : 224 , loss : 6.509694576263428\n",
      "iteration : 225 , loss : 6.650312900543213\n",
      "iteration : 226 , loss : 6.346210956573486\n",
      "iteration : 227 , loss : 6.573509216308594\n",
      "iteration : 228 , loss : 6.443655967712402\n",
      "iteration : 229 , loss : 6.485351085662842\n",
      "iteration : 230 , loss : 6.420233249664307\n",
      "iteration : 231 , loss : 6.498229026794434\n",
      "iteration : 232 , loss : 6.529494285583496\n",
      "iteration : 233 , loss : 6.485107898712158\n",
      "iteration : 234 , loss : 6.5117363929748535\n",
      "iteration : 235 , loss : 6.602249622344971\n",
      "iteration : 236 , loss : 6.389455795288086\n",
      "iteration : 237 , loss : 6.613281726837158\n",
      "iteration : 238 , loss : 6.371433734893799\n",
      "iteration : 239 , loss : 6.571885108947754\n",
      "iteration : 240 , loss : 6.34160041809082\n",
      "iteration : 241 , loss : 6.391046524047852\n",
      "iteration : 242 , loss : 6.4545440673828125\n",
      "iteration : 243 , loss : 6.449047565460205\n",
      "iteration : 244 , loss : 6.3341803550720215\n",
      "iteration : 245 , loss : 6.6779866218566895\n",
      "iteration : 246 , loss : 6.398719310760498\n",
      "iteration : 247 , loss : 6.602658271789551\n",
      "iteration : 248 , loss : 6.533905029296875\n",
      "iteration : 249 , loss : 6.258270740509033\n",
      "iteration : 250 , loss : 6.179215431213379\n",
      "iteration : 251 , loss : 6.398626804351807\n",
      "iteration : 252 , loss : 6.293182849884033\n",
      "iteration : 253 , loss : 6.491863250732422\n",
      "iteration : 254 , loss : 6.206335067749023\n",
      "iteration : 255 , loss : 6.239810466766357\n",
      "iteration : 256 , loss : 6.361405372619629\n",
      "iteration : 257 , loss : 6.1924333572387695\n",
      "iteration : 258 , loss : 6.58481502532959\n",
      "iteration : 259 , loss : 6.442257404327393\n",
      "iteration : 260 , loss : 6.363375186920166\n",
      "iteration : 261 , loss : 6.1617889404296875\n",
      "iteration : 262 , loss : 6.3595147132873535\n",
      "iteration : 263 , loss : 6.419991493225098\n",
      "iteration : 264 , loss : 6.410820484161377\n",
      "iteration : 265 , loss : 6.370640754699707\n",
      "iteration : 266 , loss : 6.380466938018799\n",
      "iteration : 267 , loss : 6.399906635284424\n",
      "iteration : 268 , loss : 6.10066556930542\n",
      "iteration : 269 , loss : 6.074660778045654\n",
      "iteration : 270 , loss : 6.084973335266113\n",
      "iteration : 271 , loss : 6.303544044494629\n",
      "iteration : 272 , loss : 6.201457500457764\n",
      "iteration : 273 , loss : 6.12367057800293\n",
      "iteration : 274 , loss : 6.199526309967041\n",
      "iteration : 275 , loss : 6.3170270919799805\n",
      "iteration : 276 , loss : 6.3005876541137695\n",
      "iteration : 277 , loss : 6.271103858947754\n",
      "iteration : 278 , loss : 6.294487953186035\n",
      "iteration : 279 , loss : 6.1803975105285645\n",
      "iteration : 280 , loss : 6.281791687011719\n",
      "iteration : 281 , loss : 6.321738243103027\n",
      "iteration : 282 , loss : 6.355590343475342\n",
      "iteration : 283 , loss : 6.155680179595947\n",
      "iteration : 284 , loss : 6.213520050048828\n",
      "iteration : 285 , loss : 6.16440486907959\n",
      "iteration : 286 , loss : 6.459636211395264\n",
      "iteration : 287 , loss : 6.333178520202637\n",
      "iteration : 288 , loss : 5.9232401847839355\n",
      "iteration : 289 , loss : 5.937787055969238\n",
      "iteration : 290 , loss : 6.232502460479736\n",
      "iteration : 291 , loss : 6.189055442810059\n",
      "iteration : 292 , loss : 6.2864532470703125\n",
      "iteration : 293 , loss : 6.144493103027344\n",
      "iteration : 294 , loss : 6.449975967407227\n",
      "iteration : 295 , loss : 6.067389011383057\n",
      "iteration : 296 , loss : 6.121676921844482\n",
      "iteration : 297 , loss : 6.1000895500183105\n",
      "iteration : 298 , loss : 5.838458061218262\n",
      "iteration : 299 , loss : 6.085475921630859\n",
      "iteration : 300 , loss : 6.067809581756592\n",
      "iteration : 301 , loss : 6.199159622192383\n",
      "iteration : 302 , loss : 6.183050155639648\n",
      "iteration : 303 , loss : 6.104618072509766\n",
      "iteration : 304 , loss : 5.989665508270264\n",
      "iteration : 305 , loss : 6.312453746795654\n",
      "iteration : 306 , loss : 6.1650710105896\n",
      "iteration : 307 , loss : 5.962551593780518\n",
      "iteration : 308 , loss : 5.898632526397705\n",
      "iteration : 309 , loss : 6.200101375579834\n",
      "iteration : 310 , loss : 5.885875701904297\n",
      "iteration : 311 , loss : 6.221216678619385\n",
      "iteration : 312 , loss : 6.142545700073242\n",
      "iteration : 313 , loss : 6.213888645172119\n",
      "iteration : 314 , loss : 6.166183948516846\n",
      "iteration : 315 , loss : 6.323057651519775\n",
      "iteration : 316 , loss : 5.957550048828125\n",
      "iteration : 317 , loss : 6.024080276489258\n",
      "iteration : 318 , loss : 6.029542446136475\n",
      "iteration : 319 , loss : 5.934924125671387\n",
      "iteration : 320 , loss : 6.044966220855713\n",
      "iteration : 321 , loss : 6.476763725280762\n",
      "iteration : 322 , loss : 5.718358039855957\n",
      "iteration : 323 , loss : 5.990398406982422\n",
      "iteration : 324 , loss : 5.9312334060668945\n",
      "iteration : 325 , loss : 6.009240627288818\n",
      "iteration : 326 , loss : 6.037470817565918\n",
      "iteration : 327 , loss : 5.7256388664245605\n",
      "iteration : 328 , loss : 5.970521450042725\n",
      "iteration : 329 , loss : 5.934023380279541\n",
      "iteration : 330 , loss : 5.989717960357666\n",
      "iteration : 331 , loss : 6.149357795715332\n",
      "iteration : 332 , loss : 5.997247695922852\n",
      "iteration : 333 , loss : 6.221102714538574\n",
      "iteration : 334 , loss : 6.1293511390686035\n",
      "iteration : 335 , loss : 6.114431858062744\n",
      "iteration : 336 , loss : 5.8175153732299805\n",
      "iteration : 337 , loss : 6.141976356506348\n",
      "iteration : 338 , loss : 6.064145565032959\n",
      "iteration : 339 , loss : 5.833775997161865\n",
      "iteration : 340 , loss : 5.943253040313721\n",
      "iteration : 341 , loss : 5.854141712188721\n",
      "iteration : 342 , loss : 5.869171619415283\n",
      "iteration : 343 , loss : 5.908975601196289\n",
      "iteration : 344 , loss : 5.858658790588379\n",
      "iteration : 345 , loss : 6.281421184539795\n",
      "iteration : 346 , loss : 5.81960391998291\n",
      "iteration : 347 , loss : 6.096841812133789\n",
      "iteration : 348 , loss : 5.912128925323486\n",
      "iteration : 349 , loss : 5.88433313369751\n",
      "iteration : 350 , loss : 6.039790630340576\n",
      "iteration : 351 , loss : 5.731836318969727\n",
      "iteration : 352 , loss : 6.097357749938965\n",
      "iteration : 353 , loss : 5.803648948669434\n",
      "iteration : 354 , loss : 5.716958999633789\n",
      "iteration : 355 , loss : 5.916100025177002\n",
      "iteration : 356 , loss : 5.756145000457764\n",
      "iteration : 357 , loss : 6.114635944366455\n",
      "iteration : 358 , loss : 5.73820161819458\n",
      "iteration : 359 , loss : 5.791192054748535\n",
      "iteration : 360 , loss : 6.001373291015625\n",
      "iteration : 361 , loss : 5.754499912261963\n",
      "iteration : 362 , loss : 6.043210983276367\n",
      "iteration : 363 , loss : 5.689901828765869\n",
      "iteration : 364 , loss : 6.115314483642578\n",
      "iteration : 365 , loss : 5.8768134117126465\n",
      "iteration : 366 , loss : 5.725707054138184\n",
      "iteration : 367 , loss : 5.775081157684326\n",
      "iteration : 368 , loss : 5.9185004234313965\n",
      "iteration : 369 , loss : 5.9923810958862305\n",
      "iteration : 370 , loss : 5.7581257820129395\n",
      "iteration : 371 , loss : 5.688466548919678\n",
      "iteration : 372 , loss : 5.812314510345459\n",
      "iteration : 373 , loss : 5.911254405975342\n",
      "iteration : 374 , loss : 5.560161590576172\n",
      "iteration : 375 , loss : 5.883486270904541\n",
      "iteration : 376 , loss : 5.838472366333008\n",
      "iteration : 377 , loss : 5.7962565422058105\n",
      "iteration : 378 , loss : 5.6583251953125\n",
      "iteration : 379 , loss : 5.564436912536621\n",
      "iteration : 380 , loss : 5.857303619384766\n",
      "iteration : 381 , loss : 5.98307466506958\n",
      "iteration : 382 , loss : 5.80251407623291\n",
      "iteration : 383 , loss : 5.429347991943359\n",
      "iteration : 384 , loss : 5.945001602172852\n",
      "iteration : 385 , loss : 5.591577053070068\n",
      "iteration : 386 , loss : 5.758998870849609\n",
      "iteration : 387 , loss : 5.839274883270264\n",
      "iteration : 388 , loss : 5.984738349914551\n",
      "iteration : 389 , loss : 5.56558895111084\n",
      "iteration : 390 , loss : 5.629720687866211\n",
      "iteration : 391 , loss : 5.673055648803711\n",
      "iteration : 392 , loss : 5.6454033851623535\n",
      "iteration : 393 , loss : 5.8111467361450195\n",
      "iteration : 394 , loss : 5.650227069854736\n",
      "iteration : 395 , loss : 5.82908296585083\n",
      "iteration : 396 , loss : 5.363521575927734\n",
      "iteration : 397 , loss : 5.768472671508789\n",
      "iteration : 398 , loss : 5.634068012237549\n",
      "iteration : 399 , loss : 5.710007667541504\n",
      "iteration : 400 , loss : 5.745069980621338\n",
      "iteration : 401 , loss : 5.865915298461914\n",
      "iteration : 402 , loss : 5.7257890701293945\n",
      "iteration : 403 , loss : 5.7815327644348145\n",
      "iteration : 404 , loss : 5.758569240570068\n",
      "iteration : 405 , loss : 5.565704822540283\n",
      "iteration : 406 , loss : 5.691560745239258\n",
      "iteration : 407 , loss : 5.826323509216309\n",
      "iteration : 408 , loss : 5.487448692321777\n",
      "iteration : 409 , loss : 5.577320575714111\n",
      "iteration : 410 , loss : 5.4369120597839355\n",
      "iteration : 411 , loss : 5.93864631652832\n",
      "iteration : 412 , loss : 5.734761714935303\n",
      "iteration : 413 , loss : 5.751926422119141\n",
      "iteration : 414 , loss : 5.517214298248291\n",
      "iteration : 415 , loss : 5.608343124389648\n",
      "iteration : 416 , loss : 5.412655353546143\n",
      "iteration : 417 , loss : 5.53588342666626\n",
      "iteration : 418 , loss : 5.761630058288574\n",
      "iteration : 419 , loss : 5.674795627593994\n",
      "iteration : 420 , loss : 5.314517974853516\n",
      "iteration : 421 , loss : 5.776373386383057\n",
      "iteration : 422 , loss : 5.443401336669922\n",
      "iteration : 423 , loss : 5.698652267456055\n",
      "iteration : 424 , loss : 5.613341331481934\n",
      "iteration : 425 , loss : 5.572206974029541\n",
      "iteration : 426 , loss : 5.6073408126831055\n",
      "iteration : 427 , loss : 5.735662937164307\n",
      "iteration : 428 , loss : 5.4966254234313965\n",
      "iteration : 429 , loss : 5.859679222106934\n",
      "iteration : 430 , loss : 5.744384765625\n",
      "iteration : 431 , loss : 5.661710739135742\n",
      "iteration : 432 , loss : 5.700438499450684\n",
      "iteration : 433 , loss : 5.470484256744385\n",
      "iteration : 434 , loss : 5.723965644836426\n",
      "iteration : 435 , loss : 5.660849094390869\n",
      "iteration : 436 , loss : 5.294104099273682\n",
      "iteration : 437 , loss : 5.830533027648926\n",
      "iteration : 438 , loss : 5.585263729095459\n",
      "iteration : 439 , loss : 5.689604759216309\n",
      "iteration : 440 , loss : 5.42444372177124\n",
      "iteration : 441 , loss : 5.5675835609436035\n",
      "iteration : 442 , loss : 5.713015079498291\n",
      "iteration : 443 , loss : 5.485201358795166\n",
      "iteration : 444 , loss : 5.785113334655762\n",
      "iteration : 445 , loss : 5.563663005828857\n",
      "iteration : 446 , loss : 5.758795738220215\n",
      "iteration : 447 , loss : 5.712305068969727\n",
      "iteration : 448 , loss : 5.501031398773193\n",
      "iteration : 449 , loss : 5.5940327644348145\n",
      "iteration : 450 , loss : 5.472072601318359\n",
      "iteration : 451 , loss : 5.736542701721191\n",
      "iteration : 452 , loss : 5.711726188659668\n",
      "iteration : 453 , loss : 5.702253818511963\n",
      "iteration : 454 , loss : 5.743048667907715\n",
      "iteration : 455 , loss : 5.590727806091309\n",
      "iteration : 456 , loss : 5.284319877624512\n",
      "iteration : 457 , loss : 5.471702575683594\n",
      "iteration : 458 , loss : 5.495180130004883\n",
      "iteration : 459 , loss : 5.386778354644775\n",
      "iteration : 460 , loss : 5.512024402618408\n",
      "iteration : 461 , loss : 5.5346150398254395\n",
      "iteration : 462 , loss : 5.594832897186279\n",
      "iteration : 463 , loss : 5.496753692626953\n",
      "iteration : 464 , loss : 5.344997406005859\n",
      "iteration : 465 , loss : 5.6481475830078125\n",
      "iteration : 466 , loss : 5.596935272216797\n",
      "iteration : 467 , loss : 5.608041286468506\n",
      "iteration : 468 , loss : 5.476444244384766\n",
      "iteration : 469 , loss : 5.348393440246582\n",
      "iteration : 470 , loss : 5.6040472984313965\n",
      "iteration : 471 , loss : 5.51878023147583\n",
      "iteration : 472 , loss : 5.180960655212402\n",
      "iteration : 473 , loss : 5.656346797943115\n",
      "iteration : 474 , loss : 5.466302871704102\n",
      "iteration : 475 , loss : 5.761197090148926\n",
      "iteration : 476 , loss : 5.51643705368042\n",
      "iteration : 477 , loss : 5.472221851348877\n",
      "iteration : 478 , loss : 5.5269598960876465\n",
      "iteration : 479 , loss : 5.461230278015137\n",
      "iteration : 480 , loss : 5.340563774108887\n",
      "iteration : 481 , loss : 5.506333827972412\n",
      "iteration : 482 , loss : 5.510606288909912\n",
      "iteration : 483 , loss : 5.271701812744141\n",
      "iteration : 484 , loss : 5.399847030639648\n",
      "iteration : 485 , loss : 5.691335201263428\n",
      "iteration : 486 , loss : 5.743285179138184\n",
      "iteration : 487 , loss : 5.465176105499268\n",
      "iteration : 488 , loss : 5.405474662780762\n",
      "iteration : 489 , loss : 5.595432281494141\n",
      "iteration : 490 , loss : 5.463044166564941\n",
      "iteration : 491 , loss : 5.668746471405029\n",
      "iteration : 492 , loss : 5.250405311584473\n",
      "iteration : 493 , loss : 5.783447265625\n",
      "iteration : 494 , loss : 5.034278392791748\n",
      "iteration : 495 , loss : 5.671566486358643\n",
      "iteration : 496 , loss : 5.464872360229492\n",
      "iteration : 497 , loss : 4.8618268966674805\n",
      "iteration : 498 , loss : 5.375495910644531\n",
      "iteration : 499 , loss : 5.235439777374268\n",
      "iteration : 500 , loss : 5.7482500076293945\n",
      "iteration : 501 , loss : 5.639331817626953\n",
      "iteration : 502 , loss : 5.296101093292236\n",
      "iteration : 503 , loss : 5.039877891540527\n",
      "iteration : 504 , loss : 5.465741157531738\n",
      "iteration : 505 , loss : 5.615145683288574\n",
      "iteration : 506 , loss : 5.620104789733887\n",
      "iteration : 507 , loss : 5.350923538208008\n",
      "iteration : 508 , loss : 5.554388999938965\n",
      "iteration : 509 , loss : 5.546719074249268\n",
      "iteration : 510 , loss : 5.673027515411377\n",
      "iteration : 511 , loss : 5.4744038581848145\n",
      "iteration : 512 , loss : 5.435555458068848\n",
      "iteration : 513 , loss : 5.421553134918213\n",
      "iteration : 514 , loss : 5.183810710906982\n",
      "iteration : 515 , loss : 5.6517863273620605\n",
      "iteration : 516 , loss : 5.785095691680908\n",
      "iteration : 517 , loss : 5.496693134307861\n",
      "iteration : 518 , loss : 5.234114646911621\n",
      "iteration : 519 , loss : 5.422054767608643\n",
      "iteration : 520 , loss : 5.539295196533203\n",
      "iteration : 521 , loss : 5.4058613777160645\n",
      "iteration : 522 , loss : 5.242587566375732\n",
      "iteration : 523 , loss : 5.191798686981201\n",
      "iteration : 524 , loss : 5.171875\n",
      "iteration : 525 , loss : 5.547304630279541\n",
      "iteration : 526 , loss : 5.458580017089844\n",
      "iteration : 527 , loss : 5.406890869140625\n",
      "iteration : 528 , loss : 5.280194282531738\n",
      "iteration : 529 , loss : 5.252136707305908\n",
      "iteration : 530 , loss : 5.171119213104248\n",
      "iteration : 531 , loss : 5.344916820526123\n",
      "iteration : 532 , loss : 5.390806674957275\n",
      "iteration : 533 , loss : 5.317135810852051\n",
      "iteration : 534 , loss : 5.145146369934082\n",
      "iteration : 535 , loss : 5.483567714691162\n",
      "iteration : 536 , loss : 5.359038352966309\n",
      "iteration : 537 , loss : 5.255727767944336\n",
      "iteration : 538 , loss : 5.381350994110107\n",
      "iteration : 539 , loss : 5.320903778076172\n",
      "iteration : 540 , loss : 5.514413833618164\n",
      "iteration : 541 , loss : 5.05264949798584\n",
      "iteration : 542 , loss : 5.5748677253723145\n",
      "iteration : 543 , loss : 5.502532005310059\n",
      "iteration : 544 , loss : 5.61715030670166\n",
      "iteration : 545 , loss : 5.450057506561279\n",
      "iteration : 546 , loss : 5.313773155212402\n",
      "iteration : 547 , loss : 5.512148380279541\n",
      "iteration : 548 , loss : 5.40707540512085\n",
      "iteration : 549 , loss : 5.452162265777588\n",
      "iteration : 550 , loss : 5.394059658050537\n",
      "iteration : 551 , loss : 5.1778035163879395\n",
      "iteration : 552 , loss : 5.406087875366211\n",
      "iteration : 553 , loss : 5.16642951965332\n",
      "iteration : 554 , loss : 5.277563095092773\n",
      "iteration : 555 , loss : 5.484123706817627\n",
      "iteration : 556 , loss : 5.256618499755859\n",
      "iteration : 557 , loss : 5.400365829467773\n",
      "iteration : 558 , loss : 5.154545783996582\n",
      "iteration : 559 , loss : 5.1946611404418945\n",
      "iteration : 560 , loss : 5.568708419799805\n",
      "iteration : 561 , loss : 5.088840007781982\n",
      "iteration : 562 , loss : 5.200990200042725\n",
      "iteration : 563 , loss : 5.368462085723877\n",
      "iteration : 564 , loss : 5.321633338928223\n",
      "iteration : 565 , loss : 5.1306538581848145\n",
      "iteration : 566 , loss : 5.297085762023926\n",
      "iteration : 567 , loss : 5.067041873931885\n",
      "iteration : 568 , loss : 5.469909191131592\n",
      "iteration : 569 , loss : 5.644871234893799\n",
      "iteration : 570 , loss : 5.055266380310059\n",
      "iteration : 571 , loss : 5.096222877502441\n",
      "iteration : 572 , loss : 5.104897499084473\n",
      "iteration : 573 , loss : 5.152117729187012\n",
      "iteration : 574 , loss : 5.165043830871582\n",
      "iteration : 575 , loss : 5.027996063232422\n",
      "iteration : 576 , loss : 5.173431873321533\n",
      "iteration : 577 , loss : 5.247711658477783\n",
      "iteration : 578 , loss : 5.234195709228516\n",
      "iteration : 579 , loss : 5.2300262451171875\n",
      "iteration : 580 , loss : 5.694044589996338\n",
      "iteration : 581 , loss : 5.058250427246094\n",
      "iteration : 582 , loss : 5.294178485870361\n",
      "iteration : 583 , loss : 5.213677406311035\n",
      "iteration : 584 , loss : 5.1079421043396\n",
      "iteration : 585 , loss : 5.151772975921631\n",
      "iteration : 586 , loss : 5.281203269958496\n",
      "iteration : 587 , loss : 5.238851070404053\n",
      "iteration : 588 , loss : 4.908269882202148\n",
      "iteration : 589 , loss : 4.9863786697387695\n",
      "iteration : 590 , loss : 5.619533061981201\n",
      "iteration : 591 , loss : 5.101365089416504\n",
      "iteration : 592 , loss : 5.0340962409973145\n",
      "iteration : 593 , loss : 5.458366870880127\n",
      "iteration : 594 , loss : 5.314225673675537\n",
      "iteration : 595 , loss : 5.008267402648926\n",
      "iteration : 596 , loss : 5.584414482116699\n",
      "iteration : 597 , loss : 5.3728227615356445\n",
      "iteration : 598 , loss : 5.286561489105225\n",
      "iteration : 599 , loss : 5.330765247344971\n",
      "iteration : 600 , loss : 5.379045009613037\n",
      "iteration : 601 , loss : 5.308300495147705\n",
      "iteration : 602 , loss : 5.0521039962768555\n",
      "iteration : 603 , loss : 5.2396345138549805\n",
      "iteration : 604 , loss : 5.080236434936523\n",
      "iteration : 605 , loss : 4.973154067993164\n",
      "iteration : 606 , loss : 4.941762447357178\n",
      "iteration : 607 , loss : 5.035640716552734\n",
      "iteration : 608 , loss : 5.085557460784912\n",
      "iteration : 609 , loss : 5.1122355461120605\n",
      "iteration : 610 , loss : 5.108598709106445\n",
      "iteration : 611 , loss : 5.277920246124268\n",
      "iteration : 612 , loss : 5.155694484710693\n",
      "iteration : 613 , loss : 5.080441951751709\n",
      "iteration : 614 , loss : 5.252295970916748\n",
      "iteration : 615 , loss : 5.136845588684082\n",
      "iteration : 616 , loss : 5.2502055168151855\n",
      "iteration : 617 , loss : 5.145692348480225\n",
      "iteration : 618 , loss : 5.33072566986084\n",
      "iteration : 619 , loss : 5.041524887084961\n",
      "iteration : 620 , loss : 5.430051326751709\n",
      "iteration : 621 , loss : 5.519222259521484\n",
      "iteration : 622 , loss : 5.1315765380859375\n",
      "iteration : 623 , loss : 5.381186008453369\n",
      "iteration : 624 , loss : 5.082530498504639\n",
      "iteration : 625 , loss : 5.042287349700928\n",
      "iteration : 626 , loss : 5.089941024780273\n",
      "iteration : 627 , loss : 5.039646148681641\n",
      "iteration : 628 , loss : 5.245586395263672\n",
      "iteration : 629 , loss : 5.016676425933838\n",
      "iteration : 630 , loss : 4.943907737731934\n",
      "iteration : 631 , loss : 5.3120198249816895\n",
      "iteration : 632 , loss : 5.216722011566162\n",
      "iteration : 633 , loss : 5.094547748565674\n",
      "iteration : 634 , loss : 5.14881706237793\n",
      "iteration : 635 , loss : 5.253982067108154\n",
      "iteration : 636 , loss : 5.304932117462158\n",
      "iteration : 637 , loss : 5.114932060241699\n",
      "iteration : 638 , loss : 5.258399486541748\n",
      "iteration : 639 , loss : 5.119152069091797\n",
      "iteration : 640 , loss : 4.876194477081299\n",
      "iteration : 641 , loss : 5.257377624511719\n",
      "iteration : 642 , loss : 5.2924370765686035\n",
      "iteration : 643 , loss : 5.020600318908691\n",
      "iteration : 644 , loss : 5.114744663238525\n",
      "iteration : 645 , loss : 4.92198371887207\n",
      "iteration : 646 , loss : 5.100894927978516\n",
      "iteration : 647 , loss : 5.051090717315674\n",
      "iteration : 648 , loss : 5.058811664581299\n",
      "iteration : 649 , loss : 4.976318359375\n",
      "iteration : 650 , loss : 5.090259552001953\n",
      "iteration : 651 , loss : 5.084261894226074\n",
      "iteration : 652 , loss : 5.016366481781006\n",
      "iteration : 653 , loss : 5.06970739364624\n",
      "iteration : 654 , loss : 4.757579326629639\n",
      "iteration : 655 , loss : 4.943117141723633\n",
      "iteration : 656 , loss : 5.124598979949951\n",
      "iteration : 657 , loss : 5.197700500488281\n",
      "iteration : 658 , loss : 5.164180278778076\n",
      "iteration : 659 , loss : 4.948570728302002\n",
      "iteration : 660 , loss : 5.091179847717285\n",
      "iteration : 661 , loss : 5.004189491271973\n",
      "iteration : 662 , loss : 4.799665927886963\n",
      "iteration : 663 , loss : 5.152706146240234\n",
      "iteration : 664 , loss : 5.2274298667907715\n",
      "iteration : 665 , loss : 5.103266716003418\n",
      "iteration : 666 , loss : 4.818648815155029\n",
      "iteration : 667 , loss : 5.1501970291137695\n",
      "iteration : 668 , loss : 4.768630027770996\n",
      "iteration : 669 , loss : 5.1860151290893555\n",
      "iteration : 670 , loss : 5.169821739196777\n",
      "iteration : 671 , loss : 4.788124084472656\n",
      "iteration : 672 , loss : 5.287618637084961\n",
      "iteration : 673 , loss : 5.194360256195068\n",
      "iteration : 674 , loss : 5.025390148162842\n",
      "iteration : 675 , loss : 5.365053176879883\n",
      "iteration : 676 , loss : 5.073467254638672\n",
      "iteration : 677 , loss : 5.077085018157959\n",
      "iteration : 678 , loss : 5.086888313293457\n",
      "iteration : 679 , loss : 4.946246147155762\n",
      "iteration : 680 , loss : 5.245449542999268\n",
      "iteration : 681 , loss : 5.216341018676758\n",
      "iteration : 682 , loss : 5.22227144241333\n",
      "iteration : 683 , loss : 5.01036262512207\n",
      "iteration : 684 , loss : 4.881101608276367\n",
      "iteration : 685 , loss : 5.050004959106445\n",
      "iteration : 686 , loss : 4.747370719909668\n",
      "iteration : 687 , loss : 4.735567092895508\n",
      "iteration : 688 , loss : 4.884202003479004\n",
      "iteration : 689 , loss : 5.230922222137451\n",
      "iteration : 690 , loss : 5.516465663909912\n",
      "iteration : 691 , loss : 5.064497947692871\n",
      "iteration : 692 , loss : 4.7715253829956055\n",
      "iteration : 693 , loss : 4.9673380851745605\n",
      "iteration : 694 , loss : 4.834295272827148\n",
      "iteration : 695 , loss : 5.195082187652588\n",
      "iteration : 696 , loss : 4.992129802703857\n",
      "iteration : 697 , loss : 4.862056255340576\n",
      "iteration : 698 , loss : 5.117321014404297\n",
      "iteration : 699 , loss : 4.7477216720581055\n",
      "iteration : 700 , loss : 4.978670597076416\n",
      "iteration : 701 , loss : 4.922109127044678\n",
      "iteration : 702 , loss : 5.095158576965332\n",
      "iteration : 703 , loss : 5.550043106079102\n",
      "iteration : 704 , loss : 5.125802040100098\n",
      "iteration : 705 , loss : 5.110611915588379\n",
      "iteration : 706 , loss : 5.003599166870117\n",
      "iteration : 707 , loss : 5.144476890563965\n",
      "iteration : 708 , loss : 5.201252460479736\n",
      "iteration : 709 , loss : 5.249500751495361\n",
      "iteration : 710 , loss : 5.006383419036865\n",
      "iteration : 711 , loss : 5.000787734985352\n",
      "iteration : 712 , loss : 5.2924699783325195\n",
      "iteration : 713 , loss : 5.0389723777771\n",
      "iteration : 714 , loss : 5.088041305541992\n",
      "iteration : 715 , loss : 4.815479755401611\n",
      "iteration : 716 , loss : 5.124868392944336\n",
      "iteration : 717 , loss : 5.102867126464844\n",
      "iteration : 718 , loss : 4.863648891448975\n",
      "iteration : 719 , loss : 5.140895366668701\n",
      "iteration : 720 , loss : 4.850465297698975\n",
      "iteration : 721 , loss : 5.03610897064209\n",
      "iteration : 722 , loss : 4.966184616088867\n",
      "iteration : 723 , loss : 5.1306657791137695\n",
      "iteration : 724 , loss : 5.054179668426514\n",
      "iteration : 725 , loss : 4.5968451499938965\n",
      "iteration : 726 , loss : 5.064964294433594\n",
      "iteration : 727 , loss : 5.114266395568848\n",
      "iteration : 728 , loss : 4.769346714019775\n",
      "iteration : 729 , loss : 4.916449069976807\n",
      "iteration : 730 , loss : 5.06158971786499\n",
      "iteration : 731 , loss : 5.050657749176025\n",
      "iteration : 732 , loss : 5.24327278137207\n",
      "iteration : 733 , loss : 5.228413105010986\n",
      "iteration : 734 , loss : 4.945201873779297\n",
      "iteration : 735 , loss : 4.876125335693359\n",
      "iteration : 736 , loss : 4.671384334564209\n",
      "iteration : 737 , loss : 4.961763381958008\n",
      "iteration : 738 , loss : 4.881267547607422\n",
      "iteration : 739 , loss : 5.123157978057861\n",
      "iteration : 740 , loss : 4.9886040687561035\n",
      "iteration : 741 , loss : 5.218810081481934\n",
      "iteration : 742 , loss : 5.066066741943359\n",
      "iteration : 743 , loss : 4.762907028198242\n",
      "iteration : 744 , loss : 5.070800304412842\n",
      "iteration : 745 , loss : 4.92918062210083\n",
      "iteration : 746 , loss : 4.823537349700928\n",
      "iteration : 747 , loss : 4.976438999176025\n",
      "iteration : 748 , loss : 4.800764560699463\n",
      "iteration : 749 , loss : 4.7451491355896\n",
      "iteration : 750 , loss : 4.728410720825195\n",
      "iteration : 751 , loss : 5.002028465270996\n",
      "iteration : 752 , loss : 4.992347240447998\n",
      "iteration : 753 , loss : 4.987971782684326\n",
      "iteration : 754 , loss : 4.902837753295898\n",
      "iteration : 755 , loss : 4.9058518409729\n",
      "iteration : 756 , loss : 4.944334030151367\n",
      "iteration : 757 , loss : 5.146801471710205\n",
      "iteration : 758 , loss : 5.006338119506836\n",
      "iteration : 759 , loss : 4.801419258117676\n",
      "iteration : 760 , loss : 4.863520622253418\n",
      "iteration : 761 , loss : 4.966646671295166\n",
      "iteration : 762 , loss : 5.024653434753418\n",
      "iteration : 763 , loss : 4.885706424713135\n",
      "iteration : 764 , loss : 4.903111934661865\n",
      "iteration : 765 , loss : 5.200194835662842\n",
      "iteration : 766 , loss : 4.8575334548950195\n",
      "iteration : 767 , loss : 5.051544666290283\n",
      "iteration : 768 , loss : 4.951982021331787\n",
      "iteration : 769 , loss : 4.762812614440918\n",
      "iteration : 770 , loss : 4.93190336227417\n",
      "iteration : 771 , loss : 5.118325710296631\n",
      "iteration : 772 , loss : 4.77282190322876\n",
      "iteration : 773 , loss : 4.933960437774658\n",
      "iteration : 774 , loss : 4.997832775115967\n",
      "iteration : 775 , loss : 4.983548641204834\n",
      "iteration : 776 , loss : 4.742225170135498\n",
      "iteration : 777 , loss : 4.994108200073242\n",
      "iteration : 778 , loss : 4.857516288757324\n",
      "iteration : 779 , loss : 4.8643598556518555\n",
      "iteration : 780 , loss : 4.802649974822998\n",
      "iteration : 781 , loss : 4.911870002746582\n",
      "iteration : 782 , loss : 5.062131881713867\n",
      "iteration : 783 , loss : 4.72698974609375\n",
      "iteration : 784 , loss : 5.036289215087891\n",
      "iteration : 785 , loss : 4.834874153137207\n",
      "iteration : 786 , loss : 4.837291240692139\n",
      "iteration : 787 , loss : 4.856441974639893\n",
      "iteration : 788 , loss : 4.738097667694092\n",
      "iteration : 789 , loss : 4.8575239181518555\n",
      "iteration : 790 , loss : 4.726747989654541\n",
      "iteration : 791 , loss : 4.691586971282959\n",
      "iteration : 792 , loss : 4.88252592086792\n",
      "iteration : 793 , loss : 5.210339546203613\n",
      "iteration : 794 , loss : 4.988830089569092\n",
      "iteration : 795 , loss : 4.803852558135986\n",
      "iteration : 796 , loss : 4.888106822967529\n",
      "iteration : 797 , loss : 4.801087379455566\n",
      "iteration : 798 , loss : 4.527856826782227\n",
      "iteration : 799 , loss : 4.886908531188965\n",
      "iteration : 800 , loss : 4.987259864807129\n",
      "iteration : 801 , loss : 5.01387357711792\n",
      "iteration : 802 , loss : 5.021431922912598\n",
      "iteration : 803 , loss : 4.9162187576293945\n",
      "iteration : 804 , loss : 5.252938747406006\n",
      "iteration : 805 , loss : 4.977358818054199\n",
      "iteration : 806 , loss : 4.779151439666748\n",
      "iteration : 807 , loss : 5.208720684051514\n",
      "iteration : 808 , loss : 5.005110740661621\n",
      "iteration : 809 , loss : 5.2220988273620605\n",
      "iteration : 810 , loss : 4.817955493927002\n",
      "iteration : 811 , loss : 4.803126811981201\n",
      "iteration : 812 , loss : 4.768058776855469\n",
      "iteration : 813 , loss : 4.983283042907715\n",
      "iteration : 814 , loss : 4.7752299308776855\n",
      "iteration : 815 , loss : 4.925573348999023\n",
      "iteration : 816 , loss : 5.034265995025635\n",
      "iteration : 817 , loss : 5.071200847625732\n",
      "iteration : 818 , loss : 4.920041084289551\n",
      "iteration : 819 , loss : 5.006891250610352\n",
      "iteration : 820 , loss : 4.994496822357178\n",
      "iteration : 821 , loss : 4.78924036026001\n",
      "iteration : 822 , loss : 4.930237293243408\n",
      "iteration : 823 , loss : 4.7347941398620605\n",
      "iteration : 824 , loss : 4.8503875732421875\n",
      "iteration : 825 , loss : 4.86082649230957\n",
      "iteration : 826 , loss : 4.772202968597412\n",
      "iteration : 827 , loss : 4.964899063110352\n",
      "iteration : 828 , loss : 4.6930832862854\n",
      "iteration : 829 , loss : 4.856410026550293\n",
      "iteration : 830 , loss : 5.026897430419922\n",
      "iteration : 831 , loss : 4.827630996704102\n",
      "iteration : 832 , loss : 4.913852214813232\n",
      "iteration : 833 , loss : 4.473211288452148\n",
      "iteration : 834 , loss : 4.59090518951416\n",
      "iteration : 835 , loss : 4.971709251403809\n",
      "iteration : 836 , loss : 4.787898063659668\n",
      "iteration : 837 , loss : 5.076712131500244\n",
      "iteration : 838 , loss : 4.735231876373291\n",
      "iteration : 839 , loss : 4.736853122711182\n",
      "iteration : 840 , loss : 4.9490556716918945\n",
      "iteration : 841 , loss : 5.115478515625\n",
      "iteration : 842 , loss : 5.204274654388428\n",
      "iteration : 843 , loss : 4.434146881103516\n",
      "iteration : 844 , loss : 4.68666410446167\n",
      "iteration : 845 , loss : 4.882882118225098\n",
      "iteration : 846 , loss : 4.8180975914001465\n",
      "iteration : 847 , loss : 4.675652027130127\n",
      "iteration : 848 , loss : 4.685532569885254\n",
      "iteration : 849 , loss : 4.813320636749268\n",
      "iteration : 850 , loss : 4.825520038604736\n",
      "iteration : 851 , loss : 4.902524471282959\n",
      "iteration : 852 , loss : 4.522243976593018\n",
      "iteration : 853 , loss : 4.640603542327881\n",
      "iteration : 854 , loss : 5.0292649269104\n",
      "iteration : 855 , loss : 4.728710651397705\n",
      "iteration : 856 , loss : 4.744577407836914\n",
      "iteration : 857 , loss : 4.605942726135254\n",
      "iteration : 858 , loss : 4.727464199066162\n",
      "iteration : 859 , loss : 4.7483439445495605\n",
      "iteration : 860 , loss : 4.738882064819336\n",
      "iteration : 861 , loss : 4.804143905639648\n",
      "iteration : 862 , loss : 4.834473609924316\n",
      "iteration : 863 , loss : 4.631887912750244\n",
      "iteration : 864 , loss : 4.7633209228515625\n",
      "iteration : 865 , loss : 4.512350559234619\n",
      "iteration : 866 , loss : 4.979142665863037\n",
      "iteration : 867 , loss : 4.879253387451172\n",
      "iteration : 868 , loss : 4.512024879455566\n",
      "iteration : 869 , loss : 4.775634765625\n",
      "iteration : 870 , loss : 4.5323028564453125\n",
      "iteration : 871 , loss : 5.390710830688477\n",
      "iteration : 872 , loss : 4.382238864898682\n",
      "iteration : 873 , loss : 4.9879584312438965\n",
      "iteration : 874 , loss : 4.868676662445068\n",
      "iteration : 875 , loss : 5.076633930206299\n",
      "iteration : 876 , loss : 4.878268718719482\n",
      "iteration : 877 , loss : 5.034753322601318\n",
      "iteration : 878 , loss : 4.743910789489746\n",
      "iteration : 879 , loss : 4.86055326461792\n",
      "iteration : 880 , loss : 4.669486999511719\n",
      "iteration : 881 , loss : 4.853703022003174\n",
      "iteration : 882 , loss : 4.73521614074707\n",
      "iteration : 883 , loss : 4.699179649353027\n",
      "iteration : 884 , loss : 4.6298675537109375\n",
      "iteration : 885 , loss : 4.914348602294922\n",
      "iteration : 886 , loss : 4.934600353240967\n",
      "iteration : 887 , loss : 4.767636775970459\n",
      "iteration : 888 , loss : 4.755166053771973\n",
      "iteration : 889 , loss : 4.723538398742676\n",
      "iteration : 890 , loss : 4.973415851593018\n",
      "iteration : 891 , loss : 4.886873722076416\n",
      "iteration : 892 , loss : 5.023080825805664\n",
      "iteration : 893 , loss : 4.815510272979736\n",
      "iteration : 894 , loss : 4.641448020935059\n",
      "iteration : 895 , loss : 4.765679836273193\n",
      "iteration : 896 , loss : 5.0511794090271\n",
      "iteration : 897 , loss : 4.7236785888671875\n",
      "iteration : 898 , loss : 4.478703498840332\n",
      "iteration : 899 , loss : 5.208098888397217\n",
      "iteration : 900 , loss : 4.685819149017334\n",
      "iteration : 901 , loss : 4.970839500427246\n",
      "iteration : 902 , loss : 4.84739875793457\n",
      "iteration : 903 , loss : 4.905486583709717\n",
      "iteration : 904 , loss : 4.936620235443115\n",
      "iteration : 905 , loss : 4.859063625335693\n",
      "iteration : 906 , loss : 4.502691745758057\n",
      "iteration : 907 , loss : 4.617963790893555\n",
      "iteration : 908 , loss : 4.861622333526611\n",
      "iteration : 909 , loss : 4.885284900665283\n",
      "iteration : 910 , loss : 4.890913486480713\n",
      "iteration : 911 , loss : 4.7958455085754395\n",
      "iteration : 912 , loss : 4.706747055053711\n",
      "iteration : 913 , loss : 4.532107830047607\n",
      "iteration : 914 , loss : 4.872158527374268\n",
      "iteration : 915 , loss : 4.704500198364258\n",
      "iteration : 916 , loss : 4.517385005950928\n",
      "iteration : 917 , loss : 4.7838521003723145\n",
      "iteration : 918 , loss : 4.874147415161133\n",
      "iteration : 919 , loss : 4.683255195617676\n",
      "iteration : 920 , loss : 4.7598419189453125\n",
      "iteration : 921 , loss : 4.751020908355713\n",
      "iteration : 922 , loss : 4.846848487854004\n",
      "iteration : 923 , loss : 4.537057876586914\n",
      "iteration : 924 , loss : 4.66382360458374\n",
      "iteration : 925 , loss : 4.87571907043457\n",
      "iteration : 926 , loss : 4.640117645263672\n",
      "iteration : 927 , loss : 4.846017360687256\n",
      "iteration : 928 , loss : 4.728642463684082\n",
      "iteration : 929 , loss : 4.70798397064209\n",
      "iteration : 930 , loss : 4.550216197967529\n",
      "iteration : 931 , loss : 4.610166549682617\n",
      "iteration : 932 , loss : 5.01101541519165\n",
      "iteration : 933 , loss : 4.644399642944336\n",
      "iteration : 934 , loss : 4.624654769897461\n",
      "iteration : 935 , loss : 5.003916263580322\n",
      "iteration : 936 , loss : 4.44288969039917\n",
      "iteration : 937 , loss : 4.801587104797363\n",
      "iteration : 938 , loss : 4.821030616760254\n",
      "iteration : 939 , loss : 4.625108242034912\n",
      "iteration : 940 , loss : 4.671461582183838\n",
      "iteration : 941 , loss : 4.889463424682617\n",
      "iteration : 942 , loss : 4.565586090087891\n",
      "iteration : 943 , loss : 5.0707688331604\n",
      "iteration : 944 , loss : 4.790281772613525\n",
      "iteration : 945 , loss : 5.064281463623047\n",
      "iteration : 946 , loss : 4.785905838012695\n",
      "iteration : 947 , loss : 4.810445308685303\n",
      "iteration : 948 , loss : 4.393479347229004\n",
      "iteration : 949 , loss : 4.860308647155762\n",
      "iteration : 950 , loss : 4.713136672973633\n",
      "iteration : 951 , loss : 4.609432220458984\n",
      "iteration : 952 , loss : 4.900142192840576\n",
      "iteration : 953 , loss : 4.768712043762207\n",
      "iteration : 954 , loss : 4.9858808517456055\n",
      "iteration : 955 , loss : 4.476849555969238\n",
      "iteration : 956 , loss : 4.488259315490723\n",
      "iteration : 957 , loss : 4.930103778839111\n",
      "iteration : 958 , loss : 4.597165107727051\n",
      "iteration : 959 , loss : 4.970511436462402\n",
      "iteration : 960 , loss : 4.911729335784912\n",
      "iteration : 961 , loss : 4.783119201660156\n",
      "iteration : 962 , loss : 4.7590484619140625\n",
      "iteration : 963 , loss : 4.725240230560303\n",
      "iteration : 964 , loss : 4.670441150665283\n",
      "iteration : 965 , loss : 4.5471649169921875\n",
      "iteration : 966 , loss : 4.917000770568848\n",
      "iteration : 967 , loss : 4.413311004638672\n",
      "iteration : 968 , loss : 4.864318370819092\n",
      "iteration : 969 , loss : 4.665555953979492\n",
      "iteration : 970 , loss : 4.613343715667725\n",
      "iteration : 971 , loss : 4.771026611328125\n",
      "iteration : 972 , loss : 4.499903678894043\n",
      "iteration : 973 , loss : 4.613404750823975\n",
      "iteration : 974 , loss : 4.516410827636719\n",
      "iteration : 975 , loss : 4.964707374572754\n",
      "iteration : 976 , loss : 4.387784957885742\n",
      "iteration : 977 , loss : 4.8429059982299805\n",
      "iteration : 978 , loss : 4.393014430999756\n",
      "iteration : 979 , loss : 4.442286014556885\n",
      "iteration : 980 , loss : 4.692126274108887\n",
      "iteration : 981 , loss : 4.757424354553223\n",
      "iteration : 982 , loss : 4.591734886169434\n",
      "iteration : 983 , loss : 4.4602274894714355\n",
      "iteration : 984 , loss : 4.658833026885986\n",
      "iteration : 985 , loss : 4.838977813720703\n",
      "iteration : 986 , loss : 4.576350212097168\n",
      "iteration : 987 , loss : 4.5219597816467285\n",
      "iteration : 988 , loss : 4.653369903564453\n",
      "iteration : 989 , loss : 4.989891529083252\n",
      "iteration : 990 , loss : 4.463622570037842\n",
      "iteration : 991 , loss : 4.796064853668213\n",
      "iteration : 992 , loss : 4.529283046722412\n",
      "iteration : 993 , loss : 4.571621417999268\n",
      "iteration : 994 , loss : 4.979003429412842\n",
      "iteration : 995 , loss : 4.605005264282227\n",
      "iteration : 996 , loss : 4.681103229522705\n",
      "iteration : 997 , loss : 4.819306373596191\n",
      "iteration : 998 , loss : 4.304396152496338\n",
      "iteration : 999 , loss : 4.572822093963623\n",
      "iteration : 1000 , loss : 4.834482669830322\n",
      "iteration : 1001 , loss : 4.7128119468688965\n",
      "iteration : 1002 , loss : 4.637375831604004\n",
      "iteration : 1003 , loss : 4.581465721130371\n",
      "iteration : 1004 , loss : 5.0068488121032715\n",
      "iteration : 1005 , loss : 4.556018829345703\n",
      "iteration : 1006 , loss : 4.628512859344482\n",
      "iteration : 1007 , loss : 4.761209487915039\n",
      "iteration : 1008 , loss : 4.497589588165283\n",
      "iteration : 1009 , loss : 4.708905220031738\n",
      "iteration : 1010 , loss : 4.972081184387207\n",
      "iteration : 1011 , loss : 4.515678405761719\n",
      "iteration : 1012 , loss : 4.57780647277832\n",
      "iteration : 1013 , loss : 4.635597229003906\n",
      "iteration : 1014 , loss : 4.8458638191223145\n",
      "iteration : 1015 , loss : 4.652012825012207\n",
      "iteration : 1016 , loss : 4.746501445770264\n",
      "iteration : 1017 , loss : 4.386828899383545\n",
      "iteration : 1018 , loss : 4.463005065917969\n",
      "iteration : 1019 , loss : 4.714332580566406\n",
      "iteration : 1020 , loss : 4.624100685119629\n",
      "iteration : 1021 , loss : 4.482079982757568\n",
      "iteration : 1022 , loss : 4.6530561447143555\n",
      "iteration : 1023 , loss : 4.622030735015869\n",
      "iteration : 1024 , loss : 4.467922687530518\n",
      "iteration : 1025 , loss : 4.750988960266113\n",
      "iteration : 1026 , loss : 4.67303991317749\n",
      "iteration : 1027 , loss : 4.807712554931641\n",
      "iteration : 1028 , loss : 4.62045955657959\n",
      "iteration : 1029 , loss : 4.64881706237793\n",
      "iteration : 1030 , loss : 4.751729965209961\n",
      "iteration : 1031 , loss : 4.982789993286133\n",
      "iteration : 1032 , loss : 4.524244785308838\n",
      "iteration : 1033 , loss : 4.753645420074463\n",
      "iteration : 1034 , loss : 4.598021030426025\n",
      "iteration : 1035 , loss : 5.05696964263916\n",
      "iteration : 1036 , loss : 4.636538505554199\n",
      "iteration : 1037 , loss : 4.969813823699951\n",
      "iteration : 1038 , loss : 4.694096565246582\n",
      "iteration : 1039 , loss : 4.465623378753662\n",
      "iteration : 1040 , loss : 4.685781955718994\n",
      "iteration : 1041 , loss : 4.73971700668335\n",
      "iteration : 1042 , loss : 4.566721439361572\n",
      "iteration : 1043 , loss : 4.7442522048950195\n",
      "iteration : 1044 , loss : 4.845224380493164\n",
      "iteration : 1045 , loss : 4.323396682739258\n",
      "iteration : 1046 , loss : 4.588714122772217\n",
      "iteration : 1047 , loss : 4.704617500305176\n",
      "iteration : 1048 , loss : 4.98668098449707\n",
      "iteration : 1049 , loss : 4.461352825164795\n",
      "iteration : 1050 , loss : 4.747028827667236\n",
      "iteration : 1051 , loss : 4.499875545501709\n",
      "iteration : 1052 , loss : 4.4550371170043945\n",
      "iteration : 1053 , loss : 4.68936014175415\n",
      "iteration : 1054 , loss : 4.765465259552002\n",
      "iteration : 1055 , loss : 5.0616936683654785\n",
      "iteration : 1056 , loss : 4.541210174560547\n",
      "iteration : 1057 , loss : 4.8133745193481445\n",
      "iteration : 1058 , loss : 4.622045516967773\n",
      "iteration : 1059 , loss : 4.586153507232666\n",
      "iteration : 1060 , loss : 4.542031764984131\n",
      "iteration : 1061 , loss : 4.067807197570801\n",
      "iteration : 1062 , loss : 4.434539318084717\n",
      "iteration : 1063 , loss : 4.343189716339111\n",
      "iteration : 1064 , loss : 4.8342437744140625\n",
      "iteration : 1065 , loss : 4.953841686248779\n",
      "iteration : 1066 , loss : 4.671792030334473\n",
      "iteration : 1067 , loss : 4.6169352531433105\n",
      "iteration : 1068 , loss : 4.441136360168457\n",
      "iteration : 1069 , loss : 4.85485315322876\n",
      "iteration : 1070 , loss : 4.602471828460693\n",
      "iteration : 1071 , loss : 4.508605003356934\n",
      "iteration : 1072 , loss : 4.44253396987915\n",
      "iteration : 1073 , loss : 4.589044094085693\n",
      "iteration : 1074 , loss : 4.340170383453369\n",
      "iteration : 1075 , loss : 5.036563396453857\n",
      "iteration : 1076 , loss : 4.334068775177002\n",
      "iteration : 1077 , loss : 4.653103828430176\n",
      "iteration : 1078 , loss : 4.826946258544922\n",
      "iteration : 1079 , loss : 4.507762908935547\n",
      "iteration : 1080 , loss : 4.805929183959961\n",
      "iteration : 1081 , loss : 4.9167351722717285\n",
      "iteration : 1082 , loss : 4.905611991882324\n",
      "iteration : 1083 , loss : 4.590771675109863\n",
      "iteration : 1084 , loss : 4.425346374511719\n",
      "iteration : 1085 , loss : 4.266636371612549\n",
      "iteration : 1086 , loss : 4.529917240142822\n",
      "iteration : 1087 , loss : 4.653416633605957\n",
      "iteration : 1088 , loss : 4.435486316680908\n",
      "iteration : 1089 , loss : 4.387502670288086\n",
      "iteration : 1090 , loss : 4.810513496398926\n",
      "iteration : 1091 , loss : 4.950229644775391\n",
      "iteration : 1092 , loss : 5.049070358276367\n",
      "iteration : 1093 , loss : 4.765174388885498\n",
      "iteration : 1094 , loss : 4.638075351715088\n",
      "iteration : 1095 , loss : 4.435667991638184\n",
      "iteration : 1096 , loss : 4.4878339767456055\n",
      "iteration : 1097 , loss : 4.511630535125732\n",
      "iteration : 1098 , loss : 4.579276084899902\n",
      "iteration : 1099 , loss : 4.459965229034424\n",
      "iteration : 1100 , loss : 4.830028057098389\n",
      "iteration : 1101 , loss : 4.7572340965271\n",
      "iteration : 1102 , loss : 4.295700550079346\n",
      "iteration : 1103 , loss : 4.753702163696289\n",
      "iteration : 1104 , loss : 4.8686933517456055\n",
      "iteration : 1105 , loss : 4.735495090484619\n",
      "iteration : 1106 , loss : 4.462711811065674\n",
      "iteration : 1107 , loss : 4.718813419342041\n",
      "iteration : 1108 , loss : 4.852711200714111\n",
      "iteration : 1109 , loss : 4.457733631134033\n",
      "iteration : 1110 , loss : 4.771368980407715\n",
      "iteration : 1111 , loss : 4.548979759216309\n",
      "iteration : 1112 , loss : 4.605295181274414\n",
      "iteration : 1113 , loss : 4.798531532287598\n",
      "iteration : 1114 , loss : 4.125365257263184\n",
      "iteration : 1115 , loss : 4.870306968688965\n",
      "iteration : 1116 , loss : 4.502416133880615\n",
      "iteration : 1117 , loss : 4.631533622741699\n",
      "iteration : 1118 , loss : 4.892088890075684\n",
      "iteration : 1119 , loss : 4.364309787750244\n",
      "iteration : 1120 , loss : 4.894537448883057\n",
      "iteration : 1121 , loss : 4.666265964508057\n",
      "iteration : 1122 , loss : 4.400052547454834\n",
      "iteration : 1123 , loss : 4.859501361846924\n",
      "iteration : 1124 , loss : 4.454893589019775\n",
      "iteration : 1125 , loss : 4.650658130645752\n",
      "iteration : 1126 , loss : 4.915806293487549\n",
      "iteration : 1127 , loss : 4.980470657348633\n",
      "iteration : 1128 , loss : 4.722888946533203\n",
      "iteration : 1129 , loss : 4.6342620849609375\n",
      "iteration : 1130 , loss : 4.746117115020752\n",
      "iteration : 1131 , loss : 4.492177963256836\n",
      "iteration : 1132 , loss : 4.475250244140625\n",
      "iteration : 1133 , loss : 4.514062404632568\n",
      "iteration : 1134 , loss : 4.433904647827148\n",
      "iteration : 1135 , loss : 4.535754680633545\n",
      "iteration : 1136 , loss : 4.324995517730713\n",
      "iteration : 1137 , loss : 4.383237838745117\n",
      "iteration : 1138 , loss : 4.66571569442749\n",
      "iteration : 1139 , loss : 4.855325222015381\n",
      "iteration : 1140 , loss : 4.201064109802246\n",
      "iteration : 1141 , loss : 4.545147895812988\n",
      "iteration : 1142 , loss : 4.495992660522461\n",
      "iteration : 1143 , loss : 4.570149898529053\n",
      "iteration : 1144 , loss : 4.285704612731934\n",
      "iteration : 1145 , loss : 4.5898566246032715\n",
      "iteration : 1146 , loss : 4.537664890289307\n",
      "iteration : 1147 , loss : 4.540637969970703\n",
      "iteration : 1148 , loss : 4.576108932495117\n",
      "iteration : 1149 , loss : 4.454719066619873\n",
      "iteration : 1150 , loss : 4.633772850036621\n",
      "iteration : 1151 , loss : 4.716341495513916\n",
      "iteration : 1152 , loss : 4.470909118652344\n",
      "iteration : 1153 , loss : 4.080301761627197\n",
      "iteration : 1154 , loss : 4.5403361320495605\n",
      "iteration : 1155 , loss : 4.138780117034912\n",
      "iteration : 1156 , loss : 4.434948444366455\n",
      "iteration : 1157 , loss : 4.441995143890381\n",
      "iteration : 1158 , loss : 4.342110633850098\n",
      "iteration : 1159 , loss : 4.152678966522217\n",
      "iteration : 1160 , loss : 4.295917987823486\n",
      "iteration : 1161 , loss : 4.547524452209473\n",
      "iteration : 1162 , loss : 4.963934898376465\n",
      "iteration : 1163 , loss : 4.337094306945801\n",
      "iteration : 1164 , loss : 4.80788516998291\n",
      "iteration : 1165 , loss : 4.721017837524414\n",
      "iteration : 1166 , loss : 4.4614763259887695\n",
      "iteration : 1167 , loss : 4.48644495010376\n",
      "iteration : 1168 , loss : 4.580249309539795\n",
      "iteration : 1169 , loss : 4.5723676681518555\n",
      "iteration : 1170 , loss : 4.481512069702148\n",
      "iteration : 1171 , loss : 4.570535659790039\n",
      "iteration : 1172 , loss : 4.342220783233643\n",
      "iteration : 1173 , loss : 4.576077938079834\n",
      "iteration : 1174 , loss : 4.363487243652344\n",
      "iteration : 1175 , loss : 4.485724449157715\n",
      "iteration : 1176 , loss : 4.702539443969727\n",
      "iteration : 1177 , loss : 4.676043510437012\n",
      "iteration : 1178 , loss : 4.644420623779297\n",
      "iteration : 1179 , loss : 4.48546838760376\n",
      "iteration : 1180 , loss : 4.728385925292969\n",
      "iteration : 1181 , loss : 4.518439292907715\n",
      "iteration : 1182 , loss : 4.3875532150268555\n",
      "iteration : 1183 , loss : 4.571136951446533\n",
      "iteration : 1184 , loss : 4.540953636169434\n",
      "iteration : 1185 , loss : 4.77372932434082\n",
      "iteration : 1186 , loss : 4.27679443359375\n",
      "iteration : 1187 , loss : 4.4244818687438965\n",
      "iteration : 1188 , loss : 4.3763813972473145\n",
      "iteration : 1189 , loss : 4.427174091339111\n",
      "iteration : 1190 , loss : 4.329327583312988\n",
      "iteration : 1191 , loss : 4.311435699462891\n",
      "iteration : 1192 , loss : 4.579026699066162\n",
      "iteration : 1193 , loss : 4.755443096160889\n",
      "iteration : 1194 , loss : 4.61486291885376\n",
      "iteration : 1195 , loss : 4.2419867515563965\n",
      "iteration : 1196 , loss : 4.384081840515137\n",
      "iteration : 1197 , loss : 4.589537620544434\n",
      "iteration : 1198 , loss : 4.568537712097168\n",
      "iteration : 1199 , loss : 4.826730728149414\n",
      "iteration : 1200 , loss : 4.4203290939331055\n",
      "iteration : 1201 , loss : 4.586627006530762\n",
      "iteration : 1202 , loss : 4.180491924285889\n",
      "iteration : 1203 , loss : 4.495766639709473\n",
      "iteration : 1204 , loss : 4.30292272567749\n",
      "iteration : 1205 , loss : 4.222024440765381\n",
      "iteration : 1206 , loss : 4.430406093597412\n",
      "iteration : 1207 , loss : 4.5041584968566895\n",
      "iteration : 1208 , loss : 4.534276962280273\n",
      "iteration : 1209 , loss : 4.5198283195495605\n",
      "iteration : 1210 , loss : 4.593736171722412\n",
      "iteration : 1211 , loss : 4.377223491668701\n",
      "iteration : 1212 , loss : 4.319276809692383\n",
      "iteration : 1213 , loss : 4.4938859939575195\n",
      "iteration : 1214 , loss : 4.5959367752075195\n",
      "iteration : 1215 , loss : 4.345124244689941\n",
      "iteration : 1216 , loss : 4.40290641784668\n",
      "iteration : 1217 , loss : 4.232635021209717\n",
      "iteration : 1218 , loss : 4.536637306213379\n",
      "iteration : 1219 , loss : 4.256904125213623\n",
      "iteration : 1220 , loss : 4.411686897277832\n",
      "iteration : 1221 , loss : 4.380459308624268\n",
      "iteration : 1222 , loss : 4.399580955505371\n",
      "iteration : 1223 , loss : 4.606149196624756\n",
      "iteration : 1224 , loss : 4.606170654296875\n",
      "iteration : 1225 , loss : 4.640859603881836\n",
      "iteration : 1226 , loss : 4.351898193359375\n",
      "iteration : 1227 , loss : 4.871764183044434\n",
      "iteration : 1228 , loss : 4.4592061042785645\n",
      "iteration : 1229 , loss : 4.413731575012207\n",
      "iteration : 1230 , loss : 4.510212421417236\n",
      "iteration : 1231 , loss : 4.646812438964844\n",
      "iteration : 1232 , loss : 4.609325885772705\n",
      "iteration : 1233 , loss : 4.243999004364014\n",
      "iteration : 1234 , loss : 4.320691108703613\n",
      "iteration : 1235 , loss : 4.5724358558654785\n",
      "iteration : 1236 , loss : 4.308378219604492\n",
      "iteration : 1237 , loss : 4.230476379394531\n",
      "iteration : 1238 , loss : 4.3010759353637695\n",
      "iteration : 1239 , loss : 4.298953533172607\n",
      "iteration : 1240 , loss : 4.326119899749756\n",
      "iteration : 1241 , loss : 4.492673873901367\n",
      "iteration : 1242 , loss : 4.743231773376465\n",
      "iteration : 1243 , loss : 4.216236114501953\n",
      "iteration : 1244 , loss : 4.4514336585998535\n",
      "iteration : 1245 , loss : 4.6031999588012695\n",
      "iteration : 1246 , loss : 4.604917526245117\n",
      "iteration : 1247 , loss : 4.420925140380859\n",
      "iteration : 1248 , loss : 4.766152858734131\n",
      "iteration : 1249 , loss : 4.458994388580322\n",
      "iteration : 1250 , loss : 4.505936145782471\n",
      "iteration : 1251 , loss : 4.379281044006348\n",
      "iteration : 1252 , loss : 4.511386871337891\n",
      "iteration : 1253 , loss : 4.4151811599731445\n",
      "iteration : 1254 , loss : 4.466380596160889\n",
      "iteration : 1255 , loss : 4.558927059173584\n",
      "iteration : 1256 , loss : 4.466940402984619\n",
      "iteration : 1257 , loss : 4.281288146972656\n",
      "iteration : 1258 , loss : 4.617164134979248\n",
      "iteration : 1259 , loss : 4.583359241485596\n",
      "iteration : 1260 , loss : 4.359445571899414\n",
      "iteration : 1261 , loss : 4.447754383087158\n",
      "iteration : 1262 , loss : 4.621191501617432\n",
      "iteration : 1263 , loss : 4.5013532638549805\n",
      "iteration : 1264 , loss : 4.662615776062012\n",
      "iteration : 1265 , loss : 4.678049564361572\n",
      "iteration : 1266 , loss : 4.472356796264648\n",
      "iteration : 1267 , loss : 4.383774280548096\n",
      "iteration : 1268 , loss : 4.417293548583984\n",
      "iteration : 1269 , loss : 4.204023361206055\n",
      "iteration : 1270 , loss : 4.386770725250244\n",
      "iteration : 1271 , loss : 4.501337051391602\n",
      "iteration : 1272 , loss : 4.576603412628174\n",
      "iteration : 1273 , loss : 4.578611850738525\n",
      "iteration : 1274 , loss : 4.6525187492370605\n",
      "iteration : 1275 , loss : 4.5958170890808105\n",
      "iteration : 1276 , loss : 4.506679534912109\n",
      "iteration : 1277 , loss : 4.742909908294678\n",
      "iteration : 1278 , loss : 4.543841361999512\n",
      "iteration : 1279 , loss : 4.34084415435791\n",
      "iteration : 1280 , loss : 4.287809371948242\n",
      "iteration : 1281 , loss : 4.400365352630615\n",
      "iteration : 1282 , loss : 4.351722717285156\n",
      "iteration : 1283 , loss : 4.360358238220215\n",
      "iteration : 1284 , loss : 4.635209560394287\n",
      "iteration : 1285 , loss : 4.6152544021606445\n",
      "iteration : 1286 , loss : 4.7421698570251465\n",
      "iteration : 1287 , loss : 4.623041152954102\n",
      "iteration : 1288 , loss : 4.235011577606201\n",
      "iteration : 1289 , loss : 4.218828201293945\n",
      "iteration : 1290 , loss : 4.28348970413208\n",
      "iteration : 1291 , loss : 4.608509063720703\n",
      "iteration : 1292 , loss : 4.202448844909668\n",
      "iteration : 1293 , loss : 4.635777950286865\n",
      "iteration : 1294 , loss : 4.28914213180542\n",
      "iteration : 1295 , loss : 4.126492500305176\n",
      "iteration : 1296 , loss : 4.7720842361450195\n",
      "iteration : 1297 , loss : 4.247287750244141\n",
      "iteration : 1298 , loss : 4.668451309204102\n",
      "iteration : 1299 , loss : 4.3046956062316895\n",
      "iteration : 1300 , loss : 4.845823287963867\n",
      "iteration : 1301 , loss : 4.446295738220215\n",
      "iteration : 1302 , loss : 4.271951675415039\n",
      "iteration : 1303 , loss : 4.542287826538086\n",
      "iteration : 1304 , loss : 4.456483364105225\n",
      "iteration : 1305 , loss : 4.397497177124023\n",
      "iteration : 1306 , loss : 4.398365497589111\n",
      "iteration : 1307 , loss : 4.449854373931885\n",
      "iteration : 1308 , loss : 4.396985054016113\n",
      "iteration : 1309 , loss : 4.078771114349365\n",
      "iteration : 1310 , loss : 4.352664470672607\n",
      "iteration : 1311 , loss : 4.563045024871826\n",
      "iteration : 1312 , loss : 4.842270851135254\n",
      "iteration : 1313 , loss : 4.380999565124512\n",
      "iteration : 1314 , loss : 4.51804780960083\n",
      "iteration : 1315 , loss : 4.327524662017822\n",
      "iteration : 1316 , loss : 4.606795787811279\n",
      "iteration : 1317 , loss : 4.193575382232666\n",
      "iteration : 1318 , loss : 4.495324611663818\n",
      "iteration : 1319 , loss : 4.5184431076049805\n",
      "iteration : 1320 , loss : 4.508693695068359\n",
      "iteration : 1321 , loss : 4.405402183532715\n",
      "iteration : 1322 , loss : 4.511455059051514\n",
      "iteration : 1323 , loss : 4.446352481842041\n",
      "iteration : 1324 , loss : 4.285166263580322\n",
      "iteration : 1325 , loss : 4.3134613037109375\n",
      "iteration : 1326 , loss : 4.268913269042969\n",
      "iteration : 1327 , loss : 4.223042964935303\n",
      "iteration : 1328 , loss : 4.678348541259766\n",
      "iteration : 1329 , loss : 4.419551849365234\n",
      "iteration : 1330 , loss : 4.822241306304932\n",
      "iteration : 1331 , loss : 4.3399553298950195\n",
      "iteration : 1332 , loss : 4.305586814880371\n",
      "iteration : 1333 , loss : 4.487851619720459\n",
      "iteration : 1334 , loss : 4.507349491119385\n",
      "iteration : 1335 , loss : 4.431853771209717\n",
      "iteration : 1336 , loss : 4.391118049621582\n",
      "iteration : 1337 , loss : 4.745803356170654\n",
      "iteration : 1338 , loss : 4.113302707672119\n",
      "iteration : 1339 , loss : 4.460136890411377\n",
      "iteration : 1340 , loss : 4.507462024688721\n",
      "iteration : 1341 , loss : 4.2020978927612305\n",
      "iteration : 1342 , loss : 4.360179424285889\n",
      "iteration : 1343 , loss : 4.469268321990967\n",
      "iteration : 1344 , loss : 4.434960842132568\n",
      "iteration : 1345 , loss : 4.23464822769165\n",
      "iteration : 1346 , loss : 4.3154425621032715\n",
      "iteration : 1347 , loss : 4.384018421173096\n",
      "iteration : 1348 , loss : 4.061975955963135\n",
      "iteration : 1349 , loss : 4.490631103515625\n",
      "iteration : 1350 , loss : 4.142874240875244\n",
      "iteration : 1351 , loss : 4.1608099937438965\n",
      "iteration : 1352 , loss : 4.296998023986816\n",
      "iteration : 1353 , loss : 4.291445255279541\n",
      "iteration : 1354 , loss : 4.297004222869873\n",
      "iteration : 1355 , loss : 4.316729545593262\n",
      "iteration : 1356 , loss : 4.437348365783691\n",
      "iteration : 1357 , loss : 4.34500789642334\n",
      "iteration : 1358 , loss : 4.309935569763184\n",
      "iteration : 1359 , loss : 4.257664680480957\n",
      "iteration : 1360 , loss : 4.616032123565674\n",
      "iteration : 1361 , loss : 4.281241416931152\n",
      "iteration : 1362 , loss : 4.380582809448242\n",
      "iteration : 1363 , loss : 4.0926690101623535\n",
      "iteration : 1364 , loss : 4.583742618560791\n",
      "iteration : 1365 , loss : 4.295308589935303\n",
      "iteration : 1366 , loss : 4.957190990447998\n",
      "iteration : 1367 , loss : 4.429471969604492\n",
      "iteration : 1368 , loss : 4.220942974090576\n",
      "iteration : 1369 , loss : 4.120615482330322\n",
      "iteration : 1370 , loss : 4.594964027404785\n",
      "iteration : 1371 , loss : 4.633548259735107\n",
      "iteration : 1372 , loss : 4.351067543029785\n",
      "iteration : 1373 , loss : 4.555867671966553\n",
      "iteration : 1374 , loss : 4.5978569984436035\n",
      "iteration : 1375 , loss : 4.455105781555176\n",
      "iteration : 1376 , loss : 4.2335100173950195\n",
      "iteration : 1377 , loss : 4.288722038269043\n",
      "iteration : 1378 , loss : 4.775888442993164\n",
      "iteration : 1379 , loss : 4.470865249633789\n",
      "iteration : 1380 , loss : 4.638234615325928\n",
      "iteration : 1381 , loss : 4.876091003417969\n",
      "iteration : 1382 , loss : 4.4244465827941895\n",
      "iteration : 1383 , loss : 4.404195308685303\n",
      "iteration : 1384 , loss : 4.2128095626831055\n",
      "iteration : 1385 , loss : 4.512157440185547\n",
      "iteration : 1386 , loss : 4.222747325897217\n",
      "iteration : 1387 , loss : 4.332001209259033\n",
      "iteration : 1388 , loss : 4.340399742126465\n",
      "iteration : 1389 , loss : 4.123355388641357\n",
      "iteration : 1390 , loss : 4.421314716339111\n",
      "iteration : 1391 , loss : 4.369363307952881\n",
      "iteration : 1392 , loss : 4.72099494934082\n",
      "iteration : 1393 , loss : 4.4082417488098145\n",
      "iteration : 1394 , loss : 4.4039716720581055\n",
      "iteration : 1395 , loss : 4.73434591293335\n",
      "iteration : 1396 , loss : 4.520730972290039\n",
      "iteration : 1397 , loss : 4.451426982879639\n",
      "iteration : 1398 , loss : 4.577147483825684\n",
      "iteration : 1399 , loss : 4.376694679260254\n",
      "iteration : 1400 , loss : 4.365689754486084\n",
      "iteration : 1401 , loss : 4.647558212280273\n",
      "iteration : 1402 , loss : 4.54158353805542\n",
      "iteration : 1403 , loss : 4.483247756958008\n",
      "iteration : 1404 , loss : 4.48448371887207\n",
      "iteration : 1405 , loss : 4.3398027420043945\n",
      "iteration : 1406 , loss : 4.152312755584717\n",
      "iteration : 1407 , loss : 4.396346569061279\n",
      "iteration : 1408 , loss : 4.554675579071045\n",
      "iteration : 1409 , loss : 4.0285444259643555\n",
      "iteration : 1410 , loss : 4.34335470199585\n",
      "iteration : 1411 , loss : 4.195961952209473\n",
      "iteration : 1412 , loss : 4.44687032699585\n",
      "iteration : 1413 , loss : 4.43787145614624\n",
      "iteration : 1414 , loss : 4.177974224090576\n",
      "iteration : 1415 , loss : 4.487215518951416\n",
      "iteration : 1416 , loss : 4.401436805725098\n",
      "iteration : 1417 , loss : 4.486508846282959\n",
      "iteration : 1418 , loss : 4.355513572692871\n",
      "iteration : 1419 , loss : 4.347656726837158\n",
      "iteration : 1420 , loss : 4.39055061340332\n",
      "iteration : 1421 , loss : 4.407139778137207\n",
      "iteration : 1422 , loss : 4.505756378173828\n",
      "iteration : 1423 , loss : 4.57249116897583\n",
      "iteration : 1424 , loss : 4.140718460083008\n",
      "iteration : 1425 , loss : 4.287895202636719\n",
      "iteration : 1426 , loss : 4.600154399871826\n",
      "iteration : 1427 , loss : 4.310408115386963\n",
      "iteration : 1428 , loss : 4.415637016296387\n",
      "iteration : 1429 , loss : 4.055734634399414\n",
      "iteration : 1430 , loss : 4.311610698699951\n",
      "iteration : 1431 , loss : 4.473013877868652\n",
      "iteration : 1432 , loss : 4.314964294433594\n",
      "iteration : 1433 , loss : 4.35921049118042\n",
      "iteration : 1434 , loss : 4.458512306213379\n",
      "iteration : 1435 , loss : 4.35275936126709\n",
      "iteration : 1436 , loss : 4.503525257110596\n",
      "iteration : 1437 , loss : 4.39478063583374\n",
      "iteration : 1438 , loss : 4.354844093322754\n",
      "iteration : 1439 , loss : 4.6226983070373535\n",
      "iteration : 1440 , loss : 4.337661266326904\n",
      "iteration : 1441 , loss : 4.081584453582764\n",
      "iteration : 1442 , loss : 4.863053321838379\n",
      "iteration : 1443 , loss : 4.702992916107178\n",
      "iteration : 1444 , loss : 4.149745464324951\n",
      "iteration : 1445 , loss : 4.526103973388672\n",
      "iteration : 1446 , loss : 4.065695285797119\n",
      "iteration : 1447 , loss : 4.592809200286865\n",
      "iteration : 1448 , loss : 4.161936283111572\n",
      "iteration : 1449 , loss : 4.675993919372559\n",
      "iteration : 1450 , loss : 4.458858013153076\n",
      "iteration : 1451 , loss : 4.407929420471191\n",
      "iteration : 1452 , loss : 4.628134250640869\n",
      "iteration : 1453 , loss : 4.193683624267578\n",
      "iteration : 1454 , loss : 4.689445972442627\n",
      "iteration : 1455 , loss : 4.371173858642578\n",
      "iteration : 1456 , loss : 4.440131664276123\n",
      "iteration : 1457 , loss : 4.634294033050537\n",
      "iteration : 1458 , loss : 4.4787421226501465\n",
      "iteration : 1459 , loss : 4.302371978759766\n",
      "iteration : 1460 , loss : 4.400264263153076\n",
      "iteration : 1461 , loss : 4.2452826499938965\n",
      "iteration : 1462 , loss : 4.461851596832275\n",
      "iteration : 1463 , loss : 4.494715213775635\n",
      "iteration : 1464 , loss : 4.37681770324707\n",
      "iteration : 1465 , loss : 4.416074752807617\n",
      "iteration : 1466 , loss : 4.395626068115234\n",
      "iteration : 1467 , loss : 4.286417007446289\n",
      "iteration : 1468 , loss : 4.354273796081543\n",
      "iteration : 1469 , loss : 4.077573299407959\n",
      "iteration : 1470 , loss : 4.317056655883789\n",
      "iteration : 1471 , loss : 4.595983982086182\n",
      "iteration : 1472 , loss : 4.537998199462891\n",
      "iteration : 1473 , loss : 4.443476676940918\n",
      "iteration : 1474 , loss : 4.31910514831543\n",
      "iteration : 1475 , loss : 4.166804790496826\n",
      "iteration : 1476 , loss : 4.263257026672363\n",
      "iteration : 1477 , loss : 4.342367172241211\n",
      "iteration : 1478 , loss : 4.307647228240967\n",
      "iteration : 1479 , loss : 4.246426582336426\n",
      "iteration : 1480 , loss : 4.700098514556885\n",
      "iteration : 1481 , loss : 4.575982570648193\n",
      "iteration : 1482 , loss : 4.2021002769470215\n",
      "iteration : 1483 , loss : 4.073668479919434\n",
      "iteration : 1484 , loss : 4.340717792510986\n",
      "iteration : 1485 , loss : 4.102845668792725\n",
      "iteration : 1486 , loss : 4.292108058929443\n",
      "iteration : 1487 , loss : 4.2170562744140625\n",
      "iteration : 1488 , loss : 4.405037879943848\n",
      "iteration : 1489 , loss : 4.227325916290283\n",
      "iteration : 1490 , loss : 4.235969543457031\n",
      "iteration : 1491 , loss : 4.283895969390869\n",
      "iteration : 1492 , loss : 4.453670978546143\n",
      "iteration : 1493 , loss : 4.211883544921875\n",
      "iteration : 1494 , loss : 4.381933212280273\n",
      "iteration : 1495 , loss : 4.3811187744140625\n",
      "iteration : 1496 , loss : 4.648786544799805\n",
      "iteration : 1497 , loss : 4.245396137237549\n",
      "iteration : 1498 , loss : 4.281581401824951\n",
      "iteration : 1499 , loss : 4.380039215087891\n",
      "iteration : 1500 , loss : 4.051669597625732\n",
      "iteration : 1501 , loss : 4.352887153625488\n",
      "iteration : 1502 , loss : 4.351867198944092\n",
      "iteration : 1503 , loss : 4.113509654998779\n",
      "iteration : 1504 , loss : 4.489232540130615\n",
      "iteration : 1505 , loss : 4.157789707183838\n",
      "iteration : 1506 , loss : 4.519628047943115\n",
      "iteration : 1507 , loss : 4.362010478973389\n",
      "iteration : 1508 , loss : 4.096371650695801\n",
      "iteration : 1509 , loss : 4.291871547698975\n",
      "iteration : 1510 , loss : 4.670149326324463\n",
      "iteration : 1511 , loss : 4.5875678062438965\n",
      "iteration : 1512 , loss : 4.112298011779785\n",
      "iteration : 1513 , loss : 3.93700909614563\n",
      "iteration : 1514 , loss : 4.528982162475586\n",
      "iteration : 1515 , loss : 4.514389991760254\n",
      "iteration : 1516 , loss : 4.109551906585693\n",
      "iteration : 1517 , loss : 4.214271545410156\n",
      "iteration : 1518 , loss : 4.02905797958374\n",
      "iteration : 1519 , loss : 4.2488226890563965\n",
      "iteration : 1520 , loss : 4.0335588455200195\n",
      "iteration : 1521 , loss : 4.372284412384033\n",
      "iteration : 1522 , loss : 3.922863006591797\n",
      "iteration : 1523 , loss : 3.9771018028259277\n",
      "iteration : 1524 , loss : 4.047795295715332\n",
      "iteration : 1525 , loss : 4.1747918128967285\n",
      "iteration : 1526 , loss : 4.134432792663574\n",
      "iteration : 1527 , loss : 4.278865337371826\n",
      "iteration : 1528 , loss : 4.253035545349121\n",
      "iteration : 1529 , loss : 4.400973320007324\n",
      "iteration : 1530 , loss : 4.538087844848633\n",
      "iteration : 1531 , loss : 4.36366081237793\n",
      "iteration : 1532 , loss : 4.117527008056641\n",
      "iteration : 1533 , loss : 4.287791728973389\n",
      "iteration : 1534 , loss : 4.2419610023498535\n",
      "iteration : 1535 , loss : 4.457864284515381\n",
      "iteration : 1536 , loss : 4.354281902313232\n",
      "iteration : 1537 , loss : 4.436345100402832\n",
      "iteration : 1538 , loss : 4.426514148712158\n",
      "iteration : 1539 , loss : 4.418309211730957\n",
      "iteration : 1540 , loss : 4.355734348297119\n",
      "iteration : 1541 , loss : 4.478000164031982\n",
      "iteration : 1542 , loss : 4.192650318145752\n",
      "iteration : 1543 , loss : 4.238180160522461\n",
      "iteration : 1544 , loss : 4.074451923370361\n",
      "iteration : 1545 , loss : 4.233954429626465\n",
      "iteration : 1546 , loss : 4.584952354431152\n",
      "iteration : 1547 , loss : 4.165146827697754\n",
      "iteration : 1548 , loss : 4.393570899963379\n",
      "iteration : 1549 , loss : 4.495105743408203\n",
      "iteration : 1550 , loss : 3.89907169342041\n",
      "iteration : 1551 , loss : 4.362000465393066\n",
      "iteration : 1552 , loss : 4.386970520019531\n",
      "iteration : 1553 , loss : 4.498913764953613\n",
      "iteration : 1554 , loss : 4.501648902893066\n",
      "iteration : 1555 , loss : 4.432275295257568\n",
      "iteration : 1556 , loss : 4.16427755355835\n",
      "iteration : 1557 , loss : 4.528549671173096\n",
      "iteration : 1558 , loss : 4.286493301391602\n",
      "iteration : 1559 , loss : 4.356943607330322\n",
      "iteration : 1560 , loss : 4.464710712432861\n",
      "iteration : 1561 , loss : 4.298943996429443\n",
      "iteration : 1562 , loss : 4.284860610961914\n",
      "iteration : 1563 , loss : 4.547135829925537\n",
      "iteration : 1564 , loss : 4.1402974128723145\n",
      "iteration : 1565 , loss : 4.602128982543945\n",
      "iteration : 1566 , loss : 4.092536926269531\n",
      "iteration : 1567 , loss : 4.251468181610107\n",
      "iteration : 1568 , loss : 4.337336540222168\n",
      "iteration : 1569 , loss : 4.28107213973999\n",
      "iteration : 1570 , loss : 3.975938320159912\n",
      "iteration : 1571 , loss : 4.121452331542969\n",
      "iteration : 1572 , loss : 4.47946834564209\n",
      "iteration : 1573 , loss : 4.400559425354004\n",
      "iteration : 1574 , loss : 4.259390354156494\n",
      "iteration : 1575 , loss : 4.13465690612793\n",
      "iteration : 1576 , loss : 4.421270370483398\n",
      "iteration : 1577 , loss : 4.0987653732299805\n",
      "iteration : 1578 , loss : 4.041738033294678\n",
      "iteration : 1579 , loss : 4.004494667053223\n",
      "iteration : 1580 , loss : 4.3581013679504395\n",
      "iteration : 1581 , loss : 4.352776527404785\n",
      "iteration : 1582 , loss : 4.313632011413574\n",
      "iteration : 1583 , loss : 4.280149936676025\n",
      "iteration : 1584 , loss : 4.334263324737549\n",
      "iteration : 1585 , loss : 4.038280487060547\n",
      "iteration : 1586 , loss : 4.14288330078125\n",
      "iteration : 1587 , loss : 4.370265960693359\n",
      "iteration : 1588 , loss : 4.392299175262451\n",
      "iteration : 1589 , loss : 4.244622707366943\n",
      "iteration : 1590 , loss : 4.2621965408325195\n",
      "iteration : 1591 , loss : 4.484095096588135\n",
      "iteration : 1592 , loss : 4.34812068939209\n",
      "iteration : 1593 , loss : 4.398313522338867\n",
      "iteration : 1594 , loss : 4.522417068481445\n",
      "iteration : 1595 , loss : 4.140860557556152\n",
      "iteration : 1596 , loss : 3.9220175743103027\n",
      "iteration : 1597 , loss : 4.458361625671387\n",
      "iteration : 1598 , loss : 4.112596035003662\n",
      "iteration : 1599 , loss : 3.776449680328369\n",
      "iteration : 1600 , loss : 4.278221607208252\n",
      "iteration : 1601 , loss : 4.339093208312988\n",
      "iteration : 1602 , loss : 4.067961692810059\n",
      "iteration : 1603 , loss : 4.0615739822387695\n",
      "iteration : 1604 , loss : 4.346575736999512\n",
      "iteration : 1605 , loss : 3.9721760749816895\n",
      "iteration : 1606 , loss : 4.347803115844727\n",
      "iteration : 1607 , loss : 4.293688774108887\n",
      "iteration : 1608 , loss : 4.214873790740967\n",
      "iteration : 1609 , loss : 4.276875019073486\n",
      "iteration : 1610 , loss : 4.293451309204102\n",
      "iteration : 1611 , loss : 4.292965888977051\n",
      "iteration : 1612 , loss : 4.131917953491211\n",
      "iteration : 1613 , loss : 4.232214450836182\n",
      "iteration : 1614 , loss : 4.316884994506836\n",
      "iteration : 1615 , loss : 4.136932849884033\n",
      "iteration : 1616 , loss : 4.323474407196045\n",
      "iteration : 1617 , loss : 4.370205879211426\n",
      "iteration : 1618 , loss : 4.386969089508057\n",
      "iteration : 1619 , loss : 4.462220191955566\n",
      "iteration : 1620 , loss : 4.363857746124268\n",
      "iteration : 1621 , loss : 4.243780136108398\n",
      "iteration : 1622 , loss : 4.39592170715332\n",
      "iteration : 1623 , loss : 4.749083042144775\n",
      "iteration : 1624 , loss : 4.171241760253906\n",
      "iteration : 1625 , loss : 4.154567241668701\n",
      "iteration : 1626 , loss : 4.389398097991943\n",
      "iteration : 1627 , loss : 4.184484481811523\n",
      "iteration : 1628 , loss : 3.9011552333831787\n",
      "iteration : 1629 , loss : 3.919060468673706\n",
      "iteration : 1630 , loss : 4.047187328338623\n",
      "iteration : 1631 , loss : 4.408420085906982\n",
      "iteration : 1632 , loss : 4.107271194458008\n",
      "iteration : 1633 , loss : 4.122686862945557\n",
      "iteration : 1634 , loss : 4.099145889282227\n",
      "iteration : 1635 , loss : 4.163475036621094\n",
      "iteration : 1636 , loss : 4.384007453918457\n",
      "iteration : 1637 , loss : 4.376430988311768\n",
      "iteration : 1638 , loss : 4.511986255645752\n",
      "iteration : 1639 , loss : 4.2148919105529785\n",
      "iteration : 1640 , loss : 4.300085544586182\n",
      "iteration : 1641 , loss : 4.072365760803223\n",
      "iteration : 1642 , loss : 4.299530506134033\n",
      "iteration : 1643 , loss : 4.4749436378479\n",
      "iteration : 1644 , loss : 4.029736518859863\n",
      "iteration : 1645 , loss : 3.8802573680877686\n",
      "iteration : 1646 , loss : 4.0144853591918945\n",
      "iteration : 1647 , loss : 4.393775939941406\n",
      "iteration : 1648 , loss : 4.322126388549805\n",
      "iteration : 1649 , loss : 4.75904655456543\n",
      "iteration : 1650 , loss : 4.703380584716797\n",
      "iteration : 1651 , loss : 4.199178218841553\n",
      "iteration : 1652 , loss : 4.319756507873535\n",
      "iteration : 1653 , loss : 4.212654113769531\n",
      "iteration : 1654 , loss : 4.258437633514404\n",
      "iteration : 1655 , loss : 4.309312343597412\n",
      "iteration : 1656 , loss : 4.039854526519775\n",
      "iteration : 1657 , loss : 4.290740966796875\n",
      "iteration : 1658 , loss : 4.4167633056640625\n",
      "iteration : 1659 , loss : 4.270013809204102\n",
      "iteration : 1660 , loss : 3.832486867904663\n",
      "iteration : 1661 , loss : 4.248343467712402\n",
      "iteration : 1662 , loss : 4.318142414093018\n",
      "iteration : 1663 , loss : 4.169232368469238\n",
      "iteration : 1664 , loss : 4.164389610290527\n",
      "iteration : 1665 , loss : 4.337376594543457\n",
      "iteration : 1666 , loss : 4.350129127502441\n",
      "iteration : 1667 , loss : 4.547501087188721\n",
      "iteration : 1668 , loss : 4.448472499847412\n",
      "iteration : 1669 , loss : 4.2681803703308105\n",
      "iteration : 1670 , loss : 4.081952095031738\n",
      "iteration : 1671 , loss : 4.196588039398193\n",
      "iteration : 1672 , loss : 4.291042327880859\n",
      "iteration : 1673 , loss : 4.286725997924805\n",
      "iteration : 1674 , loss : 4.488596439361572\n",
      "iteration : 1675 , loss : 4.25457239151001\n",
      "iteration : 1676 , loss : 4.304108619689941\n",
      "iteration : 1677 , loss : 4.271134853363037\n",
      "iteration : 1678 , loss : 4.079851150512695\n",
      "iteration : 1679 , loss : 4.033450603485107\n",
      "iteration : 1680 , loss : 4.155034065246582\n",
      "iteration : 1681 , loss : 4.179391860961914\n",
      "iteration : 1682 , loss : 4.479027271270752\n",
      "iteration : 1683 , loss : 4.307487964630127\n",
      "iteration : 1684 , loss : 4.154407978057861\n",
      "iteration : 1685 , loss : 4.3527607917785645\n",
      "iteration : 1686 , loss : 4.2469048500061035\n",
      "iteration : 1687 , loss : 3.9542949199676514\n",
      "iteration : 1688 , loss : 4.446311950683594\n",
      "iteration : 1689 , loss : 4.4571533203125\n",
      "iteration : 1690 , loss : 4.022941589355469\n",
      "iteration : 1691 , loss : 4.228818893432617\n",
      "iteration : 1692 , loss : 4.15228271484375\n",
      "iteration : 1693 , loss : 4.142119884490967\n",
      "iteration : 1694 , loss : 4.028995037078857\n",
      "iteration : 1695 , loss : 4.134997844696045\n",
      "iteration : 1696 , loss : 4.164337158203125\n",
      "iteration : 1697 , loss : 4.347176551818848\n",
      "iteration : 1698 , loss : 4.324774265289307\n",
      "iteration : 1699 , loss : 4.2479119300842285\n",
      "iteration : 1700 , loss : 4.168100357055664\n",
      "iteration : 1701 , loss : 3.990839958190918\n",
      "iteration : 1702 , loss : 4.396054744720459\n",
      "iteration : 1703 , loss : 4.048887729644775\n",
      "iteration : 1704 , loss : 4.107603549957275\n",
      "iteration : 1705 , loss : 4.5771613121032715\n",
      "iteration : 1706 , loss : 4.575451374053955\n",
      "iteration : 1707 , loss : 4.102406978607178\n",
      "iteration : 1708 , loss : 4.301721096038818\n",
      "iteration : 1709 , loss : 4.483705520629883\n",
      "iteration : 1710 , loss : 4.202491283416748\n",
      "iteration : 1711 , loss : 4.3134002685546875\n",
      "iteration : 1712 , loss : 4.4885454177856445\n",
      "iteration : 1713 , loss : 4.002038955688477\n",
      "iteration : 1714 , loss : 4.122211933135986\n",
      "iteration : 1715 , loss : 4.069709777832031\n",
      "iteration : 1716 , loss : 4.04747200012207\n",
      "iteration : 1717 , loss : 4.119705677032471\n",
      "iteration : 1718 , loss : 4.2909932136535645\n",
      "iteration : 1719 , loss : 4.072432518005371\n",
      "iteration : 1720 , loss : 4.380053997039795\n",
      "iteration : 1721 , loss : 4.160404205322266\n",
      "iteration : 1722 , loss : 4.1017889976501465\n",
      "iteration : 1723 , loss : 4.329252243041992\n",
      "iteration : 1724 , loss : 4.255434036254883\n",
      "iteration : 1725 , loss : 4.459461688995361\n",
      "iteration : 1726 , loss : 4.4680681228637695\n",
      "iteration : 1727 , loss : 4.642071723937988\n",
      "iteration : 1728 , loss : 4.13100528717041\n",
      "iteration : 1729 , loss : 4.172001361846924\n",
      "iteration : 1730 , loss : 4.061356067657471\n",
      "iteration : 1731 , loss : 4.075688362121582\n",
      "iteration : 1732 , loss : 4.2407121658325195\n",
      "iteration : 1733 , loss : 4.512224197387695\n",
      "iteration : 1734 , loss : 4.326980113983154\n",
      "iteration : 1735 , loss : 4.194288730621338\n",
      "iteration : 1736 , loss : 4.494734287261963\n",
      "iteration : 1737 , loss : 4.138718605041504\n",
      "iteration : 1738 , loss : 4.010876655578613\n",
      "iteration : 1739 , loss : 4.2436113357543945\n",
      "iteration : 1740 , loss : 4.432933330535889\n",
      "iteration : 1741 , loss : 4.080855369567871\n",
      "iteration : 1742 , loss : 4.388884544372559\n",
      "iteration : 1743 , loss : 4.357175827026367\n",
      "iteration : 1744 , loss : 4.278590202331543\n",
      "iteration : 1745 , loss : 4.085886478424072\n",
      "iteration : 1746 , loss : 3.9376418590545654\n",
      "iteration : 1747 , loss : 4.432137489318848\n",
      "iteration : 1748 , loss : 4.3762431144714355\n",
      "iteration : 1749 , loss : 4.480881690979004\n",
      "iteration : 1750 , loss : 4.250682830810547\n",
      "iteration : 1751 , loss : 4.056598663330078\n",
      "iteration : 1752 , loss : 4.162142276763916\n",
      "iteration : 1753 , loss : 4.2286601066589355\n",
      "iteration : 1754 , loss : 4.20620059967041\n",
      "iteration : 1755 , loss : 4.025818347930908\n",
      "iteration : 1756 , loss : 4.238725662231445\n",
      "iteration : 1757 , loss : 4.291861057281494\n",
      "iteration : 1758 , loss : 4.507579803466797\n",
      "iteration : 1759 , loss : 4.1231303215026855\n",
      "iteration : 1760 , loss : 3.928053855895996\n",
      "iteration : 1761 , loss : 3.920515775680542\n",
      "iteration : 1762 , loss : 4.1504998207092285\n",
      "iteration : 1763 , loss : 4.1107001304626465\n",
      "iteration : 1764 , loss : 3.8107240200042725\n",
      "iteration : 1765 , loss : 3.9325687885284424\n",
      "iteration : 1766 , loss : 4.250641345977783\n",
      "iteration : 1767 , loss : 4.240993499755859\n",
      "iteration : 1768 , loss : 4.487091064453125\n",
      "iteration : 1769 , loss : 4.500233173370361\n",
      "iteration : 1770 , loss : 4.0991902351379395\n",
      "iteration : 1771 , loss : 4.247819900512695\n",
      "iteration : 1772 , loss : 4.18912410736084\n",
      "iteration : 1773 , loss : 4.345858097076416\n",
      "iteration : 1774 , loss : 4.247072696685791\n",
      "iteration : 1775 , loss : 4.025213718414307\n",
      "iteration : 1776 , loss : 4.156956195831299\n",
      "iteration : 1777 , loss : 4.01100492477417\n",
      "iteration : 1778 , loss : 3.8391664028167725\n",
      "iteration : 1779 , loss : 4.1760430335998535\n",
      "iteration : 1780 , loss : 4.142062664031982\n",
      "iteration : 1781 , loss : 3.9383320808410645\n",
      "iteration : 1782 , loss : 4.153055667877197\n",
      "iteration : 1783 , loss : 4.233287334442139\n",
      "iteration : 1784 , loss : 3.9117422103881836\n",
      "iteration : 1785 , loss : 4.293803691864014\n",
      "iteration : 1786 , loss : 4.339395999908447\n",
      "iteration : 1787 , loss : 4.210819721221924\n",
      "iteration : 1788 , loss : 4.230264186859131\n",
      "iteration : 1789 , loss : 4.067983150482178\n",
      "iteration : 1790 , loss : 4.429783344268799\n",
      "iteration : 1791 , loss : 4.321157932281494\n",
      "iteration : 1792 , loss : 4.107891082763672\n",
      "iteration : 1793 , loss : 3.995541572570801\n",
      "iteration : 1794 , loss : 4.334873199462891\n",
      "iteration : 1795 , loss : 3.996460437774658\n",
      "iteration : 1796 , loss : 4.567782878875732\n",
      "iteration : 1797 , loss : 4.223419189453125\n",
      "iteration : 1798 , loss : 3.655763626098633\n",
      "iteration : 1799 , loss : 4.151848793029785\n",
      "iteration : 1800 , loss : 4.3543291091918945\n",
      "iteration : 1801 , loss : 4.079151153564453\n",
      "iteration : 1802 , loss : 4.099420070648193\n",
      "iteration : 1803 , loss : 4.09958028793335\n",
      "iteration : 1804 , loss : 4.065283298492432\n",
      "iteration : 1805 , loss : 4.292787551879883\n",
      "iteration : 1806 , loss : 4.243766784667969\n",
      "iteration : 1807 , loss : 4.152097225189209\n",
      "iteration : 1808 , loss : 4.288912773132324\n",
      "iteration : 1809 , loss : 4.32119083404541\n",
      "iteration : 1810 , loss : 4.247424125671387\n",
      "iteration : 1811 , loss : 4.15781307220459\n",
      "iteration : 1812 , loss : 4.504354476928711\n",
      "iteration : 1813 , loss : 3.936371326446533\n",
      "iteration : 1814 , loss : 4.366909027099609\n",
      "iteration : 1815 , loss : 4.3762993812561035\n",
      "iteration : 1816 , loss : 4.024560451507568\n",
      "iteration : 1817 , loss : 4.039864540100098\n",
      "iteration : 1818 , loss : 4.19760274887085\n",
      "iteration : 1819 , loss : 4.2314534187316895\n",
      "iteration : 1820 , loss : 4.3861589431762695\n",
      "iteration : 1821 , loss : 4.076934814453125\n",
      "iteration : 1822 , loss : 4.307034969329834\n",
      "iteration : 1823 , loss : 4.137378692626953\n",
      "iteration : 1824 , loss : 4.037681579589844\n",
      "iteration : 1825 , loss : 4.197531700134277\n",
      "iteration : 1826 , loss : 4.299680233001709\n",
      "iteration : 1827 , loss : 4.761152267456055\n",
      "iteration : 1828 , loss : 4.577984809875488\n",
      "iteration : 1829 , loss : 4.555046558380127\n",
      "iteration : 1830 , loss : 4.414175987243652\n",
      "iteration : 1831 , loss : 4.045260429382324\n",
      "iteration : 1832 , loss : 4.116987228393555\n",
      "iteration : 1833 , loss : 4.280554294586182\n",
      "iteration : 1834 , loss : 4.099931716918945\n",
      "iteration : 1835 , loss : 4.287332057952881\n",
      "iteration : 1836 , loss : 4.164403915405273\n",
      "iteration : 1837 , loss : 4.193142414093018\n",
      "iteration : 1838 , loss : 4.061604976654053\n",
      "iteration : 1839 , loss : 4.215221405029297\n",
      "iteration : 1840 , loss : 4.18180513381958\n",
      "iteration : 1841 , loss : 3.8000144958496094\n",
      "iteration : 1842 , loss : 4.10876989364624\n",
      "iteration : 1843 , loss : 3.9929585456848145\n",
      "iteration : 1844 , loss : 4.3274664878845215\n",
      "iteration : 1845 , loss : 4.284030914306641\n",
      "iteration : 1846 , loss : 4.033505439758301\n",
      "iteration : 1847 , loss : 4.160446643829346\n",
      "iteration : 1848 , loss : 4.0583038330078125\n",
      "iteration : 1849 , loss : 4.04367733001709\n",
      "iteration : 1850 , loss : 4.042532444000244\n",
      "iteration : 1851 , loss : 3.8830316066741943\n",
      "iteration : 1852 , loss : 4.2126383781433105\n",
      "iteration : 1853 , loss : 4.751853942871094\n",
      "iteration : 1854 , loss : 4.334710121154785\n",
      "iteration : 1855 , loss : 4.106035232543945\n",
      "iteration : 1856 , loss : 4.1860527992248535\n",
      "iteration : 1857 , loss : 4.190969944000244\n",
      "iteration : 1858 , loss : 4.186258792877197\n",
      "iteration : 1859 , loss : 4.3263258934021\n",
      "iteration : 1860 , loss : 4.2571797370910645\n",
      "iteration : 1861 , loss : 4.248740196228027\n",
      "iteration : 1862 , loss : 3.912917375564575\n",
      "iteration : 1863 , loss : 4.270585536956787\n",
      "iteration : 1864 , loss : 4.49653434753418\n",
      "iteration : 1865 , loss : 4.194246292114258\n",
      "iteration : 1866 , loss : 4.029944896697998\n",
      "iteration : 1867 , loss : 4.149970054626465\n",
      "iteration : 1868 , loss : 4.205957889556885\n",
      "iteration : 1869 , loss : 4.138912677764893\n",
      "iteration : 1870 , loss : 4.201355457305908\n",
      "iteration : 1871 , loss : 4.09141731262207\n",
      "iteration : 1872 , loss : 4.3052167892456055\n",
      "iteration : 1873 , loss : 4.216534614562988\n",
      "iteration : 1874 , loss : 4.111670970916748\n",
      "iteration : 1875 , loss : 4.518252372741699\n",
      "iteration : 1876 , loss : 3.9734864234924316\n",
      "iteration : 1877 , loss : 4.1594343185424805\n",
      "iteration : 1878 , loss : 4.093469142913818\n",
      "iteration : 1879 , loss : 4.053941249847412\n",
      "iteration : 1880 , loss : 4.290124416351318\n",
      "iteration : 1881 , loss : 4.127381324768066\n",
      "iteration : 1882 , loss : 4.332543849945068\n",
      "iteration : 1883 , loss : 3.837855100631714\n",
      "iteration : 1884 , loss : 4.009990215301514\n",
      "iteration : 1885 , loss : 4.215358734130859\n",
      "iteration : 1886 , loss : 3.8862149715423584\n",
      "iteration : 1887 , loss : 4.279703140258789\n",
      "iteration : 1888 , loss : 4.391087532043457\n",
      "iteration : 1889 , loss : 4.365861415863037\n",
      "iteration : 1890 , loss : 4.4414143562316895\n",
      "iteration : 1891 , loss : 4.193222999572754\n",
      "iteration : 1892 , loss : 4.258432865142822\n",
      "iteration : 1893 , loss : 4.106891632080078\n",
      "iteration : 1894 , loss : 4.090874195098877\n",
      "iteration : 1895 , loss : 4.196874618530273\n",
      "iteration : 1896 , loss : 4.267481327056885\n",
      "iteration : 1897 , loss : 3.762253999710083\n",
      "iteration : 1898 , loss : 4.258296012878418\n",
      "iteration : 1899 , loss : 3.8713948726654053\n",
      "iteration : 1900 , loss : 4.306426048278809\n",
      "iteration : 1901 , loss : 3.976539373397827\n",
      "iteration : 1902 , loss : 3.9876396656036377\n",
      "iteration : 1903 , loss : 4.202697277069092\n",
      "iteration : 1904 , loss : 4.06515645980835\n",
      "iteration : 1905 , loss : 4.365354537963867\n",
      "iteration : 1906 , loss : 3.8330142498016357\n",
      "iteration : 1907 , loss : 4.327322959899902\n",
      "iteration : 1908 , loss : 4.331287384033203\n",
      "iteration : 1909 , loss : 3.957833766937256\n",
      "iteration : 1910 , loss : 4.346327781677246\n",
      "iteration : 1911 , loss : 3.8927931785583496\n",
      "iteration : 1912 , loss : 3.9456112384796143\n",
      "iteration : 1913 , loss : 4.255475997924805\n",
      "iteration : 1914 , loss : 4.109565258026123\n",
      "iteration : 1915 , loss : 4.120743751525879\n",
      "iteration : 1916 , loss : 4.361863613128662\n",
      "iteration : 1917 , loss : 4.083223342895508\n",
      "iteration : 1918 , loss : 4.034276485443115\n",
      "iteration : 1919 , loss : 4.043144226074219\n",
      "iteration : 1920 , loss : 4.320631980895996\n",
      "iteration : 1921 , loss : 3.895937204360962\n",
      "iteration : 1922 , loss : 4.146143913269043\n",
      "iteration : 1923 , loss : 4.0971455574035645\n",
      "iteration : 1924 , loss : 4.054069995880127\n",
      "iteration : 1925 , loss : 4.157399654388428\n",
      "iteration : 1926 , loss : 4.082592010498047\n",
      "iteration : 1927 , loss : 4.229874610900879\n",
      "iteration : 1928 , loss : 4.069481372833252\n",
      "iteration : 1929 , loss : 3.846529722213745\n",
      "iteration : 1930 , loss : 4.120074272155762\n",
      "iteration : 1931 , loss : 4.119715213775635\n",
      "iteration : 1932 , loss : 4.212593078613281\n",
      "iteration : 1933 , loss : 4.13084602355957\n",
      "iteration : 1934 , loss : 4.116208553314209\n",
      "iteration : 1935 , loss : 4.094562530517578\n",
      "iteration : 1936 , loss : 4.408290386199951\n",
      "iteration : 1937 , loss : 4.30203104019165\n",
      "iteration : 1938 , loss : 4.0971808433532715\n",
      "iteration : 1939 , loss : 4.11590576171875\n",
      "iteration : 1940 , loss : 4.0801005363464355\n",
      "iteration : 1941 , loss : 4.172145366668701\n",
      "iteration : 1942 , loss : 4.48272705078125\n",
      "iteration : 1943 , loss : 4.381593227386475\n",
      "iteration : 1944 , loss : 4.255647659301758\n",
      "iteration : 1945 , loss : 3.896796703338623\n",
      "iteration : 1946 , loss : 3.9516375064849854\n",
      "iteration : 1947 , loss : 3.9104020595550537\n",
      "iteration : 1948 , loss : 3.8037099838256836\n",
      "iteration : 1949 , loss : 3.955483913421631\n",
      "iteration : 1950 , loss : 4.244727611541748\n",
      "iteration : 1951 , loss : 4.1764302253723145\n",
      "iteration : 1952 , loss : 3.8139235973358154\n",
      "iteration : 1953 , loss : 4.132933616638184\n",
      "iteration : 1954 , loss : 3.895864248275757\n",
      "iteration : 1955 , loss : 4.09442663192749\n",
      "iteration : 1956 , loss : 4.4198899269104\n",
      "iteration : 1957 , loss : 4.32634973526001\n",
      "iteration : 1958 , loss : 4.3284525871276855\n",
      "iteration : 1959 , loss : 4.427165985107422\n",
      "iteration : 1960 , loss : 4.075003147125244\n",
      "iteration : 1961 , loss : 4.2876739501953125\n",
      "iteration : 1962 , loss : 4.32166051864624\n",
      "iteration : 1963 , loss : 4.376562118530273\n",
      "iteration : 1964 , loss : 4.187117576599121\n",
      "iteration : 1965 , loss : 3.9601352214813232\n",
      "iteration : 1966 , loss : 3.891892433166504\n",
      "iteration : 1967 , loss : 3.9400155544281006\n",
      "iteration : 1968 , loss : 3.8734054565429688\n",
      "iteration : 1969 , loss : 4.081472396850586\n",
      "iteration : 1970 , loss : 4.21562385559082\n",
      "iteration : 1971 , loss : 4.260420322418213\n",
      "iteration : 1972 , loss : 4.209605693817139\n",
      "iteration : 1973 , loss : 3.911222219467163\n",
      "iteration : 1974 , loss : 4.0008931159973145\n",
      "iteration : 1975 , loss : 4.160894870758057\n",
      "iteration : 1976 , loss : 4.261118412017822\n",
      "iteration : 1977 , loss : 4.137852668762207\n",
      "iteration : 1978 , loss : 4.146049976348877\n",
      "iteration : 1979 , loss : 3.9791438579559326\n",
      "iteration : 1980 , loss : 4.045996189117432\n",
      "iteration : 1981 , loss : 3.977142095565796\n",
      "iteration : 1982 , loss : 4.215180397033691\n",
      "iteration : 1983 , loss : 4.073400974273682\n",
      "iteration : 1984 , loss : 4.003479957580566\n",
      "iteration : 1985 , loss : 4.115230083465576\n",
      "iteration : 1986 , loss : 4.091265678405762\n",
      "iteration : 1987 , loss : 4.169036388397217\n",
      "iteration : 1988 , loss : 4.0113701820373535\n",
      "iteration : 1989 , loss : 4.066216945648193\n",
      "iteration : 1990 , loss : 4.296049118041992\n",
      "iteration : 1991 , loss : 3.9861021041870117\n",
      "iteration : 1992 , loss : 4.211236953735352\n",
      "iteration : 1993 , loss : 4.329158306121826\n",
      "iteration : 1994 , loss : 4.218018531799316\n",
      "iteration : 1995 , loss : 4.067742347717285\n",
      "iteration : 1996 , loss : 4.407172203063965\n",
      "iteration : 1997 , loss : 4.047161102294922\n",
      "iteration : 1998 , loss : 4.298464298248291\n",
      "iteration : 1999 , loss : 4.233282089233398\n",
      "iteration : 2000 , loss : 3.795551300048828\n",
      "iteration : 2001 , loss : 3.870210647583008\n",
      "iteration : 2002 , loss : 4.363594055175781\n",
      "iteration : 2003 , loss : 4.156508922576904\n",
      "iteration : 2004 , loss : 3.9550468921661377\n",
      "iteration : 2005 , loss : 4.422146320343018\n",
      "iteration : 2006 , loss : 4.362175464630127\n",
      "iteration : 2007 , loss : 4.086336135864258\n",
      "iteration : 2008 , loss : 3.944110870361328\n",
      "iteration : 2009 , loss : 4.138575553894043\n",
      "iteration : 2010 , loss : 4.1275482177734375\n",
      "iteration : 2011 , loss : 4.0389084815979\n",
      "iteration : 2012 , loss : 4.128902435302734\n",
      "iteration : 2013 , loss : 4.015893936157227\n",
      "iteration : 2014 , loss : 4.430797576904297\n",
      "iteration : 2015 , loss : 4.220639705657959\n",
      "iteration : 2016 , loss : 3.9991626739501953\n",
      "iteration : 2017 , loss : 4.091978073120117\n",
      "iteration : 2018 , loss : 3.9568865299224854\n",
      "iteration : 2019 , loss : 3.9961371421813965\n",
      "iteration : 2020 , loss : 3.9288623332977295\n",
      "iteration : 2021 , loss : 3.9479260444641113\n",
      "iteration : 2022 , loss : 4.28561544418335\n",
      "iteration : 2023 , loss : 4.3151960372924805\n",
      "iteration : 2024 , loss : 3.978041410446167\n",
      "iteration : 2025 , loss : 3.8881869316101074\n",
      "iteration : 2026 , loss : 3.817352771759033\n",
      "iteration : 2027 , loss : 4.04123592376709\n",
      "iteration : 2028 , loss : 4.131707668304443\n",
      "iteration : 2029 , loss : 3.8977627754211426\n",
      "iteration : 2030 , loss : 4.271212100982666\n",
      "iteration : 2031 , loss : 4.069586753845215\n",
      "iteration : 2032 , loss : 4.20211124420166\n",
      "iteration : 2033 , loss : 3.9303526878356934\n",
      "iteration : 2034 , loss : 4.279081344604492\n",
      "iteration : 2035 , loss : 4.195086479187012\n",
      "iteration : 2036 , loss : 4.014561176300049\n",
      "iteration : 2037 , loss : 3.968623161315918\n",
      "iteration : 2038 , loss : 4.352185249328613\n",
      "iteration : 2039 , loss : 3.7384581565856934\n",
      "iteration : 2040 , loss : 4.026343822479248\n",
      "iteration : 2041 , loss : 3.9959793090820312\n",
      "iteration : 2042 , loss : 3.9774558544158936\n",
      "iteration : 2043 , loss : 3.992460012435913\n",
      "iteration : 2044 , loss : 4.2280426025390625\n",
      "iteration : 2045 , loss : 3.9372222423553467\n",
      "iteration : 2046 , loss : 4.403346538543701\n",
      "iteration : 2047 , loss : 4.3306498527526855\n",
      "iteration : 2048 , loss : 4.269331455230713\n",
      "iteration : 2049 , loss : 4.032850742340088\n",
      "iteration : 2050 , loss : 3.963212251663208\n",
      "iteration : 2051 , loss : 3.8954617977142334\n",
      "iteration : 2052 , loss : 3.722132444381714\n",
      "iteration : 2053 , loss : 4.575362205505371\n",
      "iteration : 2054 , loss : 4.051951885223389\n",
      "iteration : 2055 , loss : 4.099920272827148\n",
      "iteration : 2056 , loss : 4.18361759185791\n",
      "iteration : 2057 , loss : 3.892293930053711\n",
      "iteration : 2058 , loss : 3.732447862625122\n",
      "iteration : 2059 , loss : 4.261850357055664\n",
      "iteration : 2060 , loss : 4.185174942016602\n",
      "iteration : 2061 , loss : 4.480592250823975\n",
      "iteration : 2062 , loss : 4.176140308380127\n",
      "iteration : 2063 , loss : 3.8838906288146973\n",
      "iteration : 2064 , loss : 4.501261234283447\n",
      "iteration : 2065 , loss : 4.272395133972168\n",
      "iteration : 2066 , loss : 3.9973368644714355\n",
      "iteration : 2067 , loss : 3.9283485412597656\n",
      "iteration : 2068 , loss : 4.381237506866455\n",
      "iteration : 2069 , loss : 3.9971535205841064\n",
      "iteration : 2070 , loss : 4.239983558654785\n",
      "iteration : 2071 , loss : 3.9101221561431885\n",
      "iteration : 2072 , loss : 4.096393585205078\n",
      "iteration : 2073 , loss : 4.134711265563965\n",
      "iteration : 2074 , loss : 4.085762977600098\n",
      "iteration : 2075 , loss : 4.293008327484131\n",
      "iteration : 2076 , loss : 4.148425579071045\n",
      "iteration : 2077 , loss : 4.109440803527832\n",
      "iteration : 2078 , loss : 4.127195835113525\n",
      "iteration : 2079 , loss : 3.9825329780578613\n",
      "iteration : 2080 , loss : 4.257779121398926\n",
      "iteration : 2081 , loss : 4.020318508148193\n",
      "iteration : 2082 , loss : 4.018972873687744\n",
      "iteration : 2083 , loss : 4.405467510223389\n",
      "iteration : 2084 , loss : 3.878666877746582\n",
      "iteration : 2085 , loss : 4.326219081878662\n",
      "iteration : 2086 , loss : 3.9797439575195312\n",
      "iteration : 2087 , loss : 3.9727072715759277\n",
      "iteration : 2088 , loss : 3.897479295730591\n",
      "iteration : 2089 , loss : 4.015865802764893\n",
      "iteration : 2090 , loss : 3.837094306945801\n",
      "iteration : 2091 , loss : 4.1240458488464355\n",
      "iteration : 2092 , loss : 3.9265451431274414\n",
      "iteration : 2093 , loss : 4.038577079772949\n",
      "iteration : 2094 , loss : 3.8869740962982178\n",
      "iteration : 2095 , loss : 3.879131555557251\n",
      "iteration : 2096 , loss : 4.014424800872803\n",
      "iteration : 2097 , loss : 4.4455647468566895\n",
      "iteration : 2098 , loss : 3.5703036785125732\n",
      "iteration : 2099 , loss : 4.130091667175293\n",
      "iteration : 2100 , loss : 4.1884870529174805\n",
      "iteration : 2101 , loss : 4.597637176513672\n",
      "iteration : 2102 , loss : 3.6799113750457764\n",
      "iteration : 2103 , loss : 4.1324849128723145\n",
      "iteration : 2104 , loss : 4.371903896331787\n",
      "iteration : 2105 , loss : 4.0956220626831055\n",
      "iteration : 2106 , loss : 4.020279407501221\n",
      "iteration : 2107 , loss : 4.384885311126709\n",
      "iteration : 2108 , loss : 4.268982410430908\n",
      "iteration : 2109 , loss : 4.450085163116455\n",
      "iteration : 2110 , loss : 4.095620155334473\n",
      "iteration : 2111 , loss : 4.098817348480225\n",
      "iteration : 2112 , loss : 4.241030216217041\n",
      "iteration : 2113 , loss : 3.8688762187957764\n",
      "iteration : 2114 , loss : 4.260246276855469\n",
      "iteration : 2115 , loss : 4.0586628913879395\n",
      "iteration : 2116 , loss : 4.051822185516357\n",
      "iteration : 2117 , loss : 3.950504779815674\n",
      "iteration : 2118 , loss : 4.386524677276611\n",
      "iteration : 2119 , loss : 3.8605823516845703\n",
      "iteration : 2120 , loss : 3.940140724182129\n",
      "iteration : 2121 , loss : 3.740135908126831\n",
      "iteration : 2122 , loss : 4.2810869216918945\n",
      "iteration : 2123 , loss : 3.857527256011963\n",
      "iteration : 2124 , loss : 4.0604634284973145\n",
      "iteration : 2125 , loss : 4.18748664855957\n",
      "iteration : 2126 , loss : 4.195857524871826\n",
      "iteration : 2127 , loss : 4.031479835510254\n",
      "iteration : 2128 , loss : 4.142351150512695\n",
      "iteration : 2129 , loss : 4.102863788604736\n",
      "iteration : 2130 , loss : 4.290135860443115\n",
      "iteration : 2131 , loss : 4.381211757659912\n",
      "iteration : 2132 , loss : 4.273773193359375\n",
      "iteration : 2133 , loss : 3.748920440673828\n",
      "iteration : 2134 , loss : 3.88931941986084\n",
      "iteration : 2135 , loss : 3.845698833465576\n",
      "iteration : 2136 , loss : 4.066193103790283\n",
      "iteration : 2137 , loss : 4.243709087371826\n",
      "iteration : 2138 , loss : 3.8239388465881348\n",
      "iteration : 2139 , loss : 4.003369331359863\n",
      "iteration : 2140 , loss : 3.9731242656707764\n",
      "iteration : 2141 , loss : 4.076529026031494\n",
      "iteration : 2142 , loss : 4.075106620788574\n",
      "iteration : 2143 , loss : 3.9157371520996094\n",
      "iteration : 2144 , loss : 3.844224214553833\n",
      "iteration : 2145 , loss : 4.181944847106934\n",
      "iteration : 2146 , loss : 4.104164123535156\n",
      "iteration : 2147 , loss : 4.060877323150635\n",
      "iteration : 2148 , loss : 4.119091987609863\n",
      "iteration : 2149 , loss : 4.026312351226807\n",
      "iteration : 2150 , loss : 4.053533554077148\n",
      "iteration : 2151 , loss : 3.906917095184326\n",
      "iteration : 2152 , loss : 4.15651798248291\n",
      "iteration : 2153 , loss : 4.050766468048096\n",
      "iteration : 2154 , loss : 4.38886022567749\n",
      "iteration : 2155 , loss : 4.066442966461182\n",
      "iteration : 2156 , loss : 4.04490852355957\n",
      "iteration : 2157 , loss : 3.9755749702453613\n",
      "iteration : 2158 , loss : 4.2486796379089355\n",
      "iteration : 2159 , loss : 4.106750011444092\n",
      "iteration : 2160 , loss : 4.463737487792969\n",
      "iteration : 2161 , loss : 4.482511043548584\n",
      "iteration : 2162 , loss : 4.119523525238037\n",
      "iteration : 2163 , loss : 4.160830020904541\n",
      "iteration : 2164 , loss : 4.330353736877441\n",
      "iteration : 2165 , loss : 4.422996520996094\n",
      "iteration : 2166 , loss : 4.368826389312744\n",
      "iteration : 2167 , loss : 4.205042362213135\n",
      "iteration : 2168 , loss : 4.317444324493408\n",
      "iteration : 2169 , loss : 3.833427906036377\n",
      "iteration : 2170 , loss : 3.8577840328216553\n",
      "iteration : 2171 , loss : 4.022252082824707\n",
      "iteration : 2172 , loss : 4.181358337402344\n",
      "iteration : 2173 , loss : 4.162121295928955\n",
      "iteration : 2174 , loss : 4.106759548187256\n",
      "iteration : 2175 , loss : 4.127288341522217\n",
      "iteration : 2176 , loss : 3.894289493560791\n",
      "iteration : 2177 , loss : 4.393592834472656\n",
      "iteration : 2178 , loss : 3.5940353870391846\n",
      "iteration : 2179 , loss : 4.007145404815674\n",
      "iteration : 2180 , loss : 3.9527337551116943\n",
      "iteration : 2181 , loss : 3.9257724285125732\n",
      "iteration : 2182 , loss : 3.8580965995788574\n",
      "iteration : 2183 , loss : 4.074508190155029\n",
      "iteration : 2184 , loss : 4.229826927185059\n",
      "iteration : 2185 , loss : 4.196975231170654\n",
      "iteration : 2186 , loss : 4.19569206237793\n",
      "iteration : 2187 , loss : 4.067599296569824\n",
      "iteration : 2188 , loss : 3.9812140464782715\n",
      "iteration : 2189 , loss : 4.1969075202941895\n",
      "iteration : 2190 , loss : 4.02362585067749\n",
      "iteration : 2191 , loss : 4.140890598297119\n",
      "iteration : 2192 , loss : 3.903714418411255\n",
      "iteration : 2193 , loss : 3.978095293045044\n",
      "iteration : 2194 , loss : 4.2457709312438965\n",
      "iteration : 2195 , loss : 3.8162031173706055\n",
      "iteration : 2196 , loss : 3.9982666969299316\n",
      "iteration : 2197 , loss : 3.7285475730895996\n",
      "iteration : 2198 , loss : 3.863776445388794\n",
      "iteration : 2199 , loss : 3.8096156120300293\n",
      "iteration : 2200 , loss : 3.9897444248199463\n",
      "iteration : 2201 , loss : 4.057393550872803\n",
      "iteration : 2202 , loss : 3.971555709838867\n",
      "iteration : 2203 , loss : 4.198543548583984\n",
      "iteration : 2204 , loss : 4.135641098022461\n",
      "iteration : 2205 , loss : 3.6824707984924316\n",
      "iteration : 2206 , loss : 4.046376705169678\n",
      "iteration : 2207 , loss : 3.7068543434143066\n",
      "iteration : 2208 , loss : 4.079972267150879\n",
      "iteration : 2209 , loss : 3.927903413772583\n",
      "iteration : 2210 , loss : 4.140384674072266\n",
      "iteration : 2211 , loss : 4.061589241027832\n",
      "iteration : 2212 , loss : 4.067176818847656\n",
      "iteration : 2213 , loss : 4.086157321929932\n",
      "iteration : 2214 , loss : 3.970431327819824\n",
      "iteration : 2215 , loss : 3.9421651363372803\n",
      "iteration : 2216 , loss : 4.123144626617432\n",
      "iteration : 2217 , loss : 4.48416805267334\n",
      "iteration : 2218 , loss : 4.1520891189575195\n",
      "iteration : 2219 , loss : 4.096250534057617\n",
      "iteration : 2220 , loss : 3.908717155456543\n",
      "iteration : 2221 , loss : 4.3113579750061035\n",
      "iteration : 2222 , loss : 4.071239948272705\n",
      "iteration : 2223 , loss : 3.8996756076812744\n",
      "iteration : 2224 , loss : 4.109385013580322\n",
      "iteration : 2225 , loss : 4.079118251800537\n",
      "iteration : 2226 , loss : 3.9636330604553223\n",
      "iteration : 2227 , loss : 4.271799087524414\n",
      "iteration : 2228 , loss : 4.204301357269287\n",
      "iteration : 2229 , loss : 3.905421733856201\n",
      "iteration : 2230 , loss : 3.989008665084839\n",
      "iteration : 2231 , loss : 3.963819980621338\n",
      "iteration : 2232 , loss : 4.274818420410156\n",
      "iteration : 2233 , loss : 3.9917378425598145\n",
      "iteration : 2234 , loss : 4.005167484283447\n",
      "iteration : 2235 , loss : 4.0643310546875\n",
      "iteration : 2236 , loss : 4.040765285491943\n",
      "iteration : 2237 , loss : 3.940110683441162\n",
      "iteration : 2238 , loss : 3.833195686340332\n",
      "iteration : 2239 , loss : 3.7229089736938477\n",
      "iteration : 2240 , loss : 4.119076728820801\n",
      "iteration : 2241 , loss : 4.0907111167907715\n",
      "iteration : 2242 , loss : 3.905311107635498\n",
      "iteration : 2243 , loss : 3.839803457260132\n",
      "iteration : 2244 , loss : 3.9931020736694336\n",
      "iteration : 2245 , loss : 3.9833996295928955\n",
      "iteration : 2246 , loss : 4.181206226348877\n",
      "iteration : 2247 , loss : 4.045877456665039\n",
      "iteration : 2248 , loss : 4.195387363433838\n",
      "iteration : 2249 , loss : 4.141664981842041\n",
      "iteration : 2250 , loss : 3.9293410778045654\n",
      "iteration : 2251 , loss : 4.0992655754089355\n",
      "iteration : 2252 , loss : 4.080143928527832\n",
      "iteration : 2253 , loss : 4.1691060066223145\n",
      "iteration : 2254 , loss : 3.8052172660827637\n",
      "iteration : 2255 , loss : 3.8895745277404785\n",
      "iteration : 2256 , loss : 3.925175428390503\n",
      "iteration : 2257 , loss : 4.063210487365723\n",
      "iteration : 2258 , loss : 4.283224582672119\n",
      "iteration : 2259 , loss : 4.110639572143555\n",
      "iteration : 2260 , loss : 3.9616217613220215\n",
      "iteration : 2261 , loss : 3.9883193969726562\n",
      "iteration : 2262 , loss : 3.8780229091644287\n",
      "iteration : 2263 , loss : 4.1574883460998535\n",
      "iteration : 2264 , loss : 4.187795162200928\n",
      "iteration : 2265 , loss : 3.940288782119751\n",
      "iteration : 2266 , loss : 4.215145587921143\n",
      "iteration : 2267 , loss : 3.868518114089966\n",
      "iteration : 2268 , loss : 4.233406066894531\n",
      "iteration : 2269 , loss : 4.49263858795166\n",
      "iteration : 2270 , loss : 3.9936225414276123\n",
      "iteration : 2271 , loss : 4.185562610626221\n",
      "iteration : 2272 , loss : 4.18195915222168\n",
      "iteration : 2273 , loss : 4.010060787200928\n",
      "iteration : 2274 , loss : 3.894134759902954\n",
      "iteration : 2275 , loss : 3.7122247219085693\n",
      "iteration : 2276 , loss : 4.069246292114258\n",
      "iteration : 2277 , loss : 4.150148868560791\n",
      "iteration : 2278 , loss : 4.14915657043457\n",
      "iteration : 2279 , loss : 3.797072172164917\n",
      "iteration : 2280 , loss : 4.441899299621582\n",
      "iteration : 2281 , loss : 3.99556040763855\n",
      "iteration : 2282 , loss : 4.102216720581055\n",
      "iteration : 2283 , loss : 4.239283561706543\n",
      "iteration : 2284 , loss : 3.928096055984497\n",
      "iteration : 2285 , loss : 4.171706199645996\n",
      "iteration : 2286 , loss : 4.218636512756348\n",
      "iteration : 2287 , loss : 4.019736289978027\n",
      "iteration : 2288 , loss : 4.204498291015625\n",
      "iteration : 2289 , loss : 4.083904266357422\n",
      "iteration : 2290 , loss : 4.014440059661865\n",
      "iteration : 2291 , loss : 4.070835590362549\n",
      "iteration : 2292 , loss : 3.999634265899658\n",
      "iteration : 2293 , loss : 4.101235389709473\n",
      "iteration : 2294 , loss : 3.858619451522827\n",
      "iteration : 2295 , loss : 3.8994829654693604\n",
      "iteration : 2296 , loss : 4.340819358825684\n",
      "iteration : 2297 , loss : 4.029936790466309\n",
      "iteration : 2298 , loss : 4.179516315460205\n",
      "iteration : 2299 , loss : 4.067207336425781\n",
      "iteration : 2300 , loss : 3.963383197784424\n",
      "iteration : 2301 , loss : 3.7571072578430176\n",
      "iteration : 2302 , loss : 4.000927448272705\n",
      "iteration : 2303 , loss : 3.889362335205078\n",
      "iteration : 2304 , loss : 3.90940523147583\n",
      "iteration : 2305 , loss : 4.300103664398193\n",
      "iteration : 2306 , loss : 4.019278526306152\n",
      "iteration : 2307 , loss : 4.001789569854736\n",
      "iteration : 2308 , loss : 4.121659755706787\n",
      "iteration : 2309 , loss : 4.030033111572266\n",
      "iteration : 2310 , loss : 4.163023948669434\n",
      "iteration : 2311 , loss : 3.915381669998169\n",
      "iteration : 2312 , loss : 3.927006483078003\n",
      "iteration : 2313 , loss : 4.208422660827637\n",
      "iteration : 2314 , loss : 3.9230289459228516\n",
      "iteration : 2315 , loss : 3.9891610145568848\n",
      "iteration : 2316 , loss : 3.998805522918701\n",
      "iteration : 2317 , loss : 4.131430149078369\n",
      "iteration : 2318 , loss : 4.2438507080078125\n",
      "iteration : 2319 , loss : 3.9580962657928467\n",
      "iteration : 2320 , loss : 3.9746501445770264\n",
      "iteration : 2321 , loss : 3.919628381729126\n",
      "iteration : 2322 , loss : 3.9817252159118652\n",
      "iteration : 2323 , loss : 4.074825763702393\n",
      "iteration : 2324 , loss : 4.060972213745117\n",
      "iteration : 2325 , loss : 4.015261173248291\n",
      "iteration : 2326 , loss : 4.038374900817871\n",
      "iteration : 2327 , loss : 4.1337995529174805\n",
      "iteration : 2328 , loss : 3.869560956954956\n",
      "iteration : 2329 , loss : 3.786349058151245\n",
      "iteration : 2330 , loss : 4.218924045562744\n",
      "iteration : 2331 , loss : 4.011025428771973\n",
      "iteration : 2332 , loss : 4.094836235046387\n",
      "iteration : 2333 , loss : 4.210224151611328\n",
      "iteration : 2334 , loss : 3.933046817779541\n",
      "iteration : 2335 , loss : 3.9342784881591797\n",
      "iteration : 2336 , loss : 3.9175777435302734\n",
      "iteration : 2337 , loss : 3.898390293121338\n",
      "iteration : 2338 , loss : 3.8983213901519775\n",
      "iteration : 2339 , loss : 4.024569034576416\n",
      "iteration : 2340 , loss : 4.046079635620117\n",
      "iteration : 2341 , loss : 4.059988021850586\n",
      "iteration : 2342 , loss : 4.135924339294434\n",
      "iteration : 2343 , loss : 3.8509507179260254\n",
      "iteration : 2344 , loss : 4.033411502838135\n",
      "iteration : 2345 , loss : 3.9467689990997314\n",
      "iteration : 2346 , loss : 4.0276336669921875\n",
      "iteration : 2347 , loss : 4.192984104156494\n",
      "iteration : 2348 , loss : 4.0058112144470215\n",
      "iteration : 2349 , loss : 4.11237907409668\n",
      "iteration : 2350 , loss : 4.210263252258301\n",
      "iteration : 2351 , loss : 4.178695201873779\n",
      "iteration : 2352 , loss : 3.961348533630371\n",
      "iteration : 2353 , loss : 3.8320891857147217\n",
      "iteration : 2354 , loss : 4.191982269287109\n",
      "iteration : 2355 , loss : 3.7822470664978027\n",
      "iteration : 2356 , loss : 4.1882476806640625\n",
      "iteration : 2357 , loss : 3.8827574253082275\n",
      "iteration : 2358 , loss : 4.003283500671387\n",
      "iteration : 2359 , loss : 3.611508369445801\n",
      "iteration : 2360 , loss : 4.024857997894287\n",
      "iteration : 2361 , loss : 3.8963000774383545\n",
      "iteration : 2362 , loss : 4.027733325958252\n",
      "iteration : 2363 , loss : 4.121485710144043\n",
      "iteration : 2364 , loss : 3.8612494468688965\n",
      "iteration : 2365 , loss : 3.9888112545013428\n",
      "iteration : 2366 , loss : 4.009940147399902\n",
      "iteration : 2367 , loss : 3.946232557296753\n",
      "iteration : 2368 , loss : 3.870267152786255\n",
      "iteration : 2369 , loss : 3.9987547397613525\n",
      "iteration : 2370 , loss : 3.930642604827881\n",
      "iteration : 2371 , loss : 4.166735649108887\n",
      "iteration : 2372 , loss : 3.760531187057495\n",
      "iteration : 2373 , loss : 3.979166269302368\n",
      "iteration : 2374 , loss : 4.056162357330322\n",
      "iteration : 2375 , loss : 3.8451004028320312\n",
      "iteration : 2376 , loss : 4.06950569152832\n",
      "iteration : 2377 , loss : 3.852756977081299\n",
      "iteration : 2378 , loss : 3.8771796226501465\n",
      "iteration : 2379 , loss : 4.13425350189209\n",
      "iteration : 2380 , loss : 3.715550184249878\n",
      "iteration : 2381 , loss : 4.110982894897461\n",
      "iteration : 2382 , loss : 3.767568588256836\n",
      "iteration : 2383 , loss : 3.9810376167297363\n",
      "iteration : 2384 , loss : 4.0453033447265625\n",
      "iteration : 2385 , loss : 3.8125815391540527\n",
      "iteration : 2386 , loss : 4.05124568939209\n",
      "iteration : 2387 , loss : 3.772104501724243\n",
      "iteration : 2388 , loss : 4.102010726928711\n",
      "iteration : 2389 , loss : 3.835815191268921\n",
      "iteration : 2390 , loss : 4.039541244506836\n",
      "iteration : 2391 , loss : 3.796588659286499\n",
      "iteration : 2392 , loss : 3.7997000217437744\n",
      "iteration : 2393 , loss : 3.4866526126861572\n",
      "iteration : 2394 , loss : 4.114360332489014\n",
      "iteration : 2395 , loss : 4.1481475830078125\n",
      "iteration : 2396 , loss : 3.8179612159729004\n",
      "iteration : 2397 , loss : 4.321975231170654\n",
      "iteration : 2398 , loss : 3.814976930618286\n",
      "iteration : 2399 , loss : 4.167590141296387\n",
      "iteration : 2400 , loss : 4.105576038360596\n",
      "iteration : 2401 , loss : 3.815483331680298\n",
      "iteration : 2402 , loss : 3.7403149604797363\n",
      "iteration : 2403 , loss : 3.661748170852661\n",
      "iteration : 2404 , loss : 3.6763265132904053\n",
      "iteration : 2405 , loss : 3.915802478790283\n",
      "iteration : 2406 , loss : 3.612908363342285\n",
      "iteration : 2407 , loss : 3.9273464679718018\n",
      "iteration : 2408 , loss : 4.078953742980957\n",
      "iteration : 2409 , loss : 3.7966971397399902\n",
      "iteration : 2410 , loss : 4.003509521484375\n",
      "iteration : 2411 , loss : 4.090734004974365\n",
      "iteration : 2412 , loss : 4.117620944976807\n",
      "iteration : 2413 , loss : 4.14381742477417\n",
      "iteration : 2414 , loss : 3.9496474266052246\n",
      "iteration : 2415 , loss : 3.709177017211914\n",
      "iteration : 2416 , loss : 4.124656677246094\n",
      "iteration : 2417 , loss : 3.9168882369995117\n",
      "iteration : 2418 , loss : 4.216464042663574\n",
      "iteration : 2419 , loss : 3.7303521633148193\n",
      "iteration : 2420 , loss : 3.927109718322754\n",
      "iteration : 2421 , loss : 3.8213751316070557\n",
      "iteration : 2422 , loss : 3.818908452987671\n",
      "iteration : 2423 , loss : 4.15704345703125\n",
      "iteration : 2424 , loss : 4.028066158294678\n",
      "iteration : 2425 , loss : 3.985142707824707\n",
      "iteration : 2426 , loss : 4.256120204925537\n",
      "iteration : 2427 , loss : 4.0973663330078125\n",
      "iteration : 2428 , loss : 4.107006549835205\n",
      "iteration : 2429 , loss : 3.837226629257202\n",
      "iteration : 2430 , loss : 3.850832223892212\n",
      "iteration : 2431 , loss : 3.86098051071167\n",
      "iteration : 2432 , loss : 4.418667316436768\n",
      "iteration : 2433 , loss : 3.9238905906677246\n",
      "iteration : 2434 , loss : 4.259990215301514\n",
      "iteration : 2435 , loss : 4.083226680755615\n",
      "iteration : 2436 , loss : 3.98950457572937\n",
      "iteration : 2437 , loss : 4.21347188949585\n",
      "iteration : 2438 , loss : 3.852677345275879\n",
      "iteration : 2439 , loss : 3.804489850997925\n",
      "iteration : 2440 , loss : 4.0550665855407715\n",
      "iteration : 2441 , loss : 3.7857465744018555\n",
      "iteration : 2442 , loss : 4.277929782867432\n",
      "iteration : 2443 , loss : 4.055662155151367\n",
      "iteration : 2444 , loss : 3.790860652923584\n",
      "iteration : 2445 , loss : 3.8902478218078613\n",
      "iteration : 2446 , loss : 4.105467796325684\n",
      "iteration : 2447 , loss : 3.8038346767425537\n",
      "iteration : 2448 , loss : 4.028717994689941\n",
      "iteration : 2449 , loss : 3.837679386138916\n",
      "iteration : 2450 , loss : 4.071979999542236\n",
      "iteration : 2451 , loss : 3.8483760356903076\n",
      "iteration : 2452 , loss : 3.9903883934020996\n",
      "iteration : 2453 , loss : 3.9765069484710693\n",
      "iteration : 2454 , loss : 3.810492992401123\n",
      "iteration : 2455 , loss : 4.312690734863281\n",
      "iteration : 2456 , loss : 3.9198293685913086\n",
      "iteration : 2457 , loss : 3.877256393432617\n",
      "iteration : 2458 , loss : 4.113348484039307\n",
      "iteration : 2459 , loss : 3.8094916343688965\n",
      "iteration : 2460 , loss : 3.8669304847717285\n",
      "iteration : 2461 , loss : 4.099550247192383\n",
      "iteration : 2462 , loss : 3.805798292160034\n",
      "iteration : 2463 , loss : 3.90099835395813\n",
      "iteration : 2464 , loss : 3.831334114074707\n",
      "iteration : 2465 , loss : 4.09419059753418\n",
      "iteration : 2466 , loss : 4.191202163696289\n",
      "iteration : 2467 , loss : 3.9116151332855225\n",
      "iteration : 2468 , loss : 3.734839677810669\n",
      "iteration : 2469 , loss : 4.131955623626709\n",
      "iteration : 2470 , loss : 4.2781853675842285\n",
      "iteration : 2471 , loss : 3.8185007572174072\n",
      "iteration : 2472 , loss : 4.083636283874512\n",
      "iteration : 2473 , loss : 4.039189338684082\n",
      "iteration : 2474 , loss : 3.933316707611084\n",
      "iteration : 2475 , loss : 3.8593289852142334\n",
      "iteration : 2476 , loss : 3.910184860229492\n",
      "iteration : 2477 , loss : 4.298901081085205\n",
      "iteration : 2478 , loss : 4.019900798797607\n",
      "iteration : 2479 , loss : 4.085867881774902\n",
      "iteration : 2480 , loss : 3.9569740295410156\n",
      "iteration : 2481 , loss : 4.1631388664245605\n",
      "iteration : 2482 , loss : 4.006058692932129\n",
      "iteration : 2483 , loss : 3.9711124897003174\n",
      "iteration : 2484 , loss : 3.861449718475342\n",
      "iteration : 2485 , loss : 3.857246160507202\n",
      "iteration : 2486 , loss : 3.8920376300811768\n",
      "iteration : 2487 , loss : 4.126862049102783\n",
      "iteration : 2488 , loss : 3.9521915912628174\n",
      "iteration : 2489 , loss : 3.9366273880004883\n",
      "iteration : 2490 , loss : 4.075552940368652\n",
      "iteration : 2491 , loss : 3.6864850521087646\n",
      "iteration : 2492 , loss : 4.050436973571777\n",
      "iteration : 2493 , loss : 4.001935005187988\n",
      "iteration : 2494 , loss : 4.045788288116455\n",
      "iteration : 2495 , loss : 4.15421724319458\n",
      "iteration : 2496 , loss : 4.482433319091797\n",
      "iteration : 2497 , loss : 3.905890703201294\n",
      "iteration : 2498 , loss : 4.019087791442871\n",
      "iteration : 2499 , loss : 3.9918267726898193\n",
      "iteration : 2500 , loss : 3.9589319229125977\n",
      "iteration : 2501 , loss : 3.974839925765991\n",
      "iteration : 2502 , loss : 4.02321720123291\n",
      "iteration : 2503 , loss : 4.0937042236328125\n",
      "iteration : 2504 , loss : 4.127181053161621\n",
      "iteration : 2505 , loss : 4.062026500701904\n",
      "iteration : 2506 , loss : 4.02976131439209\n",
      "iteration : 2507 , loss : 4.157003402709961\n",
      "iteration : 2508 , loss : 3.618901252746582\n",
      "iteration : 2509 , loss : 4.111556053161621\n",
      "iteration : 2510 , loss : 4.071824550628662\n",
      "iteration : 2511 , loss : 3.7312161922454834\n",
      "iteration : 2512 , loss : 4.101711273193359\n",
      "iteration : 2513 , loss : 3.831965684890747\n",
      "iteration : 2514 , loss : 4.062521457672119\n",
      "iteration : 2515 , loss : 3.871669292449951\n",
      "iteration : 2516 , loss : 3.871006727218628\n",
      "iteration : 2517 , loss : 4.116814136505127\n",
      "iteration : 2518 , loss : 3.826528549194336\n",
      "iteration : 2519 , loss : 3.9974489212036133\n",
      "iteration : 2520 , loss : 3.999298334121704\n",
      "iteration : 2521 , loss : 4.075589179992676\n",
      "iteration : 2522 , loss : 3.8938028812408447\n",
      "iteration : 2523 , loss : 4.284555912017822\n",
      "iteration : 2524 , loss : 4.300378799438477\n",
      "iteration : 2525 , loss : 4.170410633087158\n",
      "iteration : 2526 , loss : 4.157159805297852\n",
      "iteration : 2527 , loss : 3.7331883907318115\n",
      "iteration : 2528 , loss : 3.865835666656494\n",
      "iteration : 2529 , loss : 3.9631049633026123\n",
      "iteration : 2530 , loss : 4.056869983673096\n",
      "iteration : 2531 , loss : 4.052996635437012\n",
      "iteration : 2532 , loss : 3.722398042678833\n",
      "iteration : 2533 , loss : 3.935591459274292\n",
      "iteration : 2534 , loss : 3.970158815383911\n",
      "iteration : 2535 , loss : 4.081783294677734\n",
      "iteration : 2536 , loss : 4.088971138000488\n",
      "iteration : 2537 , loss : 3.958954334259033\n",
      "iteration : 2538 , loss : 3.889962673187256\n",
      "iteration : 2539 , loss : 4.020463943481445\n",
      "iteration : 2540 , loss : 3.837458848953247\n",
      "iteration : 2541 , loss : 3.6875975131988525\n",
      "iteration : 2542 , loss : 3.9388482570648193\n",
      "iteration : 2543 , loss : 3.8578903675079346\n",
      "iteration : 2544 , loss : 4.129757404327393\n",
      "iteration : 2545 , loss : 4.109700679779053\n",
      "iteration : 2546 , loss : 3.8802309036254883\n",
      "iteration : 2547 , loss : 4.18757963180542\n",
      "iteration : 2548 , loss : 4.119438171386719\n",
      "iteration : 2549 , loss : 3.855823278427124\n",
      "iteration : 2550 , loss : 3.9320566654205322\n",
      "iteration : 2551 , loss : 4.155699253082275\n",
      "iteration : 2552 , loss : 4.268463134765625\n",
      "iteration : 2553 , loss : 3.8528895378112793\n",
      "iteration : 2554 , loss : 3.8717191219329834\n",
      "iteration : 2555 , loss : 4.243503570556641\n",
      "iteration : 2556 , loss : 3.841038942337036\n",
      "iteration : 2557 , loss : 3.960616111755371\n",
      "iteration : 2558 , loss : 4.070346832275391\n",
      "iteration : 2559 , loss : 4.011250972747803\n",
      "iteration : 2560 , loss : 3.9192099571228027\n",
      "iteration : 2561 , loss : 4.000694751739502\n",
      "iteration : 2562 , loss : 4.029340744018555\n",
      "iteration : 2563 , loss : 4.031500339508057\n",
      "iteration : 2564 , loss : 4.061117172241211\n",
      "iteration : 2565 , loss : 3.742068290710449\n",
      "iteration : 2566 , loss : 3.8395066261291504\n",
      "iteration : 2567 , loss : 3.576150417327881\n",
      "iteration : 2568 , loss : 4.018935680389404\n",
      "iteration : 2569 , loss : 4.008033275604248\n",
      "iteration : 2570 , loss : 3.851539134979248\n",
      "iteration : 2571 , loss : 3.9160499572753906\n",
      "iteration : 2572 , loss : 4.197748184204102\n",
      "iteration : 2573 , loss : 4.068771839141846\n",
      "iteration : 2574 , loss : 3.990706443786621\n",
      "iteration : 2575 , loss : 3.8290343284606934\n",
      "iteration : 2576 , loss : 3.8908073902130127\n",
      "iteration : 2577 , loss : 3.9213924407958984\n",
      "iteration : 2578 , loss : 3.8463945388793945\n",
      "iteration : 2579 , loss : 4.076410293579102\n",
      "iteration : 2580 , loss : 3.72776460647583\n",
      "iteration : 2581 , loss : 4.457285404205322\n",
      "iteration : 2582 , loss : 3.875710964202881\n",
      "iteration : 2583 , loss : 4.0369343757629395\n",
      "iteration : 2584 , loss : 4.087070941925049\n",
      "iteration : 2585 , loss : 3.8519229888916016\n",
      "iteration : 2586 , loss : 4.209815979003906\n",
      "iteration : 2587 , loss : 4.0354790687561035\n",
      "iteration : 2588 , loss : 3.97694730758667\n",
      "iteration : 2589 , loss : 4.303800106048584\n",
      "iteration : 2590 , loss : 4.097670078277588\n",
      "iteration : 2591 , loss : 4.063883304595947\n",
      "iteration : 2592 , loss : 3.7107651233673096\n",
      "iteration : 2593 , loss : 3.800739049911499\n",
      "iteration : 2594 , loss : 3.975701093673706\n",
      "iteration : 2595 , loss : 4.113879680633545\n",
      "iteration : 2596 , loss : 3.996973991394043\n",
      "iteration : 2597 , loss : 4.3720831871032715\n",
      "iteration : 2598 , loss : 3.9075891971588135\n",
      "iteration : 2599 , loss : 4.064675807952881\n",
      "iteration : 2600 , loss : 3.5990357398986816\n",
      "iteration : 2601 , loss : 4.093867301940918\n",
      "iteration : 2602 , loss : 3.9323434829711914\n",
      "iteration : 2603 , loss : 3.789374828338623\n",
      "iteration : 2604 , loss : 3.974234104156494\n",
      "iteration : 2605 , loss : 4.155497074127197\n",
      "iteration : 2606 , loss : 4.07997465133667\n",
      "iteration : 2607 , loss : 3.930936574935913\n",
      "iteration : 2608 , loss : 3.701312780380249\n",
      "iteration : 2609 , loss : 3.7616915702819824\n",
      "iteration : 2610 , loss : 3.5955662727355957\n",
      "iteration : 2611 , loss : 3.922900915145874\n",
      "iteration : 2612 , loss : 3.9777579307556152\n",
      "iteration : 2613 , loss : 4.1196465492248535\n",
      "iteration : 2614 , loss : 4.158806800842285\n",
      "iteration : 2615 , loss : 3.9372243881225586\n",
      "iteration : 2616 , loss : 4.057053089141846\n",
      "iteration : 2617 , loss : 3.953746795654297\n",
      "iteration : 2618 , loss : 4.010191440582275\n",
      "iteration : 2619 , loss : 3.7110612392425537\n",
      "iteration : 2620 , loss : 3.9581520557403564\n",
      "iteration : 2621 , loss : 3.9638185501098633\n",
      "iteration : 2622 , loss : 3.7412538528442383\n",
      "iteration : 2623 , loss : 3.906996965408325\n",
      "iteration : 2624 , loss : 3.776276111602783\n",
      "iteration : 2625 , loss : 4.176355361938477\n",
      "iteration : 2626 , loss : 4.002013683319092\n",
      "iteration : 2627 , loss : 4.1098952293396\n",
      "iteration : 2628 , loss : 4.17262077331543\n",
      "iteration : 2629 , loss : 3.860966205596924\n",
      "iteration : 2630 , loss : 3.7715189456939697\n",
      "iteration : 2631 , loss : 3.8468785285949707\n",
      "iteration : 2632 , loss : 4.098640441894531\n",
      "iteration : 2633 , loss : 3.997361898422241\n",
      "iteration : 2634 , loss : 4.196114540100098\n",
      "iteration : 2635 , loss : 3.9486947059631348\n",
      "iteration : 2636 , loss : 4.093724727630615\n",
      "iteration : 2637 , loss : 4.038360595703125\n",
      "iteration : 2638 , loss : 4.141629695892334\n",
      "iteration : 2639 , loss : 3.8067662715911865\n",
      "iteration : 2640 , loss : 3.853273391723633\n",
      "iteration : 2641 , loss : 3.912278413772583\n",
      "iteration : 2642 , loss : 3.9003541469573975\n",
      "iteration : 2643 , loss : 3.7810733318328857\n",
      "iteration : 2644 , loss : 3.8439218997955322\n",
      "iteration : 2645 , loss : 3.8716790676116943\n",
      "iteration : 2646 , loss : 3.9320733547210693\n",
      "iteration : 2647 , loss : 3.8220510482788086\n",
      "iteration : 2648 , loss : 4.081206798553467\n",
      "iteration : 2649 , loss : 3.922731399536133\n",
      "iteration : 2650 , loss : 3.9788615703582764\n",
      "iteration : 2651 , loss : 3.9443912506103516\n",
      "iteration : 2652 , loss : 4.080067157745361\n",
      "iteration : 2653 , loss : 3.7506420612335205\n",
      "iteration : 2654 , loss : 3.8448925018310547\n",
      "iteration : 2655 , loss : 3.8215854167938232\n",
      "iteration : 2656 , loss : 3.7955245971679688\n",
      "iteration : 2657 , loss : 3.768730640411377\n",
      "iteration : 2658 , loss : 3.906935214996338\n",
      "iteration : 2659 , loss : 3.8006367683410645\n",
      "iteration : 2660 , loss : 4.062145233154297\n",
      "iteration : 2661 , loss : 4.148432731628418\n",
      "iteration : 2662 , loss : 4.036181449890137\n",
      "iteration : 2663 , loss : 3.706341028213501\n",
      "iteration : 2664 , loss : 4.346789360046387\n",
      "iteration : 2665 , loss : 3.669938802719116\n",
      "iteration : 2666 , loss : 4.0510783195495605\n",
      "iteration : 2667 , loss : 4.025717735290527\n",
      "iteration : 2668 , loss : 3.8690435886383057\n",
      "iteration : 2669 , loss : 3.802441120147705\n",
      "iteration : 2670 , loss : 3.8149800300598145\n",
      "iteration : 2671 , loss : 4.136509895324707\n",
      "iteration : 2672 , loss : 3.769927501678467\n",
      "iteration : 2673 , loss : 3.8927321434020996\n",
      "iteration : 2674 , loss : 4.065738677978516\n",
      "iteration : 2675 , loss : 4.096871852874756\n",
      "iteration : 2676 , loss : 3.5068302154541016\n",
      "iteration : 2677 , loss : 4.039294719696045\n",
      "iteration : 2678 , loss : 3.9827117919921875\n",
      "iteration : 2679 , loss : 4.329834938049316\n",
      "iteration : 2680 , loss : 3.8692538738250732\n",
      "iteration : 2681 , loss : 3.840228796005249\n",
      "iteration : 2682 , loss : 3.8668665885925293\n",
      "iteration : 2683 , loss : 3.813570499420166\n",
      "iteration : 2684 , loss : 3.764047861099243\n",
      "iteration : 2685 , loss : 3.9735260009765625\n",
      "iteration : 2686 , loss : 3.730480432510376\n",
      "iteration : 2687 , loss : 4.194479465484619\n",
      "iteration : 2688 , loss : 4.039475917816162\n",
      "iteration : 2689 , loss : 3.4600086212158203\n",
      "iteration : 2690 , loss : 3.753495216369629\n",
      "iteration : 2691 , loss : 3.9600932598114014\n",
      "iteration : 2692 , loss : 4.269060134887695\n",
      "iteration : 2693 , loss : 4.014622688293457\n",
      "iteration : 2694 , loss : 3.8519015312194824\n",
      "iteration : 2695 , loss : 3.664641857147217\n",
      "iteration : 2696 , loss : 3.875352382659912\n",
      "iteration : 2697 , loss : 3.8906803131103516\n",
      "iteration : 2698 , loss : 3.940633535385132\n",
      "iteration : 2699 , loss : 3.9129621982574463\n",
      "iteration : 2700 , loss : 3.7390553951263428\n",
      "iteration : 2701 , loss : 3.963961124420166\n",
      "iteration : 2702 , loss : 3.930330276489258\n",
      "iteration : 2703 , loss : 3.7367982864379883\n",
      "iteration : 2704 , loss : 3.966073751449585\n",
      "iteration : 2705 , loss : 3.679718255996704\n",
      "iteration : 2706 , loss : 3.9718165397644043\n",
      "iteration : 2707 , loss : 4.125416278839111\n",
      "iteration : 2708 , loss : 3.9130911827087402\n",
      "iteration : 2709 , loss : 3.981921434402466\n",
      "iteration : 2710 , loss : 3.7624073028564453\n",
      "iteration : 2711 , loss : 3.943681001663208\n",
      "iteration : 2712 , loss : 3.700744152069092\n",
      "iteration : 2713 , loss : 3.99609375\n",
      "iteration : 2714 , loss : 3.940473794937134\n",
      "iteration : 2715 , loss : 3.7859585285186768\n",
      "iteration : 2716 , loss : 3.883899211883545\n",
      "iteration : 2717 , loss : 4.017329692840576\n",
      "iteration : 2718 , loss : 4.03458309173584\n",
      "iteration : 2719 , loss : 3.8268966674804688\n",
      "iteration : 2720 , loss : 3.7164463996887207\n",
      "iteration : 2721 , loss : 3.793172597885132\n",
      "iteration : 2722 , loss : 3.6872568130493164\n",
      "iteration : 2723 , loss : 3.822031021118164\n",
      "iteration : 2724 , loss : 3.9094855785369873\n",
      "iteration : 2725 , loss : 4.1007981300354\n",
      "iteration : 2726 , loss : 3.7844743728637695\n",
      "iteration : 2727 , loss : 3.8745992183685303\n",
      "iteration : 2728 , loss : 3.8071978092193604\n",
      "iteration : 2729 , loss : 3.7298130989074707\n",
      "iteration : 2730 , loss : 3.897397756576538\n",
      "iteration : 2731 , loss : 3.839362859725952\n",
      "iteration : 2732 , loss : 4.0172038078308105\n",
      "iteration : 2733 , loss : 3.562366008758545\n",
      "iteration : 2734 , loss : 3.9198431968688965\n",
      "iteration : 2735 , loss : 4.084797382354736\n",
      "iteration : 2736 , loss : 3.664232015609741\n",
      "iteration : 2737 , loss : 3.7677111625671387\n",
      "iteration : 2738 , loss : 3.8323745727539062\n",
      "iteration : 2739 , loss : 3.850079298019409\n",
      "iteration : 2740 , loss : 3.9388930797576904\n",
      "iteration : 2741 , loss : 4.152153968811035\n",
      "iteration : 2742 , loss : 3.888648748397827\n",
      "iteration : 2743 , loss : 3.947824478149414\n",
      "iteration : 2744 , loss : 3.809919834136963\n",
      "iteration : 2745 , loss : 3.9508724212646484\n",
      "iteration : 2746 , loss : 4.00593900680542\n",
      "iteration : 2747 , loss : 3.785869836807251\n",
      "iteration : 2748 , loss : 3.7429986000061035\n",
      "iteration : 2749 , loss : 4.14024543762207\n",
      "iteration : 2750 , loss : 3.973609209060669\n",
      "iteration : 2751 , loss : 4.08967924118042\n",
      "iteration : 2752 , loss : 3.674666166305542\n",
      "iteration : 2753 , loss : 3.6515166759490967\n",
      "iteration : 2754 , loss : 4.168172836303711\n",
      "iteration : 2755 , loss : 4.214895248413086\n",
      "iteration : 2756 , loss : 3.9490280151367188\n",
      "iteration : 2757 , loss : 3.8406567573547363\n",
      "iteration : 2758 , loss : 3.822357416152954\n",
      "iteration : 2759 , loss : 4.239184379577637\n",
      "iteration : 2760 , loss : 4.172412395477295\n",
      "iteration : 2761 , loss : 3.614330530166626\n",
      "iteration : 2762 , loss : 3.5897207260131836\n",
      "iteration : 2763 , loss : 4.307917594909668\n",
      "iteration : 2764 , loss : 4.078701019287109\n",
      "iteration : 2765 , loss : 3.969543218612671\n",
      "iteration : 2766 , loss : 3.9797251224517822\n",
      "iteration : 2767 , loss : 3.8964641094207764\n",
      "iteration : 2768 , loss : 3.9117815494537354\n",
      "iteration : 2769 , loss : 4.0696892738342285\n",
      "iteration : 2770 , loss : 3.9876725673675537\n",
      "iteration : 2771 , loss : 3.8335509300231934\n",
      "iteration : 2772 , loss : 4.199252605438232\n",
      "iteration : 2773 , loss : 3.7902088165283203\n",
      "iteration : 2774 , loss : 3.6915066242218018\n",
      "iteration : 2775 , loss : 3.9003825187683105\n",
      "iteration : 2776 , loss : 4.009256839752197\n",
      "iteration : 2777 , loss : 3.795419454574585\n",
      "iteration : 2778 , loss : 3.7646520137786865\n",
      "iteration : 2779 , loss : 3.8742973804473877\n",
      "iteration : 2780 , loss : 4.030856609344482\n",
      "iteration : 2781 , loss : 4.081023693084717\n",
      "iteration : 2782 , loss : 3.7858641147613525\n",
      "iteration : 2783 , loss : 3.971073865890503\n",
      "iteration : 2784 , loss : 4.1025285720825195\n",
      "iteration : 2785 , loss : 4.007259845733643\n",
      "iteration : 2786 , loss : 3.7519569396972656\n",
      "iteration : 2787 , loss : 3.9209868907928467\n",
      "iteration : 2788 , loss : 4.207098484039307\n",
      "iteration : 2789 , loss : 3.7888875007629395\n",
      "iteration : 2790 , loss : 3.580103635787964\n",
      "iteration : 2791 , loss : 4.090478897094727\n",
      "iteration : 2792 , loss : 3.892568588256836\n",
      "iteration : 2793 , loss : 3.8382177352905273\n",
      "iteration : 2794 , loss : 3.9828081130981445\n",
      "iteration : 2795 , loss : 4.188756942749023\n",
      "iteration : 2796 , loss : 4.006760120391846\n",
      "iteration : 2797 , loss : 3.843674421310425\n",
      "iteration : 2798 , loss : 4.151787281036377\n",
      "iteration : 2799 , loss : 3.819838047027588\n",
      "iteration : 2800 , loss : 3.783200263977051\n",
      "iteration : 2801 , loss : 4.002418518066406\n",
      "iteration : 2802 , loss : 3.9487686157226562\n",
      "iteration : 2803 , loss : 3.9530715942382812\n",
      "iteration : 2804 , loss : 3.710017681121826\n",
      "iteration : 2805 , loss : 4.066429138183594\n",
      "iteration : 2806 , loss : 3.789423942565918\n",
      "iteration : 2807 , loss : 3.9355475902557373\n",
      "iteration : 2808 , loss : 4.188127040863037\n",
      "iteration : 2809 , loss : 4.06210470199585\n",
      "iteration : 2810 , loss : 3.6263787746429443\n",
      "iteration : 2811 , loss : 3.8555469512939453\n",
      "iteration : 2812 , loss : 3.954169750213623\n",
      "iteration : 2813 , loss : 4.135626316070557\n",
      "iteration : 2814 , loss : 3.742788553237915\n",
      "iteration : 2815 , loss : 4.079030513763428\n",
      "iteration : 2816 , loss : 3.584278106689453\n",
      "iteration : 2817 , loss : 3.673480749130249\n",
      "iteration : 2818 , loss : 3.8715288639068604\n",
      "iteration : 2819 , loss : 4.055673122406006\n",
      "iteration : 2820 , loss : 3.8773674964904785\n",
      "iteration : 2821 , loss : 4.102813243865967\n",
      "iteration : 2822 , loss : 3.8998284339904785\n",
      "iteration : 2823 , loss : 3.9634034633636475\n",
      "iteration : 2824 , loss : 4.068307399749756\n",
      "iteration : 2825 , loss : 4.042603969573975\n",
      "iteration : 2826 , loss : 4.060131549835205\n",
      "iteration : 2827 , loss : 3.9608559608459473\n",
      "iteration : 2828 , loss : 3.7733516693115234\n",
      "iteration : 2829 , loss : 4.109951972961426\n",
      "iteration : 2830 , loss : 3.9964330196380615\n",
      "iteration : 2831 , loss : 3.6595818996429443\n",
      "iteration : 2832 , loss : 3.690403938293457\n",
      "iteration : 2833 , loss : 4.126078128814697\n",
      "iteration : 2834 , loss : 3.848207712173462\n",
      "iteration : 2835 , loss : 4.062196254730225\n",
      "iteration : 2836 , loss : 3.9203479290008545\n",
      "iteration : 2837 , loss : 3.6122753620147705\n",
      "iteration : 2838 , loss : 3.761146068572998\n",
      "iteration : 2839 , loss : 3.8379082679748535\n",
      "iteration : 2840 , loss : 3.7977678775787354\n",
      "iteration : 2841 , loss : 3.961169958114624\n",
      "iteration : 2842 , loss : 3.8687331676483154\n",
      "iteration : 2843 , loss : 3.80196475982666\n",
      "iteration : 2844 , loss : 4.0136332511901855\n",
      "iteration : 2845 , loss : 3.938453435897827\n",
      "iteration : 2846 , loss : 3.8890798091888428\n",
      "iteration : 2847 , loss : 3.83171010017395\n",
      "iteration : 2848 , loss : 4.095046043395996\n",
      "iteration : 2849 , loss : 4.021047592163086\n",
      "iteration : 2850 , loss : 3.8297810554504395\n",
      "iteration : 2851 , loss : 4.129347801208496\n",
      "iteration : 2852 , loss : 3.9690210819244385\n",
      "iteration : 2853 , loss : 4.055130481719971\n",
      "iteration : 2854 , loss : 4.049445629119873\n",
      "iteration : 2855 , loss : 3.9414258003234863\n",
      "iteration : 2856 , loss : 4.050912857055664\n",
      "iteration : 2857 , loss : 3.9482102394104004\n",
      "iteration : 2858 , loss : 3.919468879699707\n",
      "iteration : 2859 , loss : 3.876673698425293\n",
      "iteration : 2860 , loss : 3.9678285121917725\n",
      "iteration : 2861 , loss : 3.945728302001953\n",
      "iteration : 2862 , loss : 3.763479232788086\n",
      "iteration : 2863 , loss : 3.9965620040893555\n",
      "iteration : 2864 , loss : 4.043302059173584\n",
      "iteration : 2865 , loss : 3.780942440032959\n",
      "iteration : 2866 , loss : 3.8342201709747314\n",
      "iteration : 2867 , loss : 4.01589822769165\n",
      "iteration : 2868 , loss : 3.8323893547058105\n",
      "iteration : 2869 , loss : 3.8409104347229004\n",
      "iteration : 2870 , loss : 3.885589361190796\n",
      "iteration : 2871 , loss : 4.105194091796875\n",
      "iteration : 2872 , loss : 3.7375752925872803\n",
      "iteration : 2873 , loss : 4.14680814743042\n",
      "iteration : 2874 , loss : 4.042505264282227\n",
      "iteration : 2875 , loss : 4.192702770233154\n",
      "iteration : 2876 , loss : 4.080784320831299\n",
      "iteration : 2877 , loss : 4.053536891937256\n",
      "iteration : 2878 , loss : 3.9224977493286133\n",
      "iteration : 2879 , loss : 3.8850021362304688\n",
      "iteration : 2880 , loss : 4.117958068847656\n",
      "iteration : 2881 , loss : 3.9225151538848877\n",
      "iteration : 2882 , loss : 4.167816638946533\n",
      "iteration : 2883 , loss : 4.155579090118408\n",
      "iteration : 2884 , loss : 4.032046794891357\n",
      "iteration : 2885 , loss : 3.8585009574890137\n",
      "iteration : 2886 , loss : 4.261773586273193\n",
      "iteration : 2887 , loss : 4.119424819946289\n",
      "iteration : 2888 , loss : 3.823485851287842\n",
      "iteration : 2889 , loss : 3.5878751277923584\n",
      "iteration : 2890 , loss : 3.7525863647460938\n",
      "iteration : 2891 , loss : 4.172497749328613\n",
      "iteration : 2892 , loss : 3.857438087463379\n",
      "iteration : 2893 , loss : 4.0272216796875\n",
      "iteration : 2894 , loss : 3.984865427017212\n",
      "iteration : 2895 , loss : 4.008396625518799\n",
      "iteration : 2896 , loss : 3.8955554962158203\n",
      "iteration : 2897 , loss : 3.826707363128662\n",
      "iteration : 2898 , loss : 3.9501752853393555\n",
      "iteration : 2899 , loss : 3.816744565963745\n",
      "iteration : 2900 , loss : 3.7584686279296875\n",
      "iteration : 2901 , loss : 3.7674272060394287\n",
      "iteration : 2902 , loss : 3.9575281143188477\n",
      "iteration : 2903 , loss : 3.940326690673828\n",
      "iteration : 2904 , loss : 3.9312267303466797\n",
      "iteration : 2905 , loss : 4.199563980102539\n",
      "iteration : 2906 , loss : 3.8645246028900146\n",
      "iteration : 2907 , loss : 4.123176574707031\n",
      "iteration : 2908 , loss : 3.9855403900146484\n",
      "iteration : 2909 , loss : 4.061086177825928\n",
      "iteration : 2910 , loss : 3.6309726238250732\n",
      "iteration : 2911 , loss : 3.9144275188446045\n",
      "iteration : 2912 , loss : 3.71256947517395\n",
      "iteration : 2913 , loss : 3.7423763275146484\n",
      "iteration : 2914 , loss : 3.7764205932617188\n",
      "iteration : 2915 , loss : 3.885418176651001\n",
      "iteration : 2916 , loss : 3.77602481842041\n",
      "iteration : 2917 , loss : 3.937326192855835\n",
      "iteration : 2918 , loss : 4.326160430908203\n",
      "iteration : 2919 , loss : 4.1865715980529785\n",
      "iteration : 2920 , loss : 3.6941909790039062\n",
      "iteration : 2921 , loss : 3.8861570358276367\n",
      "iteration : 2922 , loss : 4.084500789642334\n",
      "iteration : 2923 , loss : 3.827633857727051\n",
      "iteration : 2924 , loss : 3.768268346786499\n",
      "iteration : 2925 , loss : 4.170815944671631\n",
      "iteration : 2926 , loss : 3.963974952697754\n",
      "iteration : 2927 , loss : 3.8414149284362793\n",
      "iteration : 2928 , loss : 3.815972089767456\n",
      "iteration : 2929 , loss : 3.836756467819214\n",
      "iteration : 2930 , loss : 3.8894762992858887\n",
      "iteration : 2931 , loss : 3.9945831298828125\n",
      "iteration : 2932 , loss : 3.8809165954589844\n",
      "iteration : 2933 , loss : 3.8393442630767822\n",
      "iteration : 2934 , loss : 3.9561593532562256\n",
      "iteration : 2935 , loss : 4.3347697257995605\n",
      "iteration : 2936 , loss : 4.131973743438721\n",
      "iteration : 2937 , loss : 4.134061813354492\n",
      "iteration : 2938 , loss : 4.20197868347168\n",
      "iteration : 2939 , loss : 3.7751340866088867\n",
      "iteration : 2940 , loss : 3.644190549850464\n",
      "iteration : 2941 , loss : 3.875312089920044\n",
      "iteration : 2942 , loss : 3.9519999027252197\n",
      "iteration : 2943 , loss : 3.7920608520507812\n",
      "iteration : 2944 , loss : 3.8366847038269043\n",
      "iteration : 2945 , loss : 3.9369804859161377\n",
      "iteration : 2946 , loss : 3.9524056911468506\n",
      "iteration : 2947 , loss : 3.924241542816162\n",
      "iteration : 2948 , loss : 4.1505513191223145\n",
      "iteration : 2949 , loss : 4.216067314147949\n",
      "iteration : 2950 , loss : 3.9380476474761963\n",
      "iteration : 2951 , loss : 3.7047152519226074\n",
      "iteration : 2952 , loss : 3.7800021171569824\n",
      "iteration : 2953 , loss : 3.880265474319458\n",
      "iteration : 2954 , loss : 3.7323546409606934\n",
      "iteration : 2955 , loss : 3.772080421447754\n",
      "iteration : 2956 , loss : 3.9203271865844727\n",
      "iteration : 2957 , loss : 3.7160370349884033\n",
      "iteration : 2958 , loss : 3.842090368270874\n",
      "iteration : 2959 , loss : 3.939349889755249\n",
      "iteration : 2960 , loss : 4.019798755645752\n",
      "iteration : 2961 , loss : 4.03722620010376\n",
      "iteration : 2962 , loss : 3.8259129524230957\n",
      "iteration : 2963 , loss : 4.252431392669678\n",
      "iteration : 2964 , loss : 4.090174198150635\n",
      "iteration : 2965 , loss : 3.5707550048828125\n",
      "iteration : 2966 , loss : 3.9475009441375732\n",
      "iteration : 2967 , loss : 3.827425241470337\n",
      "iteration : 2968 , loss : 3.95977520942688\n",
      "iteration : 2969 , loss : 3.7892017364501953\n",
      "iteration : 2970 , loss : 3.9564709663391113\n",
      "iteration : 2971 , loss : 3.9000773429870605\n",
      "iteration : 2972 , loss : 3.9934732913970947\n",
      "iteration : 2973 , loss : 3.8010776042938232\n",
      "iteration : 2974 , loss : 3.471169948577881\n",
      "iteration : 2975 , loss : 3.7782485485076904\n",
      "iteration : 2976 , loss : 3.9030261039733887\n",
      "iteration : 2977 , loss : 3.87343168258667\n",
      "iteration : 2978 , loss : 3.8890700340270996\n",
      "iteration : 2979 , loss : 3.848796844482422\n",
      "iteration : 2980 , loss : 4.060366153717041\n",
      "iteration : 2981 , loss : 3.6131248474121094\n",
      "iteration : 2982 , loss : 3.9282596111297607\n",
      "iteration : 2983 , loss : 3.9976158142089844\n",
      "iteration : 2984 , loss : 3.8671295642852783\n",
      "iteration : 2985 , loss : 3.7167296409606934\n",
      "iteration : 2986 , loss : 3.9309301376342773\n",
      "iteration : 2987 , loss : 3.737626075744629\n",
      "iteration : 2988 , loss : 3.8160412311553955\n",
      "iteration : 2989 , loss : 3.7832632064819336\n",
      "iteration : 2990 , loss : 3.8943819999694824\n",
      "iteration : 2991 , loss : 3.9826340675354004\n",
      "iteration : 2992 , loss : 3.621654987335205\n",
      "iteration : 2993 , loss : 4.065436840057373\n",
      "iteration : 2994 , loss : 3.76151704788208\n",
      "iteration : 2995 , loss : 3.8519437313079834\n",
      "iteration : 2996 , loss : 4.069151401519775\n",
      "iteration : 2997 , loss : 3.946718215942383\n",
      "iteration : 2998 , loss : 4.141062259674072\n",
      "iteration : 2999 , loss : 3.694305658340454\n",
      "iteration : 3000 , loss : 4.090841770172119\n",
      "iteration : 3001 , loss : 3.877575159072876\n",
      "iteration : 3002 , loss : 3.337496280670166\n",
      "iteration : 3003 , loss : 3.890160083770752\n",
      "iteration : 3004 , loss : 4.054081439971924\n",
      "iteration : 3005 , loss : 3.838386058807373\n",
      "iteration : 3006 , loss : 4.258423805236816\n",
      "iteration : 3007 , loss : 4.018287658691406\n",
      "iteration : 3008 , loss : 3.7951951026916504\n",
      "iteration : 3009 , loss : 3.8770720958709717\n",
      "iteration : 3010 , loss : 3.8261215686798096\n",
      "iteration : 3011 , loss : 4.128298282623291\n",
      "iteration : 3012 , loss : 3.7837092876434326\n",
      "iteration : 3013 , loss : 3.9628071784973145\n",
      "iteration : 3014 , loss : 3.749481439590454\n",
      "iteration : 3015 , loss : 3.9606478214263916\n",
      "iteration : 3016 , loss : 4.056235313415527\n",
      "iteration : 3017 , loss : 3.8211517333984375\n",
      "iteration : 3018 , loss : 3.9729344844818115\n",
      "iteration : 3019 , loss : 3.9883437156677246\n",
      "iteration : 3020 , loss : 3.709402561187744\n",
      "iteration : 3021 , loss : 3.7597169876098633\n",
      "iteration : 3022 , loss : 3.8831748962402344\n",
      "iteration : 3023 , loss : 3.894648313522339\n",
      "iteration : 3024 , loss : 3.8928983211517334\n",
      "iteration : 3025 , loss : 3.7961201667785645\n",
      "iteration : 3026 , loss : 3.4675509929656982\n",
      "iteration : 3027 , loss : 3.945216417312622\n",
      "iteration : 3028 , loss : 3.861755609512329\n",
      "iteration : 3029 , loss : 3.9673125743865967\n",
      "iteration : 3030 , loss : 3.8189895153045654\n",
      "iteration : 3031 , loss : 3.7289116382598877\n",
      "iteration : 3032 , loss : 3.7847931385040283\n",
      "iteration : 3033 , loss : 3.9158666133880615\n",
      "iteration : 3034 , loss : 4.005137920379639\n",
      "iteration : 3035 , loss : 4.314244747161865\n",
      "iteration : 3036 , loss : 3.839520215988159\n",
      "iteration : 3037 , loss : 4.034290313720703\n",
      "iteration : 3038 , loss : 4.048081398010254\n",
      "iteration : 3039 , loss : 4.099857807159424\n",
      "iteration : 3040 , loss : 3.8602590560913086\n",
      "iteration : 3041 , loss : 4.039236545562744\n",
      "iteration : 3042 , loss : 3.8000752925872803\n",
      "iteration : 3043 , loss : 3.704132318496704\n",
      "iteration : 3044 , loss : 3.8690733909606934\n",
      "iteration : 3045 , loss : 3.6628551483154297\n",
      "iteration : 3046 , loss : 3.808372974395752\n",
      "iteration : 3047 , loss : 3.9832050800323486\n",
      "iteration : 3048 , loss : 3.644456624984741\n",
      "iteration : 3049 , loss : 4.128318786621094\n",
      "iteration : 3050 , loss : 3.8341028690338135\n",
      "iteration : 3051 , loss : 4.031282424926758\n",
      "iteration : 3052 , loss : 4.007826328277588\n",
      "iteration : 3053 , loss : 4.136588096618652\n",
      "iteration : 3054 , loss : 3.89227557182312\n",
      "iteration : 3055 , loss : 4.027403354644775\n",
      "iteration : 3056 , loss : 3.580069065093994\n",
      "iteration : 3057 , loss : 3.422262668609619\n",
      "iteration : 3058 , loss : 3.8631067276000977\n",
      "iteration : 3059 , loss : 3.7615439891815186\n",
      "iteration : 3060 , loss : 3.6737635135650635\n",
      "iteration : 3061 , loss : 3.7448623180389404\n",
      "iteration : 3062 , loss : 3.901031017303467\n",
      "iteration : 3063 , loss : 3.455432891845703\n",
      "iteration : 3064 , loss : 4.094048500061035\n",
      "iteration : 3065 , loss : 3.7686898708343506\n",
      "iteration : 3066 , loss : 3.972203493118286\n",
      "iteration : 3067 , loss : 4.035551071166992\n",
      "iteration : 3068 , loss : 3.9262430667877197\n",
      "iteration : 3069 , loss : 4.205569744110107\n",
      "iteration : 3070 , loss : 3.8811187744140625\n",
      "iteration : 3071 , loss : 3.7905828952789307\n",
      "iteration : 3072 , loss : 3.8217661380767822\n",
      "iteration : 3073 , loss : 3.9230904579162598\n",
      "iteration : 3074 , loss : 3.9448018074035645\n",
      "iteration : 3075 , loss : 3.874742269515991\n",
      "iteration : 3076 , loss : 3.896256685256958\n",
      "iteration : 3077 , loss : 4.0304436683654785\n",
      "iteration : 3078 , loss : 4.086926460266113\n",
      "iteration : 3079 , loss : 3.95149564743042\n",
      "iteration : 3080 , loss : 3.744915723800659\n",
      "iteration : 3081 , loss : 3.7579269409179688\n",
      "iteration : 3082 , loss : 4.073031902313232\n",
      "iteration : 3083 , loss : 3.8158750534057617\n",
      "iteration : 3084 , loss : 3.614300012588501\n",
      "iteration : 3085 , loss : 3.62565016746521\n",
      "iteration : 3086 , loss : 3.6244375705718994\n",
      "iteration : 3087 , loss : 3.6563141345977783\n",
      "iteration : 3088 , loss : 3.7657930850982666\n",
      "iteration : 3089 , loss : 3.9802205562591553\n",
      "iteration : 3090 , loss : 3.6132075786590576\n",
      "iteration : 3091 , loss : 3.6695070266723633\n",
      "iteration : 3092 , loss : 4.048783302307129\n",
      "iteration : 3093 , loss : 4.035427570343018\n",
      "iteration : 3094 , loss : 3.842334508895874\n",
      "iteration : 3095 , loss : 3.947373628616333\n",
      "iteration : 3096 , loss : 3.7418599128723145\n",
      "iteration : 3097 , loss : 3.8856821060180664\n",
      "iteration : 3098 , loss : 3.9328536987304688\n",
      "iteration : 3099 , loss : 3.9392735958099365\n",
      "iteration : 3100 , loss : 4.26007604598999\n",
      "iteration : 3101 , loss : 3.952256679534912\n",
      "iteration : 3102 , loss : 3.9717307090759277\n",
      "iteration : 3103 , loss : 4.1309027671813965\n",
      "iteration : 3104 , loss : 4.1249847412109375\n",
      "iteration : 3105 , loss : 3.9656031131744385\n",
      "iteration : 3106 , loss : 3.9596447944641113\n",
      "iteration : 3107 , loss : 3.73850154876709\n",
      "iteration : 3108 , loss : 3.7939538955688477\n",
      "iteration : 3109 , loss : 3.870549201965332\n",
      "iteration : 3110 , loss : 3.785346031188965\n",
      "iteration : 3111 , loss : 3.739784002304077\n",
      "iteration : 3112 , loss : 3.727632761001587\n",
      "iteration : 3113 , loss : 4.138631343841553\n",
      "iteration : 3114 , loss : 3.891258955001831\n",
      "iteration : 3115 , loss : 3.9139106273651123\n",
      "iteration : 3116 , loss : 3.8954551219940186\n",
      "iteration : 3117 , loss : 3.679802656173706\n",
      "iteration : 3118 , loss : 4.0799431800842285\n",
      "iteration : 3119 , loss : 3.8749260902404785\n",
      "iteration : 3120 , loss : 4.057165622711182\n",
      "iteration : 3121 , loss : 3.562950849533081\n",
      "iteration : 3122 , loss : 4.117431163787842\n",
      "iteration : 3123 , loss : 3.8178844451904297\n",
      "iteration : 3124 , loss : 3.778453826904297\n",
      "iteration : 3125 , loss : 4.034219741821289\n",
      "iteration : 3126 , loss : 3.8960139751434326\n",
      "iteration : 3127 , loss : 3.601670742034912\n",
      "iteration : 3128 , loss : 3.6258983612060547\n",
      "iteration : 3129 , loss : 4.137001037597656\n",
      "iteration : 3130 , loss : 3.6056883335113525\n",
      "iteration : 3131 , loss : 4.167211532592773\n",
      "iteration : 3132 , loss : 3.959214210510254\n",
      "iteration : 3133 , loss : 3.737520456314087\n",
      "iteration : 3134 , loss : 3.5877463817596436\n",
      "iteration : 3135 , loss : 3.779968738555908\n",
      "iteration : 3136 , loss : 3.768406391143799\n",
      "iteration : 3137 , loss : 3.9873390197753906\n",
      "iteration : 3138 , loss : 3.8199241161346436\n",
      "iteration : 3139 , loss : 3.768928050994873\n",
      "iteration : 3140 , loss : 3.924929618835449\n",
      "iteration : 3141 , loss : 3.8535804748535156\n",
      "iteration : 3142 , loss : 3.907010316848755\n",
      "iteration : 3143 , loss : 3.9469354152679443\n",
      "iteration : 3144 , loss : 3.9692888259887695\n",
      "iteration : 3145 , loss : 3.758878231048584\n",
      "iteration : 3146 , loss : 3.8157153129577637\n",
      "iteration : 3147 , loss : 3.9286274909973145\n",
      "iteration : 3148 , loss : 3.8430862426757812\n",
      "iteration : 3149 , loss : 3.626795530319214\n",
      "iteration : 3150 , loss : 3.6923489570617676\n",
      "iteration : 3151 , loss : 3.8020944595336914\n",
      "iteration : 3152 , loss : 3.799947500228882\n",
      "iteration : 3153 , loss : 3.8948583602905273\n",
      "iteration : 3154 , loss : 3.6194512844085693\n",
      "iteration : 3155 , loss : 3.9142744541168213\n",
      "iteration : 3156 , loss : 3.8620870113372803\n",
      "iteration : 3157 , loss : 4.064455509185791\n",
      "iteration : 3158 , loss : 3.912940740585327\n",
      "iteration : 3159 , loss : 3.9697439670562744\n",
      "iteration : 3160 , loss : 3.8520445823669434\n",
      "iteration : 3161 , loss : 3.831099271774292\n",
      "iteration : 3162 , loss : 3.688729763031006\n",
      "iteration : 3163 , loss : 3.688688039779663\n",
      "iteration : 3164 , loss : 3.9665780067443848\n",
      "iteration : 3165 , loss : 3.660956382751465\n",
      "iteration : 3166 , loss : 4.171548366546631\n",
      "iteration : 3167 , loss : 3.9674229621887207\n",
      "iteration : 3168 , loss : 4.132214546203613\n",
      "iteration : 3169 , loss : 3.9734184741973877\n",
      "iteration : 3170 , loss : 3.890942335128784\n",
      "iteration : 3171 , loss : 3.6519646644592285\n",
      "iteration : 3172 , loss : 3.7651712894439697\n",
      "iteration : 3173 , loss : 3.936504602432251\n",
      "iteration : 3174 , loss : 3.9291908740997314\n",
      "iteration : 3175 , loss : 3.791781425476074\n",
      "iteration : 3176 , loss : 3.6890616416931152\n",
      "iteration : 3177 , loss : 3.375739336013794\n",
      "iteration : 3178 , loss : 3.914318561553955\n",
      "iteration : 3179 , loss : 3.84102725982666\n",
      "iteration : 3180 , loss : 3.670013189315796\n",
      "iteration : 3181 , loss : 3.751805543899536\n",
      "iteration : 3182 , loss : 4.135946750640869\n",
      "iteration : 3183 , loss : 3.688180923461914\n",
      "iteration : 3184 , loss : 4.128476142883301\n",
      "iteration : 3185 , loss : 3.9008307456970215\n",
      "iteration : 3186 , loss : 3.6487174034118652\n",
      "iteration : 3187 , loss : 3.7158401012420654\n",
      "iteration : 3188 , loss : 4.060844421386719\n",
      "iteration : 3189 , loss : 3.881906032562256\n",
      "iteration : 3190 , loss : 4.081902980804443\n",
      "iteration : 3191 , loss : 3.9305918216705322\n",
      "iteration : 3192 , loss : 3.819383382797241\n",
      "iteration : 3193 , loss : 4.173070430755615\n",
      "iteration : 3194 , loss : 3.8584253787994385\n",
      "iteration : 3195 , loss : 3.63889741897583\n",
      "iteration : 3196 , loss : 3.7473342418670654\n",
      "iteration : 3197 , loss : 4.003251075744629\n",
      "iteration : 3198 , loss : 3.6497068405151367\n",
      "iteration : 3199 , loss : 3.9513132572174072\n",
      "iteration : 3200 , loss : 4.206271171569824\n",
      "iteration : 3201 , loss : 3.5769662857055664\n",
      "iteration : 3202 , loss : 3.6887764930725098\n",
      "iteration : 3203 , loss : 3.7939982414245605\n",
      "iteration : 3204 , loss : 3.7169296741485596\n",
      "iteration : 3205 , loss : 3.815816879272461\n",
      "iteration : 3206 , loss : 3.618190050125122\n",
      "iteration : 3207 , loss : 3.958584785461426\n",
      "iteration : 3208 , loss : 4.012361526489258\n",
      "iteration : 3209 , loss : 3.7561259269714355\n",
      "iteration : 3210 , loss : 3.7567412853240967\n",
      "iteration : 3211 , loss : 3.8667197227478027\n",
      "iteration : 3212 , loss : 3.8073863983154297\n",
      "iteration : 3213 , loss : 4.030398845672607\n",
      "iteration : 3214 , loss : 3.862433671951294\n",
      "iteration : 3215 , loss : 3.7331600189208984\n",
      "iteration : 3216 , loss : 3.849604606628418\n",
      "iteration : 3217 , loss : 3.7299983501434326\n",
      "iteration : 3218 , loss : 3.999382734298706\n",
      "iteration : 3219 , loss : 3.866337776184082\n",
      "iteration : 3220 , loss : 4.0071611404418945\n",
      "iteration : 3221 , loss : 3.890343189239502\n",
      "iteration : 3222 , loss : 3.653008222579956\n",
      "iteration : 3223 , loss : 3.838825225830078\n",
      "iteration : 3224 , loss : 3.7750942707061768\n",
      "iteration : 3225 , loss : 3.833095073699951\n",
      "iteration : 3226 , loss : 3.891045570373535\n",
      "iteration : 3227 , loss : 3.672354221343994\n",
      "iteration : 3228 , loss : 3.9524452686309814\n",
      "iteration : 3229 , loss : 3.931631326675415\n",
      "iteration : 3230 , loss : 3.897308349609375\n",
      "iteration : 3231 , loss : 3.616987466812134\n",
      "iteration : 3232 , loss : 3.863252878189087\n",
      "iteration : 3233 , loss : 4.089972972869873\n",
      "iteration : 3234 , loss : 3.772939682006836\n",
      "iteration : 3235 , loss : 4.023207664489746\n",
      "iteration : 3236 , loss : 3.9931204319000244\n",
      "iteration : 3237 , loss : 3.7926034927368164\n",
      "iteration : 3238 , loss : 3.895372152328491\n",
      "iteration : 3239 , loss : 3.8385915756225586\n",
      "iteration : 3240 , loss : 4.109960556030273\n",
      "iteration : 3241 , loss : 3.7598652839660645\n",
      "iteration : 3242 , loss : 3.8634493350982666\n",
      "iteration : 3243 , loss : 4.055628776550293\n",
      "iteration : 3244 , loss : 3.667724609375\n",
      "iteration : 3245 , loss : 3.815748929977417\n",
      "iteration : 3246 , loss : 4.043128967285156\n",
      "iteration : 3247 , loss : 3.9752376079559326\n",
      "iteration : 3248 , loss : 3.9109747409820557\n",
      "iteration : 3249 , loss : 3.7201879024505615\n",
      "iteration : 3250 , loss : 3.9918770790100098\n",
      "iteration : 3251 , loss : 4.049841403961182\n",
      "iteration : 3252 , loss : 4.230852127075195\n",
      "iteration : 3253 , loss : 4.094935417175293\n",
      "iteration : 3254 , loss : 3.616753101348877\n",
      "iteration : 3255 , loss : 3.736285924911499\n",
      "iteration : 3256 , loss : 4.093569755554199\n",
      "iteration : 3257 , loss : 3.891756296157837\n",
      "iteration : 3258 , loss : 3.8224406242370605\n",
      "iteration : 3259 , loss : 3.9307591915130615\n",
      "iteration : 3260 , loss : 3.3240833282470703\n",
      "iteration : 3261 , loss : 3.6916306018829346\n",
      "iteration : 3262 , loss : 3.624157667160034\n",
      "iteration : 3263 , loss : 3.5997493267059326\n",
      "iteration : 3264 , loss : 3.7315096855163574\n",
      "iteration : 3265 , loss : 3.7124247550964355\n",
      "iteration : 3266 , loss : 3.80836820602417\n",
      "iteration : 3267 , loss : 3.752732515335083\n",
      "iteration : 3268 , loss : 3.714477300643921\n",
      "iteration : 3269 , loss : 4.016236305236816\n",
      "iteration : 3270 , loss : 3.9956469535827637\n",
      "iteration : 3271 , loss : 3.805906295776367\n",
      "iteration : 3272 , loss : 3.9111037254333496\n",
      "iteration : 3273 , loss : 3.7181925773620605\n",
      "iteration : 3274 , loss : 3.5164527893066406\n",
      "iteration : 3275 , loss : 3.8618996143341064\n",
      "iteration : 3276 , loss : 3.537557363510132\n",
      "iteration : 3277 , loss : 4.04712438583374\n",
      "iteration : 3278 , loss : 3.6762635707855225\n",
      "iteration : 3279 , loss : 3.642387866973877\n",
      "iteration : 3280 , loss : 3.7970337867736816\n",
      "iteration : 3281 , loss : 3.6362805366516113\n",
      "iteration : 3282 , loss : 3.8419699668884277\n",
      "iteration : 3283 , loss : 3.9905624389648438\n",
      "iteration : 3284 , loss : 4.056159973144531\n",
      "iteration : 3285 , loss : 3.6381590366363525\n",
      "iteration : 3286 , loss : 3.8698201179504395\n",
      "iteration : 3287 , loss : 4.174317359924316\n",
      "iteration : 3288 , loss : 3.7706494331359863\n",
      "iteration : 3289 , loss : 3.8240864276885986\n",
      "iteration : 3290 , loss : 3.954007863998413\n",
      "iteration : 3291 , loss : 3.557354688644409\n",
      "iteration : 3292 , loss : 3.9705379009246826\n",
      "iteration : 3293 , loss : 3.7799971103668213\n",
      "iteration : 3294 , loss : 3.830735683441162\n",
      "iteration : 3295 , loss : 3.6738293170928955\n",
      "iteration : 3296 , loss : 3.5541703701019287\n",
      "iteration : 3297 , loss : 4.003660678863525\n",
      "iteration : 3298 , loss : 3.926347255706787\n",
      "iteration : 3299 , loss : 3.723257303237915\n",
      "iteration : 3300 , loss : 3.863870620727539\n",
      "iteration : 3301 , loss : 3.7957117557525635\n",
      "iteration : 3302 , loss : 3.591653347015381\n",
      "iteration : 3303 , loss : 3.714751958847046\n",
      "iteration : 3304 , loss : 3.9332969188690186\n",
      "iteration : 3305 , loss : 4.035549640655518\n",
      "iteration : 3306 , loss : 3.6995511054992676\n",
      "iteration : 3307 , loss : 3.738987445831299\n",
      "iteration : 3308 , loss : 3.6188180446624756\n",
      "iteration : 3309 , loss : 3.71075439453125\n",
      "iteration : 3310 , loss : 3.564237594604492\n",
      "iteration : 3311 , loss : 3.975389003753662\n",
      "iteration : 3312 , loss : 3.8689684867858887\n",
      "iteration : 3313 , loss : 3.901975393295288\n",
      "iteration : 3314 , loss : 3.6690845489501953\n",
      "iteration : 3315 , loss : 3.858997106552124\n",
      "iteration : 3316 , loss : 3.6429762840270996\n",
      "iteration : 3317 , loss : 3.94195294380188\n",
      "iteration : 3318 , loss : 3.884542226791382\n",
      "iteration : 3319 , loss : 3.7697832584381104\n",
      "iteration : 3320 , loss : 3.929016351699829\n",
      "iteration : 3321 , loss : 3.86489200592041\n",
      "iteration : 3322 , loss : 3.937220573425293\n",
      "iteration : 3323 , loss : 3.789991855621338\n",
      "iteration : 3324 , loss : 3.640349864959717\n",
      "iteration : 3325 , loss : 3.7693707942962646\n",
      "iteration : 3326 , loss : 3.837999105453491\n",
      "iteration : 3327 , loss : 3.8034682273864746\n",
      "iteration : 3328 , loss : 3.8875651359558105\n",
      "iteration : 3329 , loss : 3.6754519939422607\n",
      "iteration : 3330 , loss : 4.025155544281006\n",
      "iteration : 3331 , loss : 3.8635454177856445\n",
      "iteration : 3332 , loss : 3.5976343154907227\n",
      "iteration : 3333 , loss : 4.026859760284424\n",
      "iteration : 3334 , loss : 3.8575515747070312\n",
      "iteration : 3335 , loss : 4.0148420333862305\n",
      "iteration : 3336 , loss : 3.8898046016693115\n",
      "iteration : 3337 , loss : 3.915407657623291\n",
      "iteration : 3338 , loss : 3.8238000869750977\n",
      "iteration : 3339 , loss : 3.836738348007202\n",
      "iteration : 3340 , loss : 3.86881685256958\n",
      "iteration : 3341 , loss : 3.900226593017578\n",
      "iteration : 3342 , loss : 3.7191920280456543\n",
      "iteration : 3343 , loss : 3.834355354309082\n",
      "iteration : 3344 , loss : 4.007200241088867\n",
      "iteration : 3345 , loss : 3.834949254989624\n",
      "iteration : 3346 , loss : 3.9191319942474365\n",
      "iteration : 3347 , loss : 3.7610676288604736\n",
      "iteration : 3348 , loss : 3.992166757583618\n",
      "iteration : 3349 , loss : 3.7377986907958984\n",
      "iteration : 3350 , loss : 3.814842700958252\n",
      "iteration : 3351 , loss : 3.967130184173584\n",
      "iteration : 3352 , loss : 3.639090061187744\n",
      "iteration : 3353 , loss : 3.8827879428863525\n",
      "iteration : 3354 , loss : 3.757725715637207\n",
      "iteration : 3355 , loss : 3.7334394454956055\n",
      "iteration : 3356 , loss : 3.8337323665618896\n",
      "iteration : 3357 , loss : 3.758615732192993\n",
      "iteration : 3358 , loss : 3.9748144149780273\n",
      "iteration : 3359 , loss : 3.7544071674346924\n",
      "iteration : 3360 , loss : 3.538342237472534\n",
      "iteration : 3361 , loss : 3.5657002925872803\n",
      "iteration : 3362 , loss : 3.7059926986694336\n",
      "iteration : 3363 , loss : 3.9813954830169678\n",
      "iteration : 3364 , loss : 3.5249314308166504\n",
      "iteration : 3365 , loss : 3.857745885848999\n",
      "iteration : 3366 , loss : 3.8606443405151367\n",
      "iteration : 3367 , loss : 3.8790547847747803\n",
      "iteration : 3368 , loss : 3.941781759262085\n",
      "iteration : 3369 , loss : 4.032283782958984\n",
      "iteration : 3370 , loss : 3.759575843811035\n",
      "iteration : 3371 , loss : 3.592207431793213\n",
      "iteration : 3372 , loss : 3.828294515609741\n",
      "iteration : 3373 , loss : 3.802290678024292\n",
      "iteration : 3374 , loss : 3.842988967895508\n",
      "iteration : 3375 , loss : 4.183050632476807\n",
      "iteration : 3376 , loss : 3.667156457901001\n",
      "iteration : 3377 , loss : 3.6629951000213623\n",
      "iteration : 3378 , loss : 3.8789191246032715\n",
      "iteration : 3379 , loss : 3.50704288482666\n",
      "iteration : 3380 , loss : 3.8892157077789307\n",
      "iteration : 3381 , loss : 3.5937814712524414\n",
      "iteration : 3382 , loss : 3.709462881088257\n",
      "iteration : 3383 , loss : 3.9676191806793213\n",
      "iteration : 3384 , loss : 3.854414701461792\n",
      "iteration : 3385 , loss : 3.7178280353546143\n",
      "iteration : 3386 , loss : 3.914069414138794\n",
      "iteration : 3387 , loss : 3.9063005447387695\n",
      "iteration : 3388 , loss : 3.979707717895508\n",
      "iteration : 3389 , loss : 3.7372729778289795\n",
      "iteration : 3390 , loss : 3.6326189041137695\n",
      "iteration : 3391 , loss : 3.8094193935394287\n",
      "iteration : 3392 , loss : 4.111515998840332\n",
      "iteration : 3393 , loss : 3.9289283752441406\n",
      "iteration : 3394 , loss : 3.8657565116882324\n",
      "iteration : 3395 , loss : 4.040416240692139\n",
      "iteration : 3396 , loss : 3.9968183040618896\n",
      "iteration : 3397 , loss : 3.968230724334717\n",
      "iteration : 3398 , loss : 4.09941291809082\n",
      "iteration : 3399 , loss : 3.6170945167541504\n",
      "iteration : 3400 , loss : 3.560697317123413\n",
      "iteration : 3401 , loss : 3.7964210510253906\n",
      "iteration : 3402 , loss : 4.1534576416015625\n",
      "iteration : 3403 , loss : 3.811805248260498\n",
      "iteration : 3404 , loss : 4.0006422996521\n",
      "iteration : 3405 , loss : 3.833866834640503\n",
      "iteration : 3406 , loss : 3.7809970378875732\n",
      "iteration : 3407 , loss : 3.624296188354492\n",
      "iteration : 3408 , loss : 3.765042543411255\n",
      "iteration : 3409 , loss : 3.72183895111084\n",
      "iteration : 3410 , loss : 3.9426958560943604\n",
      "iteration : 3411 , loss : 4.003565788269043\n",
      "iteration : 3412 , loss : 3.7995355129241943\n",
      "iteration : 3413 , loss : 3.7616336345672607\n",
      "iteration : 3414 , loss : 3.7990963459014893\n",
      "iteration : 3415 , loss : 3.9624016284942627\n",
      "iteration : 3416 , loss : 3.880772352218628\n",
      "iteration : 3417 , loss : 3.9272842407226562\n",
      "iteration : 3418 , loss : 4.072054386138916\n",
      "iteration : 3419 , loss : 3.6656112670898438\n",
      "iteration : 3420 , loss : 4.12822961807251\n",
      "iteration : 3421 , loss : 3.8384227752685547\n",
      "iteration : 3422 , loss : 3.7554879188537598\n",
      "iteration : 3423 , loss : 3.9667766094207764\n",
      "iteration : 3424 , loss : 3.9223814010620117\n",
      "iteration : 3425 , loss : 3.830068826675415\n",
      "iteration : 3426 , loss : 3.860168218612671\n",
      "iteration : 3427 , loss : 3.897322177886963\n",
      "iteration : 3428 , loss : 3.8040575981140137\n",
      "iteration : 3429 , loss : 3.7640345096588135\n",
      "iteration : 3430 , loss : 3.6909666061401367\n",
      "iteration : 3431 , loss : 3.7592790126800537\n",
      "iteration : 3432 , loss : 3.7278950214385986\n",
      "iteration : 3433 , loss : 3.7136101722717285\n",
      "iteration : 3434 , loss : 4.046261787414551\n",
      "iteration : 3435 , loss : 3.6308746337890625\n",
      "iteration : 3436 , loss : 3.6002862453460693\n",
      "iteration : 3437 , loss : 3.979017496109009\n",
      "iteration : 3438 , loss : 3.8995585441589355\n",
      "iteration : 3439 , loss : 4.1556396484375\n",
      "iteration : 3440 , loss : 3.774467945098877\n",
      "iteration : 3441 , loss : 3.7927422523498535\n",
      "iteration : 3442 , loss : 3.946237802505493\n",
      "iteration : 3443 , loss : 3.8164544105529785\n",
      "iteration : 3444 , loss : 4.012592315673828\n",
      "iteration : 3445 , loss : 4.0918869972229\n",
      "iteration : 3446 , loss : 3.715930461883545\n",
      "iteration : 3447 , loss : 3.793617010116577\n",
      "iteration : 3448 , loss : 3.58258318901062\n",
      "iteration : 3449 , loss : 3.7860448360443115\n",
      "iteration : 3450 , loss : 3.7905499935150146\n",
      "iteration : 3451 , loss : 3.661053419113159\n",
      "iteration : 3452 , loss : 3.893481969833374\n",
      "iteration : 3453 , loss : 3.549227237701416\n",
      "iteration : 3454 , loss : 3.764014720916748\n",
      "iteration : 3455 , loss : 3.8347091674804688\n",
      "iteration : 3456 , loss : 3.9138054847717285\n",
      "iteration : 3457 , loss : 3.648000717163086\n",
      "iteration : 3458 , loss : 3.7727057933807373\n",
      "iteration : 3459 , loss : 3.739978551864624\n",
      "iteration : 3460 , loss : 4.1580047607421875\n",
      "iteration : 3461 , loss : 3.921701669692993\n",
      "iteration : 3462 , loss : 3.5806386470794678\n",
      "iteration : 3463 , loss : 3.8052196502685547\n",
      "iteration : 3464 , loss : 3.8543529510498047\n",
      "iteration : 3465 , loss : 3.9751038551330566\n",
      "iteration : 3466 , loss : 3.6854116916656494\n",
      "iteration : 3467 , loss : 3.916567802429199\n",
      "iteration : 3468 , loss : 3.5290119647979736\n",
      "iteration : 3469 , loss : 4.070497512817383\n",
      "iteration : 3470 , loss : 3.583496332168579\n",
      "iteration : 3471 , loss : 3.455702304840088\n",
      "iteration : 3472 , loss : 3.7464675903320312\n",
      "iteration : 3473 , loss : 4.057840824127197\n",
      "iteration : 3474 , loss : 3.9359891414642334\n",
      "iteration : 3475 , loss : 3.8479509353637695\n",
      "iteration : 3476 , loss : 3.8305139541625977\n",
      "iteration : 3477 , loss : 3.9196722507476807\n",
      "iteration : 3478 , loss : 3.9942684173583984\n",
      "iteration : 3479 , loss : 3.8728020191192627\n",
      "iteration : 3480 , loss : 3.823213577270508\n",
      "iteration : 3481 , loss : 3.963977575302124\n",
      "iteration : 3482 , loss : 3.9419620037078857\n",
      "iteration : 3483 , loss : 3.9926340579986572\n",
      "iteration : 3484 , loss : 3.77620267868042\n",
      "iteration : 3485 , loss : 3.902219295501709\n",
      "iteration : 3486 , loss : 3.8772475719451904\n",
      "iteration : 3487 , loss : 3.9223318099975586\n",
      "iteration : 3488 , loss : 3.7530221939086914\n",
      "iteration : 3489 , loss : 3.8431291580200195\n",
      "iteration : 3490 , loss : 3.7646596431732178\n",
      "iteration : 3491 , loss : 3.7828993797302246\n",
      "iteration : 3492 , loss : 3.5610837936401367\n",
      "iteration : 3493 , loss : 4.0090861320495605\n",
      "iteration : 3494 , loss : 3.898071765899658\n",
      "iteration : 3495 , loss : 3.9902422428131104\n",
      "iteration : 3496 , loss : 3.5338428020477295\n",
      "iteration : 3497 , loss : 3.7689812183380127\n",
      "iteration : 3498 , loss : 3.7430262565612793\n",
      "iteration : 3499 , loss : 3.969538688659668\n",
      "iteration : 3500 , loss : 4.046244144439697\n",
      "iteration : 3501 , loss : 3.693601369857788\n",
      "iteration : 3502 , loss : 4.012939453125\n",
      "iteration : 3503 , loss : 3.9583284854888916\n",
      "iteration : 3504 , loss : 3.9002296924591064\n",
      "iteration : 3505 , loss : 3.8774728775024414\n",
      "iteration : 3506 , loss : 3.762291669845581\n",
      "iteration : 3507 , loss : 3.913017988204956\n",
      "iteration : 3508 , loss : 3.6594152450561523\n",
      "iteration : 3509 , loss : 3.7138516902923584\n",
      "iteration : 3510 , loss : 3.7309365272521973\n",
      "iteration : 3511 , loss : 3.9259257316589355\n",
      "iteration : 3512 , loss : 3.963839530944824\n",
      "iteration : 3513 , loss : 3.877020835876465\n",
      "iteration : 3514 , loss : 3.7807791233062744\n",
      "iteration : 3515 , loss : 3.809741258621216\n",
      "iteration : 3516 , loss : 4.069677829742432\n",
      "iteration : 3517 , loss : 3.6801512241363525\n",
      "iteration : 3518 , loss : 3.7604846954345703\n",
      "iteration : 3519 , loss : 3.870654344558716\n",
      "iteration : 3520 , loss : 3.944746732711792\n",
      "iteration : 3521 , loss : 4.084036827087402\n",
      "iteration : 3522 , loss : 4.109875202178955\n",
      "iteration : 3523 , loss : 4.119398593902588\n",
      "iteration : 3524 , loss : 4.059909820556641\n",
      "iteration : 3525 , loss : 3.7493371963500977\n",
      "iteration : 3526 , loss : 3.8427090644836426\n",
      "iteration : 3527 , loss : 3.6996142864227295\n",
      "iteration : 3528 , loss : 3.868443250656128\n",
      "iteration : 3529 , loss : 3.8278543949127197\n",
      "iteration : 3530 , loss : 4.016982078552246\n",
      "iteration : 3531 , loss : 3.851167678833008\n",
      "iteration : 3532 , loss : 3.7930474281311035\n",
      "iteration : 3533 , loss : 3.8167881965637207\n",
      "iteration : 3534 , loss : 3.9505200386047363\n",
      "iteration : 3535 , loss : 3.9262683391571045\n",
      "iteration : 3536 , loss : 3.851130723953247\n",
      "iteration : 3537 , loss : 3.996800661087036\n",
      "iteration : 3538 , loss : 3.8011231422424316\n",
      "iteration : 3539 , loss : 3.8188555240631104\n",
      "iteration : 3540 , loss : 3.8086979389190674\n",
      "iteration : 3541 , loss : 3.622694969177246\n",
      "iteration : 3542 , loss : 3.91338849067688\n",
      "iteration : 3543 , loss : 3.955052375793457\n",
      "iteration : 3544 , loss : 3.7423200607299805\n",
      "iteration : 3545 , loss : 3.6872968673706055\n",
      "iteration : 3546 , loss : 4.038082122802734\n",
      "iteration : 3547 , loss : 3.6366465091705322\n",
      "iteration : 3548 , loss : 3.655832052230835\n",
      "iteration : 3549 , loss : 4.046871662139893\n",
      "iteration : 3550 , loss : 3.8803977966308594\n",
      "iteration : 3551 , loss : 3.5128676891326904\n",
      "iteration : 3552 , loss : 3.920558214187622\n",
      "iteration : 3553 , loss : 3.94972825050354\n",
      "iteration : 3554 , loss : 3.9421298503875732\n",
      "iteration : 3555 , loss : 3.748878002166748\n",
      "iteration : 3556 , loss : 3.8661153316497803\n",
      "iteration : 3557 , loss : 3.979806900024414\n",
      "iteration : 3558 , loss : 3.7906501293182373\n",
      "iteration : 3559 , loss : 3.8792293071746826\n",
      "iteration : 3560 , loss : 3.427266836166382\n",
      "iteration : 3561 , loss : 3.853874683380127\n",
      "iteration : 3562 , loss : 3.781287670135498\n",
      "iteration : 3563 , loss : 3.9208431243896484\n",
      "iteration : 3564 , loss : 3.905379295349121\n",
      "iteration : 3565 , loss : 3.7214622497558594\n",
      "iteration : 3566 , loss : 3.816012144088745\n",
      "iteration : 3567 , loss : 3.9065754413604736\n",
      "iteration : 3568 , loss : 3.94034743309021\n",
      "iteration : 3569 , loss : 3.6321909427642822\n",
      "iteration : 3570 , loss : 3.81630277633667\n",
      "iteration : 3571 , loss : 3.993753433227539\n",
      "iteration : 3572 , loss : 3.8198912143707275\n",
      "iteration : 3573 , loss : 3.676063299179077\n",
      "iteration : 3574 , loss : 3.618452787399292\n",
      "iteration : 3575 , loss : 3.9058749675750732\n",
      "iteration : 3576 , loss : 3.8173773288726807\n",
      "iteration : 3577 , loss : 3.7583014965057373\n",
      "iteration : 3578 , loss : 3.771909475326538\n",
      "iteration : 3579 , loss : 3.7248952388763428\n",
      "iteration : 3580 , loss : 3.6886534690856934\n",
      "iteration : 3581 , loss : 3.7786920070648193\n",
      "iteration : 3582 , loss : 3.619516372680664\n",
      "iteration : 3583 , loss : 3.9733502864837646\n",
      "iteration : 3584 , loss : 4.044859886169434\n",
      "iteration : 3585 , loss : 3.821138858795166\n",
      "iteration : 3586 , loss : 3.722625970840454\n",
      "iteration : 3587 , loss : 3.917800188064575\n",
      "iteration : 3588 , loss : 3.6026947498321533\n",
      "iteration : 3589 , loss : 3.862760066986084\n",
      "iteration : 3590 , loss : 3.849320411682129\n",
      "iteration : 3591 , loss : 3.5762155055999756\n",
      "iteration : 3592 , loss : 3.8240668773651123\n",
      "iteration : 3593 , loss : 3.8452696800231934\n",
      "iteration : 3594 , loss : 3.7967777252197266\n",
      "iteration : 3595 , loss : 3.9083614349365234\n",
      "iteration : 3596 , loss : 3.6525137424468994\n",
      "iteration : 3597 , loss : 4.019350051879883\n",
      "iteration : 3598 , loss : 3.6789650917053223\n",
      "iteration : 3599 , loss : 3.7089931964874268\n",
      "iteration : 3600 , loss : 3.8627710342407227\n",
      "iteration : 3601 , loss : 3.7321839332580566\n",
      "iteration : 3602 , loss : 3.882423162460327\n",
      "iteration : 3603 , loss : 3.971041202545166\n",
      "iteration : 3604 , loss : 3.83567214012146\n",
      "iteration : 3605 , loss : 3.624797821044922\n",
      "iteration : 3606 , loss : 3.6726021766662598\n",
      "iteration : 3607 , loss : 3.564302921295166\n",
      "iteration : 3608 , loss : 3.838233470916748\n",
      "iteration : 3609 , loss : 3.8304314613342285\n",
      "iteration : 3610 , loss : 3.597334623336792\n",
      "iteration : 3611 , loss : 3.71770977973938\n",
      "iteration : 3612 , loss : 3.701469898223877\n",
      "iteration : 3613 , loss : 4.042026042938232\n",
      "iteration : 3614 , loss : 3.6908915042877197\n",
      "iteration : 3615 , loss : 3.997863531112671\n",
      "iteration : 3616 , loss : 3.7754733562469482\n",
      "iteration : 3617 , loss : 3.8287556171417236\n",
      "iteration : 3618 , loss : 3.740788459777832\n",
      "iteration : 3619 , loss : 3.748439311981201\n",
      "iteration : 3620 , loss : 3.9334075450897217\n",
      "iteration : 3621 , loss : 3.9136505126953125\n",
      "iteration : 3622 , loss : 3.6918678283691406\n",
      "iteration : 3623 , loss : 3.616826295852661\n",
      "iteration : 3624 , loss : 3.820369243621826\n",
      "iteration : 3625 , loss : 3.8556249141693115\n",
      "iteration : 3626 , loss : 3.760181427001953\n",
      "iteration : 3627 , loss : 3.712299346923828\n",
      "iteration : 3628 , loss : 3.698901653289795\n",
      "iteration : 3629 , loss : 3.592957019805908\n",
      "iteration : 3630 , loss : 3.7851486206054688\n",
      "iteration : 3631 , loss : 3.450021266937256\n",
      "iteration : 3632 , loss : 3.9547691345214844\n",
      "iteration : 3633 , loss : 3.5491251945495605\n",
      "iteration : 3634 , loss : 3.780095100402832\n",
      "iteration : 3635 , loss : 3.701765537261963\n",
      "iteration : 3636 , loss : 3.836294651031494\n",
      "iteration : 3637 , loss : 3.9289133548736572\n",
      "iteration : 3638 , loss : 3.9096755981445312\n",
      "iteration : 3639 , loss : 3.605116367340088\n",
      "iteration : 3640 , loss : 3.821309804916382\n",
      "iteration : 3641 , loss : 3.937638521194458\n",
      "iteration : 3642 , loss : 3.635530710220337\n",
      "iteration : 3643 , loss : 3.8441617488861084\n",
      "iteration : 3644 , loss : 3.653554677963257\n",
      "iteration : 3645 , loss : 3.7075998783111572\n",
      "iteration : 3646 , loss : 3.8287532329559326\n",
      "iteration : 3647 , loss : 3.900965690612793\n",
      "iteration : 3648 , loss : 3.824286937713623\n",
      "iteration : 3649 , loss : 3.468384027481079\n",
      "iteration : 3650 , loss : 3.821725368499756\n",
      "iteration : 3651 , loss : 3.7591471672058105\n",
      "iteration : 3652 , loss : 3.7872817516326904\n",
      "iteration : 3653 , loss : 3.819096088409424\n",
      "iteration : 3654 , loss : 3.9272592067718506\n",
      "iteration : 3655 , loss : 3.907176971435547\n",
      "iteration : 3656 , loss : 3.742072343826294\n",
      "iteration : 3657 , loss : 3.776531219482422\n",
      "iteration : 3658 , loss : 3.6991467475891113\n",
      "iteration : 3659 , loss : 3.899970769882202\n",
      "iteration : 3660 , loss : 3.8525643348693848\n",
      "iteration : 3661 , loss : 3.781698703765869\n",
      "iteration : 3662 , loss : 3.8572006225585938\n",
      "iteration : 3663 , loss : 3.5241689682006836\n",
      "iteration : 3664 , loss : 3.6832540035247803\n",
      "iteration : 3665 , loss : 4.188774108886719\n",
      "iteration : 3666 , loss : 3.8887574672698975\n",
      "iteration : 3667 , loss : 3.7164061069488525\n",
      "iteration : 3668 , loss : 3.75958251953125\n",
      "iteration : 3669 , loss : 3.663001775741577\n",
      "iteration : 3670 , loss : 3.6793630123138428\n",
      "iteration : 3671 , loss : 3.8963935375213623\n",
      "iteration : 3672 , loss : 3.8333656787872314\n",
      "iteration : 3673 , loss : 3.774569034576416\n",
      "iteration : 3674 , loss : 3.7902588844299316\n",
      "iteration : 3675 , loss : 3.664320945739746\n",
      "iteration : 3676 , loss : 3.859583616256714\n",
      "iteration : 3677 , loss : 3.5674870014190674\n",
      "iteration : 3678 , loss : 3.697843551635742\n",
      "iteration : 3679 , loss : 3.49949312210083\n",
      "iteration : 3680 , loss : 3.5809326171875\n",
      "iteration : 3681 , loss : 3.86979079246521\n",
      "iteration : 3682 , loss : 3.8419156074523926\n",
      "iteration : 3683 , loss : 3.592291831970215\n",
      "iteration : 3684 , loss : 3.7395498752593994\n",
      "iteration : 3685 , loss : 3.8282272815704346\n",
      "iteration : 3686 , loss : 3.816070079803467\n",
      "iteration : 3687 , loss : 3.706881523132324\n",
      "iteration : 3688 , loss : 4.025624752044678\n",
      "iteration : 3689 , loss : 3.8840036392211914\n",
      "iteration : 3690 , loss : 3.723551034927368\n",
      "iteration : 3691 , loss : 3.5043187141418457\n",
      "iteration : 3692 , loss : 3.760765790939331\n",
      "iteration : 3693 , loss : 3.5916359424591064\n",
      "iteration : 3694 , loss : 3.7772209644317627\n",
      "iteration : 3695 , loss : 3.7317070960998535\n",
      "iteration : 3696 , loss : 3.876704216003418\n",
      "iteration : 3697 , loss : 3.68550181388855\n",
      "iteration : 3698 , loss : 3.9782328605651855\n",
      "iteration : 3699 , loss : 3.912886619567871\n",
      "iteration : 3700 , loss : 3.5824546813964844\n",
      "iteration : 3701 , loss : 3.7271344661712646\n",
      "iteration : 3702 , loss : 3.620637893676758\n",
      "iteration : 3703 , loss : 4.02023983001709\n",
      "iteration : 3704 , loss : 3.845569610595703\n",
      "iteration : 3705 , loss : 3.9989516735076904\n",
      "iteration : 3706 , loss : 3.745556116104126\n",
      "iteration : 3707 , loss : 3.7932724952697754\n",
      "iteration : 3708 , loss : 3.828810930252075\n",
      "iteration : 3709 , loss : 3.923957109451294\n",
      "iteration : 3710 , loss : 3.783452033996582\n",
      "iteration : 3711 , loss : 3.82804536819458\n",
      "iteration : 3712 , loss : 3.919875383377075\n",
      "iteration : 3713 , loss : 3.495004177093506\n",
      "iteration : 3714 , loss : 3.6699206829071045\n",
      "iteration : 3715 , loss : 3.8479835987091064\n",
      "iteration : 3716 , loss : 3.890929937362671\n",
      "iteration : 3717 , loss : 3.536102294921875\n",
      "iteration : 3718 , loss : 3.766920804977417\n",
      "iteration : 3719 , loss : 3.879925012588501\n",
      "iteration : 3720 , loss : 3.8030178546905518\n",
      "iteration : 3721 , loss : 3.820713758468628\n",
      "iteration : 3722 , loss : 3.802147150039673\n",
      "iteration : 3723 , loss : 3.6491312980651855\n",
      "iteration : 3724 , loss : 3.5686185359954834\n",
      "iteration : 3725 , loss : 3.536679983139038\n",
      "iteration : 3726 , loss : 3.7752420902252197\n",
      "iteration : 3727 , loss : 3.8929238319396973\n",
      "iteration : 3728 , loss : 3.795778751373291\n",
      "iteration : 3729 , loss : 3.8385894298553467\n",
      "iteration : 3730 , loss : 3.8532941341400146\n",
      "iteration : 3731 , loss : 3.872832775115967\n",
      "iteration : 3732 , loss : 3.724062442779541\n",
      "iteration : 3733 , loss : 3.777449607849121\n",
      "iteration : 3734 , loss : 3.560030221939087\n",
      "iteration : 3735 , loss : 3.5932722091674805\n",
      "iteration : 3736 , loss : 3.7057149410247803\n",
      "iteration : 3737 , loss : 3.9641687870025635\n",
      "iteration : 3738 , loss : 3.983035087585449\n",
      "iteration : 3739 , loss : 3.5420734882354736\n",
      "iteration : 3740 , loss : 4.136704921722412\n",
      "iteration : 3741 , loss : 3.786846399307251\n",
      "iteration : 3742 , loss : 3.709528923034668\n",
      "iteration : 3743 , loss : 3.844193696975708\n",
      "iteration : 3744 , loss : 3.7156879901885986\n",
      "iteration : 3745 , loss : 3.7710700035095215\n",
      "iteration : 3746 , loss : 3.5986013412475586\n",
      "iteration : 3747 , loss : 3.692079782485962\n",
      "iteration : 3748 , loss : 3.847749948501587\n",
      "iteration : 3749 , loss : 3.661325216293335\n",
      "iteration : 3750 , loss : 4.040937423706055\n",
      "iteration : 3751 , loss : 3.924604892730713\n",
      "iteration : 3752 , loss : 3.6954965591430664\n",
      "iteration : 3753 , loss : 3.78397274017334\n",
      "iteration : 3754 , loss : 3.6384992599487305\n",
      "iteration : 3755 , loss : 3.785400390625\n",
      "iteration : 3756 , loss : 3.694000482559204\n",
      "iteration : 3757 , loss : 4.036981582641602\n",
      "iteration : 3758 , loss : 3.765333890914917\n",
      "iteration : 3759 , loss : 3.541779041290283\n",
      "iteration : 3760 , loss : 3.8821511268615723\n",
      "iteration : 3761 , loss : 4.000469207763672\n",
      "iteration : 3762 , loss : 3.6140382289886475\n",
      "iteration : 3763 , loss : 3.5813486576080322\n",
      "iteration : 3764 , loss : 3.7958476543426514\n",
      "iteration : 3765 , loss : 3.675499200820923\n",
      "iteration : 3766 , loss : 3.8141732215881348\n",
      "iteration : 3767 , loss : 4.204342365264893\n",
      "iteration : 3768 , loss : 4.108941078186035\n",
      "iteration : 3769 , loss : 3.657003402709961\n",
      "iteration : 3770 , loss : 3.661447525024414\n",
      "iteration : 3771 , loss : 4.022366523742676\n",
      "iteration : 3772 , loss : 3.69059157371521\n",
      "iteration : 3773 , loss : 3.626289129257202\n",
      "iteration : 3774 , loss : 3.9056501388549805\n",
      "iteration : 3775 , loss : 3.6533830165863037\n",
      "iteration : 3776 , loss : 3.8477327823638916\n",
      "iteration : 3777 , loss : 4.01028299331665\n",
      "iteration : 3778 , loss : 3.682309627532959\n",
      "iteration : 3779 , loss : 3.8131344318389893\n",
      "iteration : 3780 , loss : 3.7085230350494385\n",
      "iteration : 3781 , loss : 3.810281276702881\n",
      "iteration : 3782 , loss : 3.8113343715667725\n",
      "iteration : 3783 , loss : 3.7866945266723633\n",
      "iteration : 3784 , loss : 3.7485527992248535\n",
      "iteration : 3785 , loss : 3.8463993072509766\n",
      "iteration : 3786 , loss : 3.976757764816284\n",
      "iteration : 3787 , loss : 3.7806529998779297\n",
      "iteration : 3788 , loss : 3.8272762298583984\n",
      "iteration : 3789 , loss : 3.6771867275238037\n",
      "iteration : 3790 , loss : 3.64371657371521\n",
      "iteration : 3791 , loss : 3.7268383502960205\n",
      "iteration : 3792 , loss : 3.977682113647461\n",
      "iteration : 3793 , loss : 3.552253484725952\n",
      "iteration : 3794 , loss : 3.7872438430786133\n",
      "iteration : 3795 , loss : 3.7785158157348633\n",
      "iteration : 3796 , loss : 3.76739764213562\n",
      "iteration : 3797 , loss : 3.9381203651428223\n",
      "iteration : 3798 , loss : 3.653308153152466\n",
      "iteration : 3799 , loss : 3.9912612438201904\n",
      "iteration : 3800 , loss : 3.5172371864318848\n",
      "iteration : 3801 , loss : 3.9554924964904785\n",
      "iteration : 3802 , loss : 3.923999547958374\n",
      "iteration : 3803 , loss : 3.6752023696899414\n",
      "iteration : 3804 , loss : 3.693877935409546\n",
      "iteration : 3805 , loss : 3.7323801517486572\n",
      "iteration : 3806 , loss : 3.682424783706665\n",
      "iteration : 3807 , loss : 3.982938528060913\n",
      "iteration : 3808 , loss : 3.825582981109619\n",
      "iteration : 3809 , loss : 3.8431334495544434\n",
      "iteration : 3810 , loss : 3.8282535076141357\n",
      "iteration : 3811 , loss : 3.9865028858184814\n",
      "iteration : 3812 , loss : 3.6390979290008545\n",
      "iteration : 3813 , loss : 3.871222734451294\n",
      "iteration : 3814 , loss : 3.8598029613494873\n",
      "iteration : 3815 , loss : 3.9859325885772705\n",
      "iteration : 3816 , loss : 3.7405691146850586\n",
      "iteration : 3817 , loss : 3.7523069381713867\n",
      "iteration : 3818 , loss : 3.667672872543335\n",
      "iteration : 3819 , loss : 3.8308606147766113\n",
      "iteration : 3820 , loss : 3.9381535053253174\n",
      "iteration : 3821 , loss : 3.7434403896331787\n",
      "iteration : 3822 , loss : 3.7700319290161133\n",
      "iteration : 3823 , loss : 3.954533815383911\n",
      "iteration : 3824 , loss : 3.5990827083587646\n",
      "iteration : 3825 , loss : 3.725703001022339\n",
      "iteration : 3826 , loss : 3.9328887462615967\n",
      "iteration : 3827 , loss : 3.635576009750366\n",
      "iteration : 3828 , loss : 3.8625504970550537\n",
      "iteration : 3829 , loss : 3.862393379211426\n",
      "iteration : 3830 , loss : 4.0513153076171875\n",
      "iteration : 3831 , loss : 3.579880475997925\n",
      "iteration : 3832 , loss : 3.7300469875335693\n",
      "iteration : 3833 , loss : 3.794811487197876\n",
      "iteration : 3834 , loss : 3.7933731079101562\n",
      "iteration : 3835 , loss : 3.848848581314087\n",
      "iteration : 3836 , loss : 3.9749979972839355\n",
      "iteration : 3837 , loss : 4.010920524597168\n",
      "iteration : 3838 , loss : 4.087390899658203\n",
      "iteration : 3839 , loss : 3.9577012062072754\n",
      "iteration : 3840 , loss : 3.7594311237335205\n",
      "iteration : 3841 , loss : 3.789515256881714\n",
      "iteration : 3842 , loss : 3.8349971771240234\n",
      "iteration : 3843 , loss : 3.7906839847564697\n",
      "iteration : 3844 , loss : 3.7687065601348877\n",
      "iteration : 3845 , loss : 3.4878828525543213\n",
      "iteration : 3846 , loss : 3.872196674346924\n",
      "iteration : 3847 , loss : 3.8015224933624268\n",
      "iteration : 3848 , loss : 3.9242982864379883\n",
      "iteration : 3849 , loss : 3.943350315093994\n",
      "iteration : 3850 , loss : 3.4368395805358887\n",
      "iteration : 3851 , loss : 3.582958459854126\n",
      "iteration : 3852 , loss : 3.7443370819091797\n",
      "iteration : 3853 , loss : 3.6747586727142334\n",
      "iteration : 3854 , loss : 3.9772984981536865\n",
      "iteration : 3855 , loss : 3.9683425426483154\n",
      "iteration : 3856 , loss : 3.8966944217681885\n",
      "iteration : 3857 , loss : 3.853182792663574\n",
      "iteration : 3858 , loss : 3.7199056148529053\n",
      "iteration : 3859 , loss : 3.884559154510498\n",
      "iteration : 3860 , loss : 3.580213785171509\n",
      "iteration : 3861 , loss : 3.827310562133789\n",
      "iteration : 3862 , loss : 3.806741952896118\n",
      "iteration : 3863 , loss : 3.6539573669433594\n",
      "iteration : 3864 , loss : 3.7257111072540283\n",
      "iteration : 3865 , loss : 3.8950982093811035\n",
      "iteration : 3866 , loss : 4.019847393035889\n",
      "iteration : 3867 , loss : 3.7425878047943115\n",
      "iteration : 3868 , loss : 3.5687575340270996\n",
      "iteration : 3869 , loss : 3.823603630065918\n",
      "iteration : 3870 , loss : 3.89017391204834\n",
      "iteration : 3871 , loss : 3.5925590991973877\n",
      "iteration : 3872 , loss : 3.6137373447418213\n",
      "iteration : 3873 , loss : 3.5431454181671143\n",
      "iteration : 3874 , loss : 3.9677515029907227\n",
      "iteration : 3875 , loss : 3.732240915298462\n",
      "iteration : 3876 , loss : 3.92598557472229\n",
      "iteration : 3877 , loss : 3.902538537979126\n",
      "iteration : 3878 , loss : 3.7844274044036865\n",
      "iteration : 3879 , loss : 3.8115456104278564\n",
      "iteration : 3880 , loss : 3.587433099746704\n",
      "iteration : 3881 , loss : 3.741152763366699\n",
      "iteration : 3882 , loss : 3.531057596206665\n",
      "iteration : 3883 , loss : 3.6319713592529297\n",
      "iteration : 3884 , loss : 3.6962742805480957\n",
      "iteration : 3885 , loss : 3.8638811111450195\n",
      "iteration : 3886 , loss : 4.061087608337402\n",
      "iteration : 3887 , loss : 3.6919076442718506\n",
      "iteration : 3888 , loss : 3.8977832794189453\n",
      "iteration : 3889 , loss : 3.8619906902313232\n",
      "iteration : 3890 , loss : 3.9328954219818115\n",
      "iteration : 3891 , loss : 3.652204990386963\n",
      "iteration : 3892 , loss : 3.8638992309570312\n",
      "iteration : 3893 , loss : 3.8559019565582275\n",
      "iteration : 3894 , loss : 3.6949079036712646\n",
      "iteration : 3895 , loss : 3.5392422676086426\n",
      "iteration : 3896 , loss : 3.8196704387664795\n",
      "iteration : 3897 , loss : 3.688159227371216\n",
      "iteration : 3898 , loss : 3.7360246181488037\n",
      "iteration : 3899 , loss : 3.9264109134674072\n",
      "iteration : 3900 , loss : 3.7719016075134277\n",
      "iteration : 3901 , loss : 3.8224079608917236\n",
      "iteration : 3902 , loss : 3.6340386867523193\n",
      "iteration : 3903 , loss : 3.8628358840942383\n",
      "iteration : 3904 , loss : 3.604612112045288\n",
      "iteration : 3905 , loss : 3.754929304122925\n",
      "iteration : 3906 , loss : 3.7656006813049316\n",
      "iteration : 3907 , loss : 4.191833972930908\n",
      "iteration : 3908 , loss : 4.041383266448975\n",
      "iteration : 3909 , loss : 3.8172900676727295\n",
      "iteration : 3910 , loss : 3.890202760696411\n",
      "iteration : 3911 , loss : 3.6539223194122314\n",
      "iteration : 3912 , loss : 3.7365739345550537\n",
      "iteration : 3913 , loss : 3.870924711227417\n",
      "iteration : 3914 , loss : 3.6561717987060547\n",
      "iteration : 3915 , loss : 3.6921792030334473\n",
      "iteration : 3916 , loss : 3.7801642417907715\n",
      "iteration : 3917 , loss : 3.8363289833068848\n",
      "iteration : 3918 , loss : 3.9003021717071533\n",
      "iteration : 3919 , loss : 3.900658369064331\n",
      "iteration : 3920 , loss : 3.657538890838623\n",
      "iteration : 3921 , loss : 3.8433964252471924\n",
      "iteration : 3922 , loss : 3.7029290199279785\n",
      "iteration : 3923 , loss : 3.5701944828033447\n",
      "iteration : 3924 , loss : 3.726288080215454\n",
      "iteration : 3925 , loss : 3.4430789947509766\n",
      "iteration : 3926 , loss : 3.9420957565307617\n",
      "iteration : 3927 , loss : 3.7587132453918457\n",
      "iteration : 3928 , loss : 3.8117432594299316\n",
      "iteration : 3929 , loss : 3.7943825721740723\n",
      "iteration : 3930 , loss : 3.566936731338501\n",
      "iteration : 3931 , loss : 3.7075273990631104\n",
      "iteration : 3932 , loss : 3.836376905441284\n",
      "iteration : 3933 , loss : 3.930851936340332\n",
      "iteration : 3934 , loss : 3.8669116497039795\n",
      "iteration : 3935 , loss : 3.8342370986938477\n",
      "iteration : 3936 , loss : 3.655165910720825\n",
      "iteration : 3937 , loss : 4.114523410797119\n",
      "iteration : 3938 , loss : 3.6414060592651367\n",
      "iteration : 3939 , loss : 3.7019429206848145\n",
      "iteration : 3940 , loss : 3.766981363296509\n",
      "iteration : 3941 , loss : 3.761596202850342\n",
      "iteration : 3942 , loss : 3.6811773777008057\n",
      "iteration : 3943 , loss : 3.7037737369537354\n",
      "iteration : 3944 , loss : 3.6806960105895996\n",
      "iteration : 3945 , loss : 3.879348039627075\n",
      "iteration : 3946 , loss : 3.9839658737182617\n",
      "iteration : 3947 , loss : 3.735076904296875\n",
      "iteration : 3948 , loss : 3.7772622108459473\n",
      "iteration : 3949 , loss : 3.6270318031311035\n",
      "iteration : 3950 , loss : 3.6406795978546143\n",
      "iteration : 3951 , loss : 3.7318501472473145\n",
      "iteration : 3952 , loss : 3.5042710304260254\n",
      "iteration : 3953 , loss : 3.6252596378326416\n",
      "iteration : 3954 , loss : 3.7179975509643555\n",
      "iteration : 3955 , loss : 3.7373430728912354\n",
      "iteration : 3956 , loss : 3.5734739303588867\n",
      "iteration : 3957 , loss : 3.922234296798706\n",
      "iteration : 3958 , loss : 3.857419967651367\n",
      "iteration : 3959 , loss : 3.8369038105010986\n",
      "iteration : 3960 , loss : 3.872206449508667\n",
      "iteration : 3961 , loss : 3.8036465644836426\n",
      "iteration : 3962 , loss : 3.8157894611358643\n",
      "iteration : 3963 , loss : 3.797330141067505\n",
      "iteration : 3964 , loss : 3.9099795818328857\n",
      "iteration : 3965 , loss : 3.607599973678589\n",
      "iteration : 3966 , loss : 3.71718692779541\n",
      "iteration : 3967 , loss : 3.6726837158203125\n",
      "iteration : 3968 , loss : 3.877516984939575\n",
      "iteration : 3969 , loss : 3.7497901916503906\n",
      "iteration : 3970 , loss : 3.90045428276062\n",
      "iteration : 3971 , loss : 3.953768253326416\n",
      "iteration : 3972 , loss : 3.575369358062744\n",
      "iteration : 3973 , loss : 3.7325150966644287\n",
      "iteration : 3974 , loss : 3.769192695617676\n",
      "iteration : 3975 , loss : 3.734109401702881\n",
      "iteration : 3976 , loss : 3.6608078479766846\n",
      "iteration : 3977 , loss : 4.1138176918029785\n",
      "iteration : 3978 , loss : 3.5626485347747803\n",
      "iteration : 3979 , loss : 3.7922275066375732\n",
      "iteration : 3980 , loss : 3.7135186195373535\n",
      "iteration : 3981 , loss : 3.9104957580566406\n",
      "iteration : 3982 , loss : 3.866581916809082\n",
      "iteration : 3983 , loss : 3.746999979019165\n",
      "iteration : 3984 , loss : 3.940589666366577\n",
      "iteration : 3985 , loss : 3.6593737602233887\n",
      "iteration : 3986 , loss : 3.7771406173706055\n",
      "iteration : 3987 , loss : 3.941777467727661\n",
      "iteration : 3988 , loss : 3.7935123443603516\n",
      "iteration : 3989 , loss : 3.6157779693603516\n",
      "iteration : 3990 , loss : 3.702130079269409\n",
      "iteration : 3991 , loss : 3.8074681758880615\n",
      "iteration : 3992 , loss : 3.8902084827423096\n",
      "iteration : 3993 , loss : 3.766404628753662\n",
      "iteration : 3994 , loss : 3.716113805770874\n",
      "iteration : 3995 , loss : 3.6558568477630615\n",
      "iteration : 3996 , loss : 3.8402280807495117\n",
      "iteration : 3997 , loss : 3.715374231338501\n",
      "iteration : 3998 , loss : 3.7894246578216553\n",
      "iteration : 3999 , loss : 3.7536733150482178\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "optimizer = torch.optim.AdamW(m.parameters() , lr = 1e-2)\n",
    "batch_size = 32\n",
    "# training loop\n",
    "for iteration in range(4000):\n",
    "    x_b , y_b = get_batch('train' , batch_size = batch_size)\n",
    "    logits , loss = m(x_b , y_b)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'iteration : {iteration} , loss : {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Those easy <UNK> ! one <UNK> , whiles forgot . \n",
      " Third Citizen : \n",
      " out there lies such men depart plant receive some <UNK> \n",
      " Volsce : \n",
      " And wouldst thou ? \n",
      " HORTENSIO consent Hast MERCUTIO : \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokens_to_text(m.generate(torch.zeros((1 , 1) , dtype = torch.long) , max_new_tokens = 40)[0].tolist()))  # Showing the result of trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is evident that the model has learned to predict the next token based on the appearance of the current one. At this stage, we notice a hint of Shakespearean style in the results. However, since the model only considers the previous token and not all preceding tokens, it falls short of generating true Shakespeare-like phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the bigram model, which only considers the previous token to predict the next one, the transformer model takes into account all preceding tokens. This comprehensive approach enables the model to more accurately determine the next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 65\n",
    "head_size = 20\n",
    "block_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a single head of transformer\n",
    "class Head(nn.Module):\n",
    "    \"\"\" One head of self-attention module \"\"\"\n",
    "    def __init__(self , head_size , embedding_size , block_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(embedding_size , head_size , bias = False)\n",
    "        self.query = nn.Linear(embedding_size , head_size , bias = False)\n",
    "        self.value = nn.Linear(embedding_size , head_size , bias = False)\n",
    "        self.register_buffer('tril' , torch.tril(torch.ones(block_size , block_size)))  # whenever the tril is called , it calls torch.tril(torch.ones(block_size , block_size)) which constructs a lower triangular matrix of size : (block_size , block_size)\n",
    "\n",
    "    def forward(self , x):\n",
    "        B , T , C = x.shape\n",
    "        k = self.key(x) # B , T , head_Size \n",
    "        q = self.query(x) # B , T , head_Size\n",
    "        v = self.value(x) # B , T , head_Size\n",
    "        product =  q @ k.transpose(1 , 2)   # (B , T , head_Size) @ (B , head_Size , T) --> (B , T , T)\n",
    "        product = product * (C ** -0.5)\n",
    "        product = product.masked_fill(self.tril[:T , :T] == 0 , float('-inf'))\n",
    "        product = F.softmax(product , dim = 2) (B , T , T)\n",
    "        out = product @ v # (B , T , T) @ (B , T , head_Size) --> (B , T , head_Size) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the transformer module \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self , vocab_size , embedding_size , block_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(num_embeddings = vocab_size , embedding_dim = embedding_size)\n",
    "        self.positional_embedding = nn.Embedding(num_embeddings = vocab_size , embedding_dim = embedding_size)\n",
    "        self.self_attention_head = Head(head_size = embedding_size , embedding_size = embedding_size , block_size = block_size) # (B , T , head_Size = embedding_size)\n",
    "        self.linear_head = nn.Linear(embedding_size , vocab_size)\n",
    "\n",
    "    def forward(self , idx , targets = None):\n",
    "        B , T , C = idx.shape()\n",
    "        token_embedding = self.token_embedding_table(idx)  # (B , T , C)\n",
    "        positional_embedding = self.positional_embedding(torch.arange(T , device = device))  # (T , C)\n",
    "        x = token_embedding + positional_embedding # (B , T , C)\n",
    "        x = self.self_attention_head(idx)    # (B , T , C)\n",
    "        logits = self.linear_head(x)   # (B , T , vocab_size)\n",
    "\n",
    "        if targets == None : \n",
    "            loss = None\n",
    "        else :\n",
    "            B , T , vocab_size = logits.shape\n",
    "            logits = logits.reshape(B * T , vocab_size)\n",
    "            targets = targets.reshape\n",
    "\n",
    "        \n",
    "    \n",
    "    def generate(self , idx , max_new_tokens):\n",
    "        # This function will predict the next word base on the previous word\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits , loss = self(idx)\n",
    "            logits = logits[: , -1 , :]  # we put -1 because we only need the last word\n",
    "            probs = F.softmax(logits , dim = 1)\n",
    "            idx_next = torch.multinomial(probs , num_samples = 1)\n",
    "            idx = torch.cat([idx , idx_next] , dim = 1)\n",
    "        return idx\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
