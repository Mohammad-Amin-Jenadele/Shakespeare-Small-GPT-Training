{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the Shakespeare.txt file\n",
    "with open('Shakespeare.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the text : 1115394\n",
      "\n",
      "First 1000 characters of the text : \n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of the text : {len(text)}\\n')\n",
    "print(f'First 1000 characters of the text : \\n{text[:1000]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text: [0, 5, 6, 7, 8, 9, 10, 11, 12, 2]\n",
      "Original Text: Before we proceed any further hear me speak\n"
     ]
    }
   ],
   "source": [
    "# Making a dictionary for the text\n",
    "\n",
    "repetition_threshold = 1  # Set your desired repetition threshold\n",
    "tokenizer = utils.TextTokenizer(repetition_threshold)\n",
    "tokenizer.process_text(text)\n",
    "# Example text and tokenized text\n",
    "example_text = \"Before we proceed any further, hear me speak.\"\n",
    "tokenized_text = tokenizer.text_to_tokens(example_text)\n",
    "print(\"Tokenized Text:\", tokenized_text)\n",
    "\n",
    "# Convert tokenized text back to original text\n",
    "original_text = tokenizer.tokens_to_text(tokenized_text)\n",
    "print(\"Original Text:\", original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([208505])\n",
      "tensor([  0,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  12,\n",
      "          3,   4,  15,  16,  17,  18,  19,  20,  21,  22,  20,  23,  13,  24,\n",
      "         18,   3,   4,   3,  25,  26,  27,  28,  29,  30,  31,  20,  32,  33,\n",
      "         13,  34,  26,  35,   6,  26,  35,   3,   4,  36,  37,  38,  39,  40,\n",
      "          6,  41,  42,  43,  44,  45,  46,  47,  48,  35,  49,  50,  13,  51,\n",
      "         52,  53,  54,  35,  55,  56,  57,  58,  59,  59,  60,   4,  61,  62,\n",
      "         63,  64,   3,   4,  34,  16,  65,  66,  64,  32,  67,  63,  68,  69,\n",
      "         70,  54,  71,  72,  37,  73,  74,  71,  75,  37,  76,  32,  77,  78,\n",
      "         56,  79,  80,   6,  81,  82,  74,   1,  37,   1,  76,  74,  83,   6,\n",
      "         16,  84,  85,  32,  86,  87,   1,  37,  32,  88,  89,  45,  90,  29,\n",
      "         91,  92,   1,  20,   1,  93,  94,  45,  95,  29,  49,  96,  20,  97,\n",
      "         36,  37,  98,  99, 100,  45, 101, 102,   6, 103,   1, 104,  32, 105,\n",
      "         26, 106,  12,  99, 107, 108, 104, 109, 110, 107, 111, 104,  98,  60,\n",
      "          4, 112,  25,   7, 113, 114,  27,  28,  13, 115,  39, 116, 117, 118,\n",
      "         49, 119, 120,  20,  32,   1,  60,   4, 121,  25, 122, 123, 117, 124,\n",
      "         58, 104, 125, 126,   3,   4, 127, 128,  40, 129,  57, 130,  20, 131,\n",
      "         39,  63, 132, 133,  76,  87, 117, 134, 135, 100, 136, 137,  60,   4,\n",
      "        138,  76,  12, 110,   1,   3,   4, 106, 139, 140,  25, 122, 117, 141,\n",
      "         58, 142, 117, 143,  56,  20,  87, 144, 145, 146,   1, 147, 148,  57,\n",
      "        130,  20, 139,  56, 149, 104, 125, 126, 117, 143,  56,  20, 150, 125,\n",
      "        151,  40,  20,  57, 152, 137, 153, 117,  29, 154, 155,  32,   1,  89,\n",
      "        125, 156,  60,   4,  68, 117, 157, 158, 107, 125, 159,  25, 160,  49,\n",
      "        161, 107,  39,  15, 162, 107, 163, 164, 139, 117,  29,   1,   3,   4,\n",
      "        165, 106, 162, 110, 106, 166, 110,  57, 167,  89, 168, 117, 141, 169,\n",
      "        100, 170,  20, 171, 107, 172,  68, 173,  16, 174, 175, 176, 177, 178,\n",
      "         32, 179,  29, 180, 181, 182,   6, 183, 184,  20,  32, 185,  13, 186,\n",
      "        187,   3,   4, 188, 189, 190, 184,  60,   4, 191, 192,   1, 193,  87,\n",
      "        141, 194, 195,  32,  33,   3,   4, 196, 118, 193, 197, 198,  71,  17,\n",
      "         32, 199,  79, 200, 201,  68, 202, 118, 203, 204, 107, 205, 206, 207,\n",
      "         25, 208, 209,  40, 210, 175, 211,  12, 106, 212,  25,   3,   4, 213,\n",
      "        214,  29, 110, 215,  20,  32, 216,  74,  42, 217,   1,  99, 218, 122,\n",
      "          6, 219,  20, 220, 153, 221,   6,  41, 222, 223, 107, 224, 225, 139,\n",
      "         66, 226,  42, 227, 228,  74, 229,  26,   6,  42, 227, 230,  84, 201,\n",
      "        231, 232, 203,  63, 233, 234, 197, 235, 236,  25, 237, 238,   3,   4,\n",
      "         34, 157, 239,   6,  16, 240, 241, 201, 106, 242,  25, 233, 243, 244,\n",
      "        245, 246,  32,  67,  89,  25, 247, 248, 249, 250, 251, 107,  99, 252,\n",
      "         25, 253,  91, 128, 254,  44,  32, 255, 100, 248, 256,  91, 257,  97,\n",
      "        115,  32, 258, 259, 260, 261, 262,  54, 175, 164,  56, 263, 264, 265,\n",
      "        266, 267, 268,  52, 227, 269, 270,  22, 148, 271, 272, 107, 248, 273,\n",
      "        247,  32, 252, 175, 105, 110,  32,  67, 274,  56,  40, 250, 275,  20,\n",
      "         97, 110, 230, 162, 158, 276,  15,  16, 277, 278, 279, 280, 206,  52,\n",
      "          1,  25,  40,  25, 281, 175, 282, 178,  32, 259, 189, 245, 104,  25,\n",
      "        283, 284, 285,  25, 286,  97,  91, 287,   3,   4, 288, 104,  37, 289,\n",
      "        290, 225, 291, 292,   1, 104,  37, 293, 294,  37,  20,  23,  40,  93,\n",
      "        295, 296,   1, 100, 297, 274,   1, 104,   1,  20, 298,   1, 299, 300,\n",
      "          8,  80, 301,   1, 114,  32, 302,  40, 303,  52, 304, 305, 300,  20,\n",
      "        306, 307,  40, 308,  32,  66, 165,  32, 309, 310,  37, 110, 307,  74,\n",
      "        262,  40, 311, 118,  17,  32, 312,  74, 313,  37, 201, 314,  25, 162,\n",
      "        315, 238, 316, 317, 318,  57, 319,  89, 320, 106, 229, 242,  25, 321,\n",
      "        322, 323,  56, 253,  57,  25,  42, 324,  56, 325, 326,  56, 327, 203,\n",
      "        328, 106, 262, 329, 330, 331,  35,  49, 332,  52,   3,   4, 333, 106,\n",
      "         41,  10,  56, 239, 293,  25, 162, 110,  83,  20,   1, 334,  45, 335,\n",
      "        100,  49, 323,  76,  92,  35, 150,  25, 336, 201, 337, 149,  49, 338,\n",
      "        339,  17,  32, 340, 118, 341,   1, 342, 114,  32, 343, 344, 319,  56,\n",
      "        345, 346, 283,  49, 347,  56, 143, 348, 106,  32, 349, 178,  32, 340,\n",
      "        350,  40,   1, 351,   1,  32,   1, 352, 353, 354, 355, 100,  32, 199,\n",
      "        206,  32, 176, 356, 357, 358,  40,  10, 359, 360, 361, 362, 363, 364,\n",
      "          1, 143, 365, 366,  32, 367,  40, 368, 369, 268,  32, 370, 340, 175,\n",
      "        343, 371, 342,   3,   4, 333, 239, 122, 371, 372,  32, 343, 201, 373,\n",
      "        106, 229, 242,  25, 208,  49, 374,  89, 375, 376, 291, 292, 377, 378,\n",
      "         32, 379,  76, 154, 344, 247, 380,  25, 106, 253, 274,  32, 343, 375,\n",
      "        381, 128,  91,  12,  56,   1, 382, 330,  32, 383, 341,  32, 384, 385,\n",
      "        345,   1, 125, 386, 154, 200, 243, 387, 381,  25,   1,  45, 388, 104,\n",
      "         87, 225,  16, 110, 389,  91,  25,   3,   4, 250, 343, 118, 371,  68,\n",
      "        175, 390, 391, 392,  32,   1, 393, 175, 394, 395,  32, 396,  45, 397,\n",
      "        213, 398,  32, 399,  32, 400,  45,   1, 208, 176,   1,  40, 401, 402,\n",
      "        403,  99,  45, 404,  73,  87,  74, 201,  68, 405, 406,  11,  99, 407,\n",
      "        408,  68, 405, 122, 405,   3,   4, 409, 278,  32, 410, 343,  57, 308,\n",
      "        342, 411,  29,  32, 412, 178,  32, 340, 201, 333, 122, 405,   3,   4,\n",
      "        175, 413,   1,  73,  74, 143, 414,  68, 129,  32, 343, 371, 201, 106,\n",
      "        262, 242,  25, 165,  25,  41, 415,  49, 416,  89, 122,  25,  42, 332,\n",
      "        417, 418,  25,  41,  10,  32])\n"
     ]
    }
   ],
   "source": [
    "# tokenizing the entire Shakespeare text\n",
    "data = torch.tensor(tokenizer.text_to_tokens(text))\n",
    "print(data.shape)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the validation and training data\n",
    "n = int(0.9 * len(data))\n",
    "training_set = data[:n]\n",
    "validation_set = data[n:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
